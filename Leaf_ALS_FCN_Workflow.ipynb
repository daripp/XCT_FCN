{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Leaf ALS FCN Workflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "209affe71dce4ff59cde91b2d8a0a52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1476d1b4239e4256b873cf7c4bf4b3a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_845ff2bbff604717a878e78567eabd0a",
              "IPY_MODEL_0218efc72e5e4161bbff0d3e44e9c511",
              "IPY_MODEL_b36be556db6e4935908b9204b83ecf26"
            ]
          }
        },
        "1476d1b4239e4256b873cf7c4bf4b3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "845ff2bbff604717a878e78567eabd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc3e9a11dcbe410ba3d98cf83c9a5a2b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df7aedfdef564e0d8b30916c6ebc5866"
          }
        },
        "0218efc72e5e4161bbff0d3e44e9c511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b119a1457634566a9afc4c500d127eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 217800805,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 217800805,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f03b72a592d74cd39757932d75752c8b"
          }
        },
        "b36be556db6e4935908b9204b83ecf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d848f28760b4c6abe0a41de33a89d3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 208M/208M [00:04&lt;00:00, 49.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4caab54ff8dd40cb8d080de5c010cf3e"
          }
        },
        "dc3e9a11dcbe410ba3d98cf83c9a5a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df7aedfdef564e0d8b30916c6ebc5866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b119a1457634566a9afc4c500d127eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f03b72a592d74cd39757932d75752c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d848f28760b4c6abe0a41de33a89d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4caab54ff8dd40cb8d080de5c010cf3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daripp/XCT_FCN/blob/main/Leaf_ALS_FCN_Workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVf81n_-qGAe"
      },
      "source": [
        "# ***Welcome to the Training and Inference Pipeline ***\n",
        "\n",
        "# ***Step 1: Mount google drive***\n",
        "\n",
        "# ***Input code from google to access your drive***\n",
        "\n",
        "*** Consider running your instance locally. This will require modification of the file name paths, but will allow use on computers with more resources.***\n",
        "\n",
        "### *To run a local instance:*\n",
        "\n",
        "jupyter notebook  --NotebookApp.allow_origin='https://colab.research.google.com'  --port=8080  --NotebookApp.port_retries=0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFNC0hEZZEQ7",
        "outputId": "e22f4864-2b46-4f76-f26c-3fa44e549add"
      },
      "source": [
        "#Code Box 1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "'01a Intro Env Soil Chem  and Soil Minerals_Jan9.pdf'\n",
            "'01b Soil Minerals_Jan11.pdf'\n",
            "'01c Soil Minerals_Jan13.pdf'\n",
            "'01e Soil Minerals_Jan20.pdf'\n",
            " 01f_Applied_Minerals_Rippner.pdf\n",
            "'02a organic matter_Jan23.pdf'\n",
            "'02b organic matter_Jan25.pdf'\n",
            "'02c organic matter_Jan27.pdf'\n",
            "'02d organic matter_Jan30.pdf'\n",
            "'03b Soil solution_Feb6.pdf'\n",
            "'03c Soil solution_Feb8.pdf'\n",
            "'03d Soil solution_Feb10.pdf'\n",
            "'03e Soil solution_Feb13.pdf'\n",
            "'04a Sorption_Feb15.pdf'\n",
            "'04c Sorption_Feb22.pdf'\n",
            "'04d Sorption_Feb24.pdf'\n",
            "'04e Sorption_Feb27.pdf'\n",
            "'04g Sorption_March3.pdf'\n",
            "'05b redox_March10.pdf'\n",
            "'05c redox_March13.pdf'\n",
            "'05d redox_March15.pdf'\n",
            "'06 Arsenic Lecture_march 17.pdf'\n",
            " 13_Mar_12-15_Grades-SSC_202_001_WQ_2017.gsheet\n",
            "'142500 Tube A  Almond Buds0017.tif'\n",
            "'15N figures 16NOV17.pptx'\n",
            " 20161114_201004.mp4\n",
            "'2017 Review Questions - 1.pdf'\n",
            "'2017 Review Questions 3-key.pdf'\n",
            "'2017 Review Questions - 3.pdf'\n",
            " 20190114_144554.mp4\n",
            " 20200216_023747_Devin_Forest10x.h5_00000.tiff.png\n",
            " 20200216_023747_Devin_Forest10x.h5_00001.tiff.png\n",
            " 20200216_023747_Devin_Forest10x.h5_00002.tiff.png\n",
            "'32P Images from 121618.pptx'\n",
            "'32P SOP.gdoc'\n",
            " 3-5COMMUNITYCONNECTION_plan.docx\n",
            " 3-5HANDOUT-COUNCILCIRCLEGUIDELINES.docx\n",
            " 4_1_40kx_4.tif\n",
            "'64Cu study.png'\n",
            "'7900 ICP-MS.png'\n",
            " AAAQ15928.pdf\n",
            " AAAQ15962.pdf\n",
            " ACL2572164.pdf\n",
            " AcutelyToxicSolidsLiquids_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            " aggregate_______2.mpg\n",
            " aggregate.mpg\n",
            "'aggregate new_Slomo.mp4'\n",
            " aggregate________Slomo.mp4\n",
            "'Ag microbiome call'\n",
            "'Alex Compost'\n",
            "'ALS R1.pdf'\n",
            "'ALS Workflow'\n",
            " Ammonium_Nitrate_10-13.docx\n",
            "'Annual Refresher Group Training_20170321.docx'\n",
            "'A workflow for segmenting soil and plant X-ray CT images with deep learning in Google’s Colaboratory.docx'\n",
            "'Bacteria on lettuce roots.png'\n",
            " Bayer\n",
            "'Bayer Supplies.gsheet'\n",
            "'Bayer Update 41919 (1).pptx'\n",
            "'Bayer Update 41919.pptx'\n",
            "'Beamline Planning.gdoc'\n",
            "'Biochar pictures.pptx'\n",
            "'Biochar Videos'\n",
            "'Birnessite-(Na0.3Ca0.1K0.1)(Mn4+,Mn3+)2O4 · 1.5 H2O.tif'\n",
            "'Blank Quiz.gform'\n",
            " Buds\n",
            " Carcinogens_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            "'Chloe Annotations.zip'\n",
            "'Chris FCN Workflow'\n",
            "'Christine FCN Workflow'\n",
            "'Clarissa colab'\n",
            "'Class Todo.gdoc'\n",
            "'Cleaning Duckweed SOP.docx'\n",
            "'CLS proposal work flow'\n",
            " CMGI_Pilot_Funds_2017_DR_RD_SJP.pdf\n",
            " colab_notebook_DARplay\n",
            "'Colab Notebook for Beth'\n",
            "'Colab notebook for Jeff'\n",
            "'Colab notebook for Joaquin'\n",
            "'Colab notebook for Kayla'\n",
            "'Colab Notebooks'\n",
            "'Colab Notebooks_'\n",
            "'Colab Notebooks_DR'\n",
            "'Colab Notebooks_MinaDAR'\n",
            "'column 5_Trim.mp4'\n",
            " column6_Trim.mp4\n",
            "'Column Pic (1).png'\n",
            "'Column Pic.png'\n",
            "'Community Composition Stats for Andrew.docx'\n",
            "'Compost Final Day CN 1 to 56.png'\n",
            "'Compost Final Day CN 57 to 84.png'\n",
            "'Compost Final Day CN.png'\n",
            "'Compost Initial Day CN 1 to 23.png'\n",
            "'Compost Initial Day CN 24 to 60.png'\n",
            "'Compost Initial Day CN 61 to 84.png'\n",
            "'Compost Mixing Schedule.gsheet'\n",
            "'CoO 2.tif'\n",
            " CoO.mp4\n",
            "'CoO NPs (40K zoom) better.png'\n",
            "'CoO NPs (40K zoom).png'\n",
            " CoO_NPs.mp4\n",
            "'Corn P uptake V2 (1).zip'\n",
            "'Corn P uptake V2 (2).zip'\n",
            "'Corn P uptake V2.zip'\n",
            " Corrosives_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            "'Costs and Design Apendix for Project.docx'\n",
            "'Costs and Design Apendix for Project.gdoc'\n",
            "'costs for each system.gsheet'\n",
            "'Costs for each System.xlsx'\n",
            "'CuO HM10.tif'\n",
            "'CuO HM_1.tif'\n",
            " dani\n",
            "'dani column_5.mpg'\n",
            "'dani column_7_1 (1).mpg'\n",
            "'dani column_7_1.mpg'\n",
            "'dani column__Trim.mp4'\n",
            "'DAR122920_SF_Edits Land management controls microbial response to Cu nanoparticles_sf.docx'\n",
            "'DAR122920_SF_Edits Land management controls microbial response to Cu nanoparticles_sf.gdoc'\n",
            " Design_Project_243a,_fall_2013l.docx\n",
            "'Devin_Ripner_Final Review.pdf'\n",
            " Draft.docx\n",
            " Draft.gdoc\n",
            "'Dragonfly 2020-06-15 15-07-53.mp4'\n",
            "'Dragonfly 2020-06-15 20-58-51.mp4'\n",
            "'Dragonfly 2020-06-29 11-31-30.mp4'\n",
            "'Dragonfly 2020-06-29 11-32-20.mp4'\n",
            "'Dragonfly 2020-06-29 11-33-31.mp4'\n",
            "'Dragonfly 2020-06-29 11-57-28.mp4'\n",
            "'Dragonfly 2020-06-29 19-49-49.mp4'\n",
            "'Dragonfly 2020-07-02 21-08-32.mp4'\n",
            "'Dragonfly 2020-07-03 16-29-10.mp4'\n",
            "'Dragonfly 2020-07-03 20-48-24.mp4'\n",
            "'Dragonfly 2020-07-03 21-09-47.mp4'\n",
            "'Dragonfly 2020-10-18 15-31-43.mp4'\n",
            "'Dragonfly 2020-11-05 10-49-30.mp4'\n",
            "'Dragonfly 2020-11-05 20-04-53.mp4'\n",
            "'DRP competition'\n",
            "'Duckweed 2.jpg'\n",
            "'Duckweed Growth.xlsx'\n",
            " Duckweed.png\n",
            "'E33 no PH adjustment.gsheet'\n",
            "'E33 no PH adjustment.xlsx'\n",
            " earlyferm.gif\n",
            "'Easter Island Slides.pdf'\n",
            "'ECG Application.doc'\n",
            "'ECG Application.gdoc'\n",
            "'Endangered soils are those with greater than 50.docx'\n",
            "'Environmental Metal Contamination.pptx'\n",
            " Erosion.jpg\n",
            "'E-Safety Training Attendance Record_2020_CR_AM_NB_TK_KK_IH_FD_KA_DR.pdf'\n",
            "'ESI (1).jpg'\n",
            " ESI.jpg\n",
            "'Event Summary.gdoc'\n",
            "'Excess Water.png'\n",
            "'FCN for Garett'\n",
            "'FCN workflow for Craig'\n",
            "'FCN WORKFLOW PAPER'\n",
            " feldstone_Slomo.mp4\n",
            "'Fertilizer and Plant Nutrition Guide FAO (1).pdf'\n",
            "'Fertilizer and Plant Nutrition Guide FAO.pdf'\n",
            " filepath\n",
            "'Final Exam Practice.pdf'\n",
            "'Financial Need.pdf'\n",
            " FlammableLiquids_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DR.pdf\n",
            "'Funding 2014-2015.gdoc'\n",
            "'Geisenheim Test 109 Davis'\n",
            "'Generalized leaf Sept 411 r3.mpg'\n",
            "'GFH No PH Adjust Design.gsheet'\n",
            "'GFH No PH Adjust Design.xlsx'\n",
            "'GFH w PH Adjustment Design (1).gsheet'\n",
            "'GFH w PH Adjustment Design.gsheet'\n",
            "'GFH w PH Adjustment Design.xlsx'\n",
            "'Grape Soil Health Initiative'\n",
            "'Green House 0.png'\n",
            "'Green House 1.png'\n",
            "'Green House 2.png'\n",
            "'Green House 3.png'\n",
            "'Green House 4.png'\n",
            "'Green House 5.png'\n",
            "'Green House 6.png'\n",
            "'Handbook for Integrated Soil Fertility Management. Africa.pdf'\n",
            "'HPC training '\n",
            " HW1_HYD134_answer_key.pdf\n",
            " HW2_HYD134_answer_key.pdf\n",
            "'HW3_HYD134_AlF Answer Key.pdf'\n",
            " HW4_HYD134_answer_key.pdf\n",
            "'HW5_HYD134 answer key.pdf'\n",
            "'HXMA_dotE Lab view (1).zip'\n",
            "'HXMA_dotE Lab view.zip'\n",
            "'HXMA Fits Labview.zip'\n",
            "'HYD_134_HW6_answer key.pdf'\n",
            "'HYD_134_HW7 answer key.pdf'\n",
            "'HYD134 Lab Manual_2016.gdoc'\n",
            "'Hydroponic Carrot (1).png'\n",
            "'Hydroponic Carrot.png'\n",
            "'image (1).png'\n",
            "'image (2).png'\n",
            "'image (3).png'\n",
            "'image (4).png'\n",
            "'image (5).png'\n",
            " image_FCN_binary\n",
            " image.png\n",
            " images_\n",
            "'images_ (1)'\n",
            " IMG_20180623_192708161.jpg\n",
            "'Incubation Figures_ajm.pptx'\n",
            "'Incubation Figures.pptx'\n",
            " incubation.png\n",
            "'In-Vivo tracking of Radiolabeled nanoparticles.pdf'\n",
            "'Job Talk USDA ARS Washington.pptx'\n",
            "'Jordon Media.pptx'\n",
            "'late ferm.gif'\n",
            " LBNL.png\n",
            "'Leaf 411_2_Slomo.mp4'\n",
            "'Leaf 411.avi'\n",
            "'Leaf 486 oct r2_Slomo.mp4'\n",
            "'Leaf 486_R2_Sep.avi'\n",
            " leaf_area_seg.zip\n",
            "'Lettuce NP uptake.png'\n",
            "'Lettuce Root Growth Experiment.png'\n",
            "'liming soil health 17OCT17.docx'\n",
            " Magnetite-Fe3O4.tif\n",
            "'Managing Soil Organic Matter.pdf'\n",
            "'matplotlib book.pdf'\n",
            " Mayachar4.tif\n",
            "'Me and the ICP-Ms.png'\n",
            "'Midterm #1 CO2 closed 2016 answer key.pdf'\n",
            "'Midterm #1 CO2 closed 2016.pdf'\n",
            "'Midterm #2 2017 Answer Key.pdf'\n",
            " Mina_Colab_Notebook\n",
            "'Moisture content correction for compost initial and final 1 to 34.png'\n",
            "'Moisture content correction for compost initial and final 36 to 73.png'\n",
            "'Moisture content correction for compost initial and final 74 to 84.png'\n",
            "'My photos'\n",
            "'nanoparticle uptake by lactuca.pdf'\n",
            "'nanoparticle uptake by Latuca.pdf'\n",
            "'Natalie Poster.pptx'\n",
            "'NDCRO-D-17-01961R1 response to reviewers 29AUG17_SJP_BA.docx'\n",
            "'new leaf_1__.avi'\n",
            " Nocco2021_Seminar_UCD_Plant_Sci.pptx\n",
            "'Notes from 72018 meeting.docx'\n",
            "'NP in Column on Mag.png'\n",
            "'oak '\n",
            "'Oak 4.emf'\n",
            "'oak reconstruction 2.emf'\n",
            "'oak reconstruction 3.emf'\n",
            "'Old ALS'\n",
            " olddataframe.csv\n",
            "'Oxalate-P Manuscript_draft_v3.docx'\n",
            "'Parikh Rippner SSSA Tomato CuO.pptx'\n",
            "'Personal Statement.gdoc'\n",
            " Pictures\n",
            "'Pixel Quantification Practice 122718_2 (1).xlsx'\n",
            "'Pixel Quantification Practice 122718_2.xlsx'\n",
            "'PNNL Proposal'\n",
            "'PNNL Soil Colab'\n",
            "'PONE-D-17-26375 Response to reviews 2DEC17_AJM.docx'\n",
            "'PowerPoint Slide Show  -  Jordon Media.pptx  -  Last saved by user 2020-11-11 20-00-48.mp4'\n",
            "'PowerPoint Slide Show  -  Soil Con talk 2021-01-25 17-48-19_Trim.mp4'\n",
            "'Practice Exam-1.pdf'\n",
            "'Practice Exam-2.pdf'\n",
            "'Practice Exam-3.pdf'\n",
            "'Practice exam questions3.pdf'\n",
            "'Practice Midterm Exam #1.pdf'\n",
            "'Practice Midterm Exam #2.pdf'\n",
            "'Practice redox questions.pdf'\n",
            " preferm.gif\n",
            "'Problem set #1-key.pdf'\n",
            "'Problem set #2-key.pdf'\n",
            "'Problem set #3-key.pdf'\n",
            "'Problem set #4-key.pdf'\n",
            "'Problem set #5-key.pdf'\n",
            "'Problem set #6.pdf'\n",
            "'Problem set #7-key.pdf'\n",
            "'Problem set #8-key.pdf'\n",
            " PSET_1_2017_KEY.pdf\n",
            " PSET_2_2017_KEY.pdf\n",
            " PSET_3_2017_KEY.pdf\n",
            " PSET_4_2017_KEY.pdf\n",
            " PSET_5_Key_2017.pdf\n",
            " Pyrophorics_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            "'Questions for Will.gdoc'\n",
            "'reconfiguring ICPMS.docx'\n",
            "'Redox midterm 2016 answer key.pdf'\n",
            "'Redox midterm 2016.pdf'\n",
            " ReproductiveToxins_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            "'Research Todo'\n",
            "'Riparian Soil Profile.png'\n",
            "'Rippner CuO Nanoparticles Soil Incubation 102317 (1).pptx'\n",
            "'Rippner CuO Nanoparticles Soil Microbial Size and Structure (1).pptx'\n",
            "'Rippner CuO Nanoparticles Soil Microbial Size and Structure.pptx'\n",
            "'Rippner, Devin.pdf'\n",
            "'RIPPNER,devin-W2018-TA-iDocJasper-1 (1).docx'\n",
            "'RIPPNER,devin-W2018-TA-iDocJasper-1 (2).docx'\n",
            " RIPPNER,devin-W2018-TA-iDocJasper-1.docx\n",
            "'Rippner_Workflow paper_2.docx'\n",
            " Role_Call_blank.PNG\n",
            " Roots.png\n",
            "'Sanjai Mentorship Nomination Letter.gdoc'\n",
            "'Sarah and I.png'\n",
            "'Shalini Images 32P'\n",
            " Shared\n",
            "'Shrink Swell.png'\n",
            "'small_image bce 100 epoch1 (1).gsheet'\n",
            "'small_image bce 100 epoch1.gsheet'\n",
            "'Soil Colab'\n",
            "'soil column 1.avi'\n",
            "'soil column 2.avi'\n",
            "'soil column 3.avi'\n",
            "'soil column 4.avi'\n",
            "'Soil Con talk__.mp4'\n",
            "'Soil Health Paper'\n",
            "'Soils Outreach - Parikh Lab'\n",
            " Soils_Wines_Vines_2017.docx\n",
            " Spectroscopy_Manuscript.docx\n",
            " Spectroscopy_Manuscript.gdoc\n",
            "'spurs embedding.pdf'\n",
            "'SSC10 zip.zip'\n",
            "'SSSA Joint Symposia Proposal.docx'\n",
            "'SSSA Talk Actual 102117.pptx'\n",
            " student_assistant_pay_plan.pdf\n",
            "'Student Assistant Position Information Form.pdf'\n",
            "'Submission Ready Folder'\n",
            "'T0 Introduction Slides.pdf'\n",
            "'T10 Slides.pdf'\n",
            "'T11 Slides.pdf'\n",
            "'T12 Slides.pdf'\n",
            "'T13 Slides.pdf'\n",
            "'T14 Slides.pdf'\n",
            "'T15-16 Slides.pdf'\n",
            "'T17 Slides.pdf'\n",
            "'T18 Slides.pdf'\n",
            "'T19 Slides.pdf'\n",
            "'T1 slides.pdf'\n",
            "'T20 Slides.pdf'\n",
            "'T2 Slides.pdf'\n",
            "'T3 Slides.pdf'\n",
            "'T4 Slides.pdf'\n",
            "'T5 Slides.pdf'\n",
            "'T6 Slides.pdf'\n",
            "'T7 Slides.pdf'\n",
            "'T8 Slides.pdf'\n",
            "'T9 Slides.pdf'\n",
            "'task_segmentation d7-2020_09_25_14_35_06-cvat for images 1.1 (4).zip'\n",
            " testcropimage.tif\n",
            "'The transport and fate of manufactured nano-metal oxides SJP.pptx'\n",
            "'Tomato Paper'\n",
            "'Tropical Soil Biology and Fertility, A handbook of methods.pdf'\n",
            " Uganda_soils.kmz\n",
            " Untitled\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document (3).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled presentation.gslides'\n",
            "'Update on 32P project.pptx'\n",
            "'URC Poster 2015 edits.ppt'\n",
            "'USDA Compost Day 0 and final.xlsx'\n",
            "'USDA NP 2017_Draft_2.pptx'\n",
            "'Using Synchrotron Light to Probe Plant, Soil.pptx'\n",
            "'validation '\n",
            "'Virginia Tech'\n",
            "'Visiting Mina.gsheet'\n",
            "'Windows Media Player 2021-01-18 13-29-33_Trim_Trim (1).mp4'\n",
            "'Windows Media Player 2021-01-18 13-29-33_Trim_Trim (2).mp4'\n",
            "'Windows Media Player 2021-01-18 13-29-33_Trim_Trim.mp4'\n",
            " WS00560230-RR_Budget_1_4-V1.4.pdf\n",
            "'XANES EXAFS proposal.gdoc'\n",
            "'XANES Fig2.tif'\n",
            "'Yuhei and Zaahir.png'\n",
            "'Zaahir Biochar Presentation.pptx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wIucgH-C0od",
        "outputId": "d8ac7d41-c96c-43a4-c110-5a39958f2042"
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 13 20:52:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    22W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_LRdfyso3Sk",
        "outputId": "dc823306-e5c6-4558-df17-a8c264a88547"
      },
      "source": [
        "pip install -U albumentations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Collecting qudida>=0.0.4\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (3.10.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.0.0)\n",
            "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-1.1.0 opencv-python-headless-4.5.5.62 qudida-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqIcbeJJNzt4",
        "outputId": "3a7717a7-9f78-4ae6-9679-fa0fa6ba56a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.5.62\n",
            "Uninstalling opencv-python-headless-4.5.5.62:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.62.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-64ac49e1.so.58.91.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-4b79e479.so.58.45.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-805734e8.so.56.51.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-018b8c17.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng15-ce838cd1.so.15.13.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-6082116c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-83ce3247.so.3.7.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-7e960168.so.5.7.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-392cd848.so.6.4.0\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled opencv-python-headless-4.5.5.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless==4.1.2.30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vNr6NgRN870",
        "outputId": "c2e83cb7-229d-401e-b5dd-aaa4d0890762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.19.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTtktpgSWaQ6"
      },
      "source": [
        "#**Materials**\n",
        "  Input the material mask name and information below.\n",
        "\n",
        "  Specifically:\n",
        " \n",
        "  **name** - The name for the material. This is pretty arbitrary, but it will be\n",
        "  used to label output folders and images.\n",
        " \n",
        "  **input_rbg_vals** - The rbg values of the material in the input mask image.\n",
        " \n",
        "  **output_val** - The greyscale value of the mask when you output the images.\n",
        "  This is arbitrary, but every material should have its own output color\n",
        "  so they can be differentiated\n",
        " \n",
        "  **confidence_threshold** - The lower this number, the more voxels will be labled a specific material. Essentially, the ML algorith outptus a confdience value  (centered on 0.5) for every voxel and every material. By default, voxels with  a confidence of 0.5 or greater are determined to be the material in question.  But we can labled voxles with a lower condience level by changing this  parameter\n",
        "  \n",
        "  **training_image_directory /training_mask_directory**: Input the directory where your training images and masks are located.\n",
        "\n",
        "  **validation_fraction**: Input the fraction of images you want to validate your model during training. These are not a independent validation, but are part of the training process.\n",
        "\n",
        "  **num_models**: Enter the number of models you want to iteratively train. Because these are statistical models, the performance of any given model will vary. Training more models will allow you to select the model that best fits your data.\n",
        "  \n",
        "  **num_epochs**: Enter number of epochs that you want to use to train your model. More is generally better, but takes more time.\n",
        "\n",
        "  **batch_size**: Input your batch size. Larger batch sizes allow for faster training, but take up more VRAM. If you are running out of VRAM during training, decrease your batch size.\n",
        "\n",
        "  **scale**: Input how you want your images scaled during model training and inference. When the scale is 1, your images will be used at full size for training. When the scale is less than 1, your images will be downsized according to the scale you set for training and inference, decreasing VRAM usage. If you run out of VRAM during training, consider rescaling your images.\n",
        "\n",
        "  **models_directory**: Directory where your models are saved.\n",
        "\n",
        "  **model_group**: Name for the group models you iteratively generate.\n",
        "\n",
        "  **current_model_name**: Name for each individual model you generate; will automatically be labeled 1 through n for the number of models you specify above.\n",
        "\n",
        "  **val_images/val_masks**: Input the directory where your independent validation images and masks are located. These images are not used for training and are used as an independent validation of your model.\n",
        "\n",
        "  **csv_directory**: Directory where a CSV file of your validation results will be saved.\n",
        "\n",
        "  **inference_directory**: Directory where the images you want analyzed are located.\n",
        "\n",
        "  **output_directory**: Directory where you want your analysis results to be saved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0lUyHr9cQy3"
      },
      "source": [
        "class Material:\n",
        " \n",
        "  def __init__(self, name, input_rgb_vals, output_val, confidence_threshold=0):\n",
        "    self.name = name\n",
        "    self.input_rgb_vals = input_rgb_vals\n",
        "    self.output_val = output_val\n",
        "    self.confidence_threshold = confidence_threshold\n",
        " \n",
        "#Creating a list of materials so we can iterate through it\n",
        "materials = [\n",
        "             Material(\"background\", [85,85,85], 30, 0.5),\n",
        "             Material(\"epidermis\", [170,170,170], 150, 0.5),\n",
        "             Material(\"mesophyll\", [255,255,255], 255, 0.5),\n",
        "             Material(\"air_space\", [0,0,0], 1, 0.4),\n",
        "             Material(\"bundle_sheath_extension\", [103,103,103], 100, 0.5),\n",
        "             Material('vein', (35,35,35), 180, 0.5)\n",
        "            ]\n",
        " \n",
        "num_materials =len(materials)\n",
        "#Various input/output directories\n",
        "training_image_directory = \"drive/MyDrive/ALS Workflow/train/leaf_images/\"\n",
        "training_mask_directory = \"drive/MyDrive/ALS Workflow/train/leaf_masks/\"\n",
        "#Fraction of total annotations you want to leave for validating the model.\n",
        "validation_fraction=0.2\n",
        "#Model Performance varies, make multiple models to have the best chance at success.\n",
        "num_models=10\n",
        "#Model Performance improves with increasing epochs, to a point.\n",
        "num_epochs=100\n",
        "\"\"\"Increasing batch size increase model training speed, but also eats up VRAM on the GPU. Find a balance between scale and batch size\n",
        "that best suits your needs\"\"\"\n",
        "batch_size=1\n",
        "#Decrease scale to decrease VRAM usage; if you run out of VRAM during traing, restart your runtime and down scale your images\n",
        "scale=1\n",
        "#Input model directory\n",
        "models_directory = \"drive/MyDrive/ALS Workflow/best_models/\"\n",
        "#Input the name you want to use for your group of models\n",
        "model_group='10 leaf bce p2 100 epoch/'\n",
        "current_model_name = '10 leaf bce p2 100 epoch__'\n",
        "\"\"\"Hold images/annotations in reserve to test your model performance. Use this metric to decide which model you want to use \n",
        "for your data analysis\"\"\"\n",
        "test_images = \"drive/MyDrive/ALS Workflow/test/test_images/\"\n",
        "test_masks= 'drive/MyDrive/ALS Workflow/test/test_masks/'\n",
        "csv_directory = \"drive/MyDrive/ALS Workflow/10 leaf bce p2 100 epoch testing code change.csv\"\n",
        "#Input the directory of the data you want to segment here.\n",
        "inference_directory= \"drive/MyDrive/ALS Workflow/test/test_images/\"\n",
        "#Input the 5 alpha-numeric characters proceding the file number of your images\n",
        "  #EX. Jmic3111_S0_GRID image_0.tif ----->mage_\n",
        "proceeding=\"lice_\"\n",
        "#Input the 4 or mor alpha-numeric characters following the file number\n",
        "  #EX. Jmic3111_S0_GRID image_0.tif ----->.tif\n",
        "following=\".png\"\n",
        "output_directory = \"drive/MyDrive/ALS Workflow/test_images_results change/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVUEc0LlWKXZ"
      },
      "source": [
        "#**Parameter Loading**\n",
        "Please do not alter this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F20zRhMZPpq",
        "outputId": "0217151a-53cf-44f0-8f2d-960f8ea91c17"
      },
      "source": [
        "#Code Box 2\n",
        "from os.path import splitext\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import logging\n",
        "from PIL import Image\n",
        "import random\n",
        "#import scipy.ndimage as ndi\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from scipy.ndimage import morphology\n",
        "from torch.utils.data import DataLoader, random_split\n",
        " \n",
        "class BasicDataset(Dataset):\n",
        "    def __init__(self, imgs_dir, masks_dir, scale=scale, transform=False):\n",
        "        self.imgs_dir = imgs_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.scale = scale\n",
        "        self.transform=transform\n",
        "        self.t_list=A.Compose([A.HorizontalFlip(p=0.4),A.VerticalFlip(p=0.4), A.Rotate(limit=(-50, 50), p=0.4),])\n",
        "        self.means=[0,0,0]\n",
        "        self.stds=[1,1,1]\n",
        "\n",
        "        \n",
        "        assert 0 < scale <= 1, 'Scale must be between 0 and 1'\n",
        " \n",
        "        self.ids = [splitext(file)[0] for file in listdir(imgs_dir)\n",
        "                    if not file.startswith('.')]\n",
        "        logging.info(f'Creating dataset with {len(self.ids)} examples')\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        " \n",
        " \n",
        "    @classmethod\n",
        "    def mask_preprocess(cls, pil_img, scale):\n",
        "        w, h = pil_img.size\n",
        "        newW, newH = int(scale * w), int(scale * h)\n",
        "        assert newW > 0 and newH > 0, 'Scale is too small'\n",
        "        pil_img = pil_img.resize((newW, newH))\n",
        " \n",
        "        img_nd = np.array(pil_img)\n",
        " \n",
        "        if len(img_nd.shape) == 2:\n",
        "            img_nd = np.expand_dims(img_nd, axis=2)\n",
        " \n",
        "       \n",
        "        return img_nd\n",
        "    \n",
        " \n",
        "        \n",
        "    def img_preprocess(cls, pil_img, scale):\n",
        "        w, h = pil_img.size\n",
        "        newW, newH = int(scale * w), int(scale * h)\n",
        "        assert newW > 0 and newH > 0, 'Scale is too small'\n",
        "        pil_img = pil_img.resize((newW, newH))\n",
        " \n",
        "        img_nd = np.array(pil_img)\n",
        " \n",
        "        if len(img_nd.shape) == 2:\n",
        "            img_nd = np.expand_dims(img_nd, axis=2)\n",
        " \n",
        "       \n",
        " \n",
        "        return img_nd\n",
        " \n",
        "    def __getitem__(self, i):\n",
        "        idx = self.ids[i]\n",
        "        mask_file = glob(self.masks_dir + idx + '*')\n",
        "        img_file = glob(self.imgs_dir + idx + '*')\n",
        " \n",
        "        assert len(mask_file) == 1, \\\n",
        "            f'Either no mask or multiple masks found for the ID {idx}: {mask_file}'\n",
        "        assert len(img_file) == 1, \\\n",
        "            f'Either no image or multiple images found for the ID {idx}: {img_file}'\n",
        "        mask = Image.open(mask_file[0])\n",
        "        img = Image.open(img_file[0])\n",
        " \n",
        "  \n",
        "        \n",
        " \n",
        "        \n",
        "        #Reshapes from 1 channel to 3 channels in grayscale\n",
        "        img = self.img_preprocess(img, self.scale)\n",
        "        mask = self.mask_preprocess(mask, self.scale)\n",
        "        new_image=np.zeros((img.shape[0],img.shape[1],3))\n",
        "        new_image[:,:,0]=img[:,:,0]\n",
        "        new_image[:,:,1]=img[:,:,0]\n",
        "        new_image[:,:,2]=img[:,:,0]\n",
        "        \n",
        " \n",
        " \n",
        " \n",
        "        img=new_image\n",
        " \n",
        "        #New Code\n",
        "        masklist=[]\n",
        "        # print(mask.shape)       \n",
        "        for i, mat in enumerate(materials):\n",
        "          # plt.imshow(mask[:,:,0])\n",
        "          # plt.show()\n",
        "          indices = np.all(mask == mat.input_rgb_vals, axis=-1)\n",
        "          new_mask=np.zeros((img.shape[0],img.shape[1]))\n",
        "          new_mask[indices] = 1\n",
        "          masklist.append(new_mask)\n",
        " \n",
        "        mask=masklist\n",
        "  \n",
        "        # plt.imshow(mask[1,:,:])\n",
        "        # i=6\n",
        "        # for i in range(len(mask)):\n",
        "        #   plt.imshow(mask[i,:,:])\n",
        "        #   plt.show()\n",
        "        \n",
        "        if img.max() > 1:\n",
        "            img = img / 255\n",
        " \n",
        "       \n",
        " \n",
        "        \n",
        "        if self.transform:\n",
        "            augmented=self.t_list(image=img, masks=mask)\n",
        "            img=augmented[\"image\"]\n",
        "            mask=augmented[\"masks\"]\n",
        "            \n",
        " \n",
        "        \n",
        " \n",
        "        img = img.transpose((2, 0, 1))\n",
        "        \n",
        "        mask=np.array(mask)\n",
        "        \n",
        "        \n",
        " \n",
        "        \n",
        " \n",
        "        img=torch.from_numpy(img)\n",
        "        mask=torch.from_numpy(mask)\n",
        "        \n",
        "        img=transforms.Normalize(mean=self.means, std=self.stds)(img)\n",
        "        return img, mask\n",
        "        \n",
        "        \n",
        "dataset = BasicDataset(training_image_directory, training_mask_directory, scale=scale, transform=False)\n",
        " \n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!Set batch size here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# train, val=trainval_split(dataset, val_fraction=0.5)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)#, collate_fn=pad_collate)\n",
        "#val_loader = DataLoader(val, batch_size=3, shuffle=False, num_workers=0, pin_memory=True)#, collate_fn=pad_collate)\n",
        "nimages = 0\n",
        "mean = 0. \n",
        "std = 0.\n",
        "for batch, _ in train_loader:\n",
        "    # Rearrange batch to be the shape of [B, C, W * H]\n",
        "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
        "    # Update total number of images\n",
        "    nimages += batch.size(0)\n",
        "    # Compute mean and std here\n",
        "    mean += batch.mean(2).sum(0) \n",
        "    std += batch.std(2).sum(0)\n",
        " \n",
        "# Final step\n",
        "mean /= nimages\n",
        "std /= nimages\n",
        " \n",
        "print(mean)\n",
        "print(std)\n",
        "\n",
        "dataset.means=mean\n",
        "dataset.stds=std \n",
        "\n",
        "nimages = 0\n",
        "mean = 0.\n",
        "std = 0.\n",
        "for batch, _ in train_loader:\n",
        "    # Rearrange batch to be the shape of [B, C, W * H]\n",
        "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
        "    # Update total number of images\n",
        "    nimages += batch.size(0)\n",
        "    # Compute mean and std here\n",
        "    mean += batch.mean(2).sum(0) \n",
        "    std += batch.std(2).sum(0)\n",
        " \n",
        "# Final step\n",
        "mean /= nimages\n",
        "std /= nimages\n",
        " \n",
        "print(mean)\n",
        "print(std)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4742, 0.4742, 0.4742], dtype=torch.float64)\n",
            "tensor([0.0569, 0.0569, 0.0569], dtype=torch.float64)\n",
            "tensor([-3.4613e-16, -3.4613e-16, -3.4613e-16], dtype=torch.float64)\n",
            "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qamo0PVkJj78"
      },
      "source": [
        "Now you are ready to train your model in code block 4. \n",
        "If you run out of VRAM, restart the runtime, reload google drive, and try again. Also consider rescaling your images or decreasing your batch size.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YVqggi2Wwzl"
      },
      "source": [
        "#**Model** **Training**\n",
        "Please do not alter this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "209affe71dce4ff59cde91b2d8a0a52d",
            "1476d1b4239e4256b873cf7c4bf4b3a4",
            "845ff2bbff604717a878e78567eabd0a",
            "0218efc72e5e4161bbff0d3e44e9c511",
            "b36be556db6e4935908b9204b83ecf26",
            "dc3e9a11dcbe410ba3d98cf83c9a5a2b",
            "df7aedfdef564e0d8b30916c6ebc5866",
            "7b119a1457634566a9afc4c500d127eb",
            "f03b72a592d74cd39757932d75752c8b",
            "0d848f28760b4c6abe0a41de33a89d3a",
            "4caab54ff8dd40cb8d080de5c010cf3e"
          ]
        },
        "id": "hfacTW9AAryp",
        "outputId": "75b43407-4d30-4de8-f292-e7788a85e5cf"
      },
      "source": [
        "#For loop for FCN model training Cell Code Box 4\n",
        "#!cd \"drive/My Drive/Colab Notebooks\"\n",
        "# Semantic Segmentation and Data Extraction in Pytorch Using FCN by Pranav Raja and a tiny bit by Devin Rippner (Plant AI and BioPhysics Lab)\n",
        "# a work in progress, works well overall but need mroe people to look at it and identify bugs\n",
        "#%%\n",
        " \n",
        "import torchvision\n",
        "from torchvision.models.segmentation.fcn import FCNHead\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "# from torch._six import container_abcs, string_classes, int_classes\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import psutil\n",
        "import gc\n",
        "import random\n",
        " \n",
        "dir_checkpoint = models_directory\n",
        " \n",
        " \n",
        "model_group=model_group\n",
        "num_models=num_models\n",
        "os.mkdir(dir_checkpoint+model_group)\n",
        "seed=0\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "for i in range(num_models):\n",
        "  #!!!!!!! Here we pull in a pretrained FCN on torch and we replace the output layer since we have six classes rather than 21!!!!!!!!\n",
        "  num_classes=num_materials\n",
        "  model=torchvision.models.segmentation.fcn_resnet101(pretrained=True, progress=True)\n",
        "  model.classifier=FCNHead(2048, num_classes)\n",
        "  \n",
        "  def trainval_split(dataset, val_fraction=0.5):\n",
        " \n",
        "    validation_size = int(len(dataset) * val_fraction)\n",
        "    train_size = len(dataset) - validation_size\n",
        "    # print(validation_size)\n",
        "    # print(train_size)\n",
        "    # print(len(dataset))\n",
        "    # print(dataset.dataset_size)\n",
        "    train, val = torch.utils.data.random_split(dataset, [train_size, validation_size], generator=torch.Generator().manual_seed(i))\n",
        " \n",
        "    return train, val\n",
        " \n",
        " \n",
        " \n",
        "  dataset= BasicDataset(training_image_directory, training_mask_directory, scale=scale, transform=True)\n",
        "  dataset_train, dataset_val=trainval_split(dataset, val_fraction=validation_fraction)\n",
        "  #!!!!!select folders for the images and masks associated with training and validation here. Also specify image scaling factor here!!!!!!!!!!!!!!!!\n",
        "  # dataset_train = BasicDataset(training_image_directory, training_mask_directory, 1, transform=True)\n",
        "  # dataset_val = BasicDataset(training_image_directory, training_mask_directory, 1, transform=False)\n",
        "  # dataset_train = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/train/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/train/mask_edited2/\", 1, transform=True)\n",
        "  # dataset_val = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/test/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/test/mask_edited2/\", 1, transform=False)\n",
        "  \n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Specify Batch Size Here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)#, collate_fn=pad_collate)\n",
        "  val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)#, collate_fn=pad_collate)\n",
        " \n",
        " \n",
        "  #%%\n",
        " \n",
        "  # this is the train code \n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!! Input epochs here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  num_epochs=num_epochs\n",
        "  # read up on optimizers but Adam should work for now, if you get good results with Adam then you can try SGD (it's harder to tune but usually converges better)\n",
        "  optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        " \n",
        "  #just initializing a value called best_loss\n",
        "  best_loss=999\n",
        " \n",
        "  # choose a loss function\n",
        "  # criterion=nn.CrossEntropyLoss()\n",
        "  #criterion=nn.BCELoss().cuda()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  # class diceloss(nn.Module):\n",
        "  #     def __init__(self, epsilon):\n",
        "  #         # super(diceloss, self).init()\n",
        "  #         super(diceloss, self).__init__()\n",
        "  #         self.sigmoid=nn.Sigmoid()\n",
        "  #         self.epsilon=epsilon\n",
        "  #         # print('HI')\n",
        "  #     def forward(self, pred, target):\n",
        "  #         if target.size() != pred.size():\n",
        "  #             raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), pred.size()))\n",
        "  #         pred=self.sigmoid(pred)\n",
        "  #         tp=torch.sum(target*pred, (1,2,3))\n",
        "  #         fp=torch.sum((1-target)*pred, (1,2,3))\n",
        "  #         fn=torch.sum(target*(1-pred), (1,2,3))\n",
        "  #         # precision=tp/(tp+fp)\n",
        "  #         # recall=tp/(tp+fn)\n",
        "  #         f1=(tp)/(tp+self.epsilon+0.5*(fp+fn))\n",
        "  #         # print(f1)\n",
        "  #         return 1-torch.mean(f1)\n",
        "  # criterion=diceloss(epsilon=epsilon)\n",
        "  # model.train()\n",
        "  # model.train()\n",
        "  #this is the train loop\n",
        "  for epoch in range(num_epochs):\n",
        "      print(psutil.virtual_memory().percent)\n",
        "      print('Epoch: ', str(epoch))\n",
        "    #add back if doing fractional training\n",
        "      train_loader.dataset.dataset.transform=True\n",
        "      model.train()\n",
        "      for images, masks in train_loader:\n",
        " \n",
        "          images = images.to(device=device, dtype=torch.float32)\n",
        "          masks = masks.to(device=device, dtype=torch.float32)\n",
        " \n",
        "          #forward pass\n",
        "          preds=model(images)['out'].cuda()\n",
        "        \n",
        "          #compute loss\n",
        "          loss=criterion(preds, masks)\n",
        "        \n",
        "          #reset the optimizer gradients to 0\n",
        "          optimizer.zero_grad()\n",
        " \n",
        "          #backward pass (compute gradients)\n",
        "          loss.backward()\n",
        " \n",
        "          #use the computed gradients to update model weights\n",
        "          optimizer.step()\n",
        " \n",
        "          print('Train loss: '+str(loss.to('cpu').detach()))\n",
        "      # model.eval()\n",
        "      #add back if doing fractional training\n",
        "      val_loader.dataset.dataset.transform=False\n",
        "      current_loss=0\n",
        "      \n",
        "      #test on val set and save the best checkpoint\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device=device, dtype=torch.float32)\n",
        "            masks = masks.to(device=device, dtype=torch.float32)\n",
        "            preds=model(images)['out'].cuda()\n",
        "            # print(preds)\n",
        "            # print(masks)\n",
        "            loss=criterion(preds, masks)\n",
        "            #print('hi')\n",
        "            current_loss+=loss.to('cpu').detach()\n",
        "            del images, masks, preds, loss\n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!Re-name model here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!        \n",
        "      if best_loss>current_loss:\n",
        "          best_loss=current_loss\n",
        "          print('Best Model Saved!, loss: '+ str(best_loss))\n",
        "          torch.save(model.state_dict(), dir_checkpoint+model_group + current_model_name+str(i+1)+\".pth\")\n",
        "      else:\n",
        "          print('Model is bad!, Current loss: '+ str(current_loss) + ' Best loss: '+str(best_loss))\n",
        "      print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fcn_resnet101_coco-7ecb50ca.pth\" to /root/.cache/torch/hub/checkpoints/fcn_resnet101_coco-7ecb50ca.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "209affe71dce4ff59cde91b2d8a0a52d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/208M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.9\n",
            "Epoch:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train loss: tensor(0.1209)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.1281)\n",
            "Train loss: tensor(0.1079)\n",
            "Train loss: tensor(0.0860)\n",
            "Train loss: tensor(0.0579)\n",
            "Train loss: tensor(0.0678)\n",
            "Train loss: tensor(0.0848)\n",
            "Train loss: tensor(0.1101)\n",
            "Train loss: tensor(0.0976)\n",
            "Train loss: tensor(0.0754)\n",
            "Train loss: tensor(0.1112)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.0810)\n",
            "Train loss: tensor(0.0822)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.0929)\n",
            "Train loss: tensor(0.0920)\n",
            "Train loss: tensor(0.0753)\n",
            "Train loss: tensor(0.0982)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.0844)\n",
            "Train loss: tensor(0.0805)\n",
            "Train loss: tensor(0.0977)\n",
            "Train loss: tensor(0.0573)\n",
            "Train loss: tensor(0.0933)\n",
            "Train loss: tensor(0.1038)\n",
            "Train loss: tensor(0.1210)\n",
            "Model is bad!, Current loss: tensor(3.7294) Best loss: tensor(1.8624)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  92\n",
            "Train loss: tensor(0.0879)\n",
            "Train loss: tensor(0.0827)\n",
            "Train loss: tensor(0.0864)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.0693)\n",
            "Train loss: tensor(0.0764)\n",
            "Train loss: tensor(0.0807)\n",
            "Train loss: tensor(0.0543)\n",
            "Train loss: tensor(0.0903)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.0574)\n",
            "Train loss: tensor(0.0876)\n",
            "Train loss: tensor(0.0801)\n",
            "Train loss: tensor(0.0799)\n",
            "Train loss: tensor(0.0929)\n",
            "Train loss: tensor(0.0651)\n",
            "Train loss: tensor(0.0864)\n",
            "Train loss: tensor(0.1176)\n",
            "Train loss: tensor(0.0924)\n",
            "Train loss: tensor(0.1172)\n",
            "Train loss: tensor(0.1159)\n",
            "Train loss: tensor(0.1072)\n",
            "Train loss: tensor(0.0879)\n",
            "Train loss: tensor(0.0723)\n",
            "Train loss: tensor(0.0603)\n",
            "Train loss: tensor(0.0935)\n",
            "Train loss: tensor(0.0799)\n",
            "Train loss: tensor(0.0987)\n",
            "Train loss: tensor(0.1458)\n",
            "Train loss: tensor(0.0761)\n",
            "Train loss: tensor(0.0865)\n",
            "Train loss: tensor(0.0824)\n",
            "Train loss: tensor(0.0878)\n",
            "Train loss: tensor(0.1487)\n",
            "Train loss: tensor(0.0857)\n",
            "Train loss: tensor(0.1323)\n",
            "Train loss: tensor(0.0978)\n",
            "Train loss: tensor(0.0839)\n",
            "Train loss: tensor(0.1183)\n",
            "Train loss: tensor(0.1160)\n",
            "Model is bad!, Current loss: tensor(7.6323) Best loss: tensor(1.8624)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  93\n",
            "Train loss: tensor(0.1099)\n",
            "Train loss: tensor(0.1561)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.0869)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0742)\n",
            "Train loss: tensor(0.0720)\n",
            "Train loss: tensor(0.0956)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.0840)\n",
            "Train loss: tensor(0.1080)\n",
            "Train loss: tensor(0.0690)\n",
            "Train loss: tensor(0.1051)\n",
            "Train loss: tensor(0.0939)\n",
            "Train loss: tensor(0.0948)\n",
            "Train loss: tensor(0.0573)\n",
            "Train loss: tensor(0.0760)\n",
            "Train loss: tensor(0.0587)\n",
            "Train loss: tensor(0.0890)\n",
            "Train loss: tensor(0.1028)\n",
            "Train loss: tensor(0.1335)\n",
            "Train loss: tensor(0.0566)\n",
            "Train loss: tensor(0.0829)\n",
            "Train loss: tensor(0.0788)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.0993)\n",
            "Train loss: tensor(0.0920)\n",
            "Train loss: tensor(0.1052)\n",
            "Train loss: tensor(0.0872)\n",
            "Train loss: tensor(0.1574)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.1102)\n",
            "Train loss: tensor(0.0797)\n",
            "Train loss: tensor(0.0881)\n",
            "Train loss: tensor(0.0872)\n",
            "Train loss: tensor(0.0731)\n",
            "Train loss: tensor(0.0702)\n",
            "Train loss: tensor(0.1242)\n",
            "Train loss: tensor(0.0779)\n",
            "Train loss: tensor(0.0858)\n",
            "Model is bad!, Current loss: tensor(13.7610) Best loss: tensor(1.8624)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  94\n",
            "Train loss: tensor(0.1252)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.0585)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0690)\n",
            "Train loss: tensor(0.0920)\n",
            "Train loss: tensor(0.0664)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.1079)\n",
            "Train loss: tensor(0.1131)\n",
            "Train loss: tensor(0.0750)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.1234)\n",
            "Train loss: tensor(0.1071)\n",
            "Train loss: tensor(0.0850)\n",
            "Train loss: tensor(0.0937)\n",
            "Train loss: tensor(0.0886)\n",
            "Train loss: tensor(0.0736)\n",
            "Train loss: tensor(0.0800)\n",
            "Train loss: tensor(0.0779)\n",
            "Train loss: tensor(0.1090)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.1174)\n",
            "Train loss: tensor(0.0831)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.1375)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.0620)\n",
            "Train loss: tensor(0.0795)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.0950)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.1181)\n",
            "Train loss: tensor(0.1068)\n",
            "Train loss: tensor(0.0830)\n",
            "Train loss: tensor(0.0870)\n",
            "Train loss: tensor(0.0984)\n",
            "Train loss: tensor(0.0903)\n",
            "Train loss: tensor(0.0878)\n",
            "Model is bad!, Current loss: tensor(9.6683) Best loss: tensor(1.8624)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  95\n",
            "Train loss: tensor(0.0914)\n",
            "Train loss: tensor(0.1036)\n",
            "Train loss: tensor(0.1160)\n",
            "Train loss: tensor(0.0726)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.1085)\n",
            "Train loss: tensor(0.0852)\n",
            "Train loss: tensor(0.1169)\n",
            "Train loss: tensor(0.1125)\n",
            "Train loss: tensor(0.0853)\n",
            "Train loss: tensor(0.1189)\n",
            "Train loss: tensor(0.0891)\n",
            "Train loss: tensor(0.0807)\n",
            "Train loss: tensor(0.0617)\n",
            "Train loss: tensor(0.1000)\n",
            "Train loss: tensor(0.0881)\n",
            "Train loss: tensor(0.0685)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.0701)\n",
            "Train loss: tensor(0.0691)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.1029)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.0859)\n",
            "Train loss: tensor(0.0757)\n",
            "Train loss: tensor(0.0617)\n",
            "Train loss: tensor(0.0992)\n",
            "Train loss: tensor(0.0755)\n",
            "Train loss: tensor(0.1123)\n",
            "Train loss: tensor(0.0706)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.0859)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0828)\n",
            "Train loss: tensor(0.0703)\n",
            "Train loss: tensor(0.1001)\n",
            "Train loss: tensor(0.0576)\n",
            "Train loss: tensor(0.0764)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0792)\n",
            "Model is bad!, Current loss: tensor(8.1055) Best loss: tensor(1.8624)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  96\n",
            "Train loss: tensor(0.0683)\n",
            "Train loss: tensor(0.0715)\n",
            "Train loss: tensor(0.1131)\n",
            "Train loss: tensor(0.0822)\n",
            "Train loss: tensor(0.0848)\n",
            "Train loss: tensor(0.0585)\n",
            "Train loss: tensor(0.0774)\n",
            "Train loss: tensor(0.0639)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.1071)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.0805)\n",
            "Train loss: tensor(0.1335)\n",
            "Train loss: tensor(0.0910)\n",
            "Train loss: tensor(0.0696)\n",
            "Train loss: tensor(0.0847)\n",
            "Train loss: tensor(0.0886)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.0579)\n",
            "Train loss: tensor(0.0629)\n",
            "Train loss: tensor(0.0617)\n",
            "Train loss: tensor(0.0773)\n",
            "Train loss: tensor(0.0869)\n",
            "Train loss: tensor(0.0584)\n",
            "Train loss: tensor(0.0789)\n",
            "Train loss: tensor(0.0852)\n",
            "Train loss: tensor(0.0810)\n",
            "Train loss: tensor(0.0807)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.0890)\n",
            "Train loss: tensor(0.0839)\n",
            "Train loss: tensor(0.0688)\n",
            "Train loss: tensor(0.0774)\n",
            "Train loss: tensor(0.0735)\n",
            "Train loss: tensor(0.1299)\n",
            "Train loss: tensor(0.0675)\n",
            "Train loss: tensor(0.0962)\n",
            "Train loss: tensor(0.0690)\n",
            "Model is bad!, Current loss: tensor(6.4736) Best loss: tensor(1.8624)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  97\n",
            "Train loss: tensor(0.0753)\n",
            "Train loss: tensor(0.0636)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.0728)\n",
            "Train loss: tensor(0.0967)\n",
            "Train loss: tensor(0.0825)\n",
            "Train loss: tensor(0.1228)\n",
            "Train loss: tensor(0.0863)\n",
            "Train loss: tensor(0.0873)\n",
            "Train loss: tensor(0.0599)\n",
            "Train loss: tensor(0.0727)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.0760)\n",
            "Train loss: tensor(0.1035)\n",
            "Train loss: tensor(0.0811)\n",
            "Train loss: tensor(0.0942)\n",
            "Train loss: tensor(0.0857)\n",
            "Train loss: tensor(0.0703)\n",
            "Train loss: tensor(0.0859)\n",
            "Train loss: tensor(0.0706)\n",
            "Train loss: tensor(0.0792)\n",
            "Train loss: tensor(0.0788)\n",
            "Train loss: tensor(0.0688)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.0538)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.0690)\n",
            "Train loss: tensor(0.0707)\n",
            "Train loss: tensor(0.0568)\n",
            "Train loss: tensor(0.0651)\n",
            "Train loss: tensor(0.0897)\n",
            "Train loss: tensor(0.0744)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.1081)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.0854)\n",
            "Train loss: tensor(0.0797)\n",
            "Train loss: tensor(0.0686)\n",
            "Train loss: tensor(0.0572)\n",
            "Model is bad!, Current loss: tensor(8.1719) Best loss: tensor(1.8624)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  98\n",
            "Train loss: tensor(0.1260)\n",
            "Train loss: tensor(0.0747)\n",
            "Train loss: tensor(0.0881)\n",
            "Train loss: tensor(0.0660)\n",
            "Train loss: tensor(0.0739)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0655)\n",
            "Train loss: tensor(0.0660)\n",
            "Train loss: tensor(0.0906)\n",
            "Train loss: tensor(0.0641)\n",
            "Train loss: tensor(0.0821)\n",
            "Train loss: tensor(0.0544)\n",
            "Train loss: tensor(0.0974)\n",
            "Train loss: tensor(0.0750)\n",
            "Train loss: tensor(0.0698)\n",
            "Train loss: tensor(0.0724)\n",
            "Train loss: tensor(0.0785)\n",
            "Train loss: tensor(0.0600)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.0686)\n",
            "Train loss: tensor(0.1000)\n",
            "Train loss: tensor(0.0601)\n",
            "Train loss: tensor(0.0764)\n",
            "Train loss: tensor(0.0994)\n",
            "Train loss: tensor(0.0881)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.0919)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.1018)\n",
            "Train loss: tensor(0.0705)\n",
            "Train loss: tensor(0.0802)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.0752)\n",
            "Train loss: tensor(0.0730)\n",
            "Train loss: tensor(0.0746)\n",
            "Train loss: tensor(0.0742)\n",
            "Train loss: tensor(0.0713)\n",
            "Train loss: tensor(0.1013)\n",
            "Train loss: tensor(0.0549)\n",
            "Model is bad!, Current loss: tensor(8.2658) Best loss: tensor(1.8624)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  99\n",
            "Train loss: tensor(0.0765)\n",
            "Train loss: tensor(0.0912)\n",
            "Train loss: tensor(0.0543)\n",
            "Train loss: tensor(0.0791)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.0727)\n",
            "Train loss: tensor(0.0663)\n",
            "Train loss: tensor(0.0783)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.0557)\n",
            "Train loss: tensor(0.0807)\n",
            "Train loss: tensor(0.0859)\n",
            "Train loss: tensor(0.0941)\n",
            "Train loss: tensor(0.0994)\n",
            "Train loss: tensor(0.0649)\n",
            "Train loss: tensor(0.0779)\n",
            "Train loss: tensor(0.0552)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.1062)\n",
            "Train loss: tensor(0.0748)\n",
            "Train loss: tensor(0.0782)\n",
            "Train loss: tensor(0.0810)\n",
            "Train loss: tensor(0.0747)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.0686)\n",
            "Train loss: tensor(0.0783)\n",
            "Train loss: tensor(0.0640)\n",
            "Train loss: tensor(0.0564)\n",
            "Train loss: tensor(0.1084)\n",
            "Train loss: tensor(0.0827)\n",
            "Train loss: tensor(0.0888)\n",
            "Train loss: tensor(0.0744)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.1022)\n",
            "Train loss: tensor(0.0912)\n",
            "Train loss: tensor(0.0703)\n",
            "Train loss: tensor(0.0938)\n",
            "Train loss: tensor(0.0709)\n",
            "Train loss: tensor(0.0784)\n",
            "Train loss: tensor(0.0694)\n",
            "Train loss: tensor(0.0897)\n",
            "Model is bad!, Current loss: tensor(8.4769) Best loss: tensor(1.8624)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  0\n",
            "Train loss: tensor(0.6785)\n",
            "Train loss: tensor(0.6317)\n",
            "Train loss: tensor(0.6162)\n",
            "Train loss: tensor(0.5026)\n",
            "Train loss: tensor(0.5290)\n",
            "Train loss: tensor(0.4656)\n",
            "Train loss: tensor(0.3250)\n",
            "Train loss: tensor(0.2968)\n",
            "Train loss: tensor(0.2831)\n",
            "Train loss: tensor(0.2507)\n",
            "Train loss: tensor(0.2457)\n",
            "Train loss: tensor(0.2960)\n",
            "Train loss: tensor(0.2183)\n",
            "Train loss: tensor(0.4115)\n",
            "Train loss: tensor(0.4449)\n",
            "Train loss: tensor(0.2547)\n",
            "Train loss: tensor(0.2459)\n",
            "Train loss: tensor(0.4940)\n",
            "Train loss: tensor(0.3828)\n",
            "Train loss: tensor(0.3894)\n",
            "Train loss: tensor(0.2743)\n",
            "Train loss: tensor(0.2292)\n",
            "Train loss: tensor(0.5014)\n",
            "Train loss: tensor(0.2236)\n",
            "Train loss: tensor(0.2239)\n",
            "Train loss: tensor(0.2046)\n",
            "Train loss: tensor(0.2193)\n",
            "Train loss: tensor(0.2214)\n",
            "Train loss: tensor(0.2391)\n",
            "Train loss: tensor(0.2589)\n",
            "Train loss: tensor(0.2878)\n",
            "Train loss: tensor(0.2091)\n",
            "Train loss: tensor(0.2036)\n",
            "Train loss: tensor(0.2313)\n",
            "Train loss: tensor(0.2205)\n",
            "Train loss: tensor(0.1849)\n",
            "Train loss: tensor(0.2159)\n",
            "Train loss: tensor(0.2433)\n",
            "Train loss: tensor(0.3672)\n",
            "Train loss: tensor(0.2101)\n",
            "Train loss: tensor(0.1656)\n",
            "Best Model Saved!, loss: tensor(3.6571)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  1\n",
            "Train loss: tensor(0.2149)\n",
            "Train loss: tensor(0.1851)\n",
            "Train loss: tensor(0.1772)\n",
            "Train loss: tensor(0.2202)\n",
            "Train loss: tensor(0.2113)\n",
            "Train loss: tensor(0.1674)\n",
            "Train loss: tensor(0.1762)\n",
            "Train loss: tensor(0.1831)\n",
            "Train loss: tensor(0.2080)\n",
            "Train loss: tensor(0.2377)\n",
            "Train loss: tensor(0.1536)\n",
            "Train loss: tensor(0.1640)\n",
            "Train loss: tensor(0.2659)\n",
            "Train loss: tensor(0.1604)\n",
            "Train loss: tensor(0.1660)\n",
            "Train loss: tensor(0.1972)\n",
            "Train loss: tensor(0.2096)\n",
            "Train loss: tensor(0.1910)\n",
            "Train loss: tensor(0.2472)\n",
            "Train loss: tensor(0.2100)\n",
            "Train loss: tensor(0.1706)\n",
            "Train loss: tensor(0.2275)\n",
            "Train loss: tensor(0.2185)\n",
            "Train loss: tensor(0.1647)\n",
            "Train loss: tensor(0.1715)\n",
            "Train loss: tensor(0.2508)\n",
            "Train loss: tensor(0.1569)\n",
            "Train loss: tensor(0.2428)\n",
            "Train loss: tensor(0.2599)\n",
            "Train loss: tensor(0.2671)\n",
            "Train loss: tensor(0.1951)\n",
            "Train loss: tensor(0.1603)\n",
            "Train loss: tensor(0.1622)\n",
            "Train loss: tensor(0.1654)\n",
            "Train loss: tensor(0.1592)\n",
            "Train loss: tensor(0.2656)\n",
            "Train loss: tensor(0.1548)\n",
            "Train loss: tensor(0.1974)\n",
            "Train loss: tensor(0.2023)\n",
            "Train loss: tensor(0.1370)\n",
            "Train loss: tensor(0.2207)\n",
            "Best Model Saved!, loss: tensor(1.7678)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  2\n",
            "Train loss: tensor(0.1508)\n",
            "Train loss: tensor(0.1369)\n",
            "Train loss: tensor(0.1946)\n",
            "Train loss: tensor(0.1631)\n",
            "Train loss: tensor(0.1739)\n",
            "Train loss: tensor(0.1745)\n",
            "Train loss: tensor(0.1981)\n",
            "Train loss: tensor(0.1297)\n",
            "Train loss: tensor(0.2448)\n",
            "Train loss: tensor(0.1290)\n",
            "Train loss: tensor(0.1446)\n",
            "Train loss: tensor(0.1294)\n",
            "Train loss: tensor(0.1366)\n",
            "Train loss: tensor(0.1878)\n",
            "Train loss: tensor(0.2053)\n",
            "Train loss: tensor(0.1924)\n",
            "Train loss: tensor(0.1276)\n",
            "Train loss: tensor(0.1721)\n",
            "Train loss: tensor(0.1359)\n",
            "Train loss: tensor(0.1476)\n",
            "Train loss: tensor(0.1452)\n",
            "Train loss: tensor(0.1236)\n",
            "Train loss: tensor(0.1497)\n",
            "Train loss: tensor(0.1428)\n",
            "Train loss: tensor(0.1252)\n",
            "Train loss: tensor(0.2946)\n",
            "Train loss: tensor(0.1852)\n",
            "Train loss: tensor(0.1390)\n",
            "Train loss: tensor(0.1229)\n",
            "Train loss: tensor(0.3004)\n",
            "Train loss: tensor(0.1211)\n",
            "Train loss: tensor(0.2452)\n",
            "Train loss: tensor(0.1784)\n",
            "Train loss: tensor(0.1578)\n",
            "Train loss: tensor(0.2169)\n",
            "Train loss: tensor(0.1239)\n",
            "Train loss: tensor(0.2204)\n",
            "Train loss: tensor(0.3846)\n",
            "Train loss: tensor(0.1657)\n",
            "Train loss: tensor(0.1566)\n",
            "Train loss: tensor(0.1401)\n",
            "Model is bad!, Current loss: tensor(4.5601) Best loss: tensor(1.7678)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  3\n",
            "Train loss: tensor(0.1837)\n",
            "Train loss: tensor(0.1677)\n",
            "Train loss: tensor(0.1517)\n",
            "Train loss: tensor(0.1760)\n",
            "Train loss: tensor(0.2647)\n",
            "Train loss: tensor(0.1461)\n",
            "Train loss: tensor(0.1585)\n",
            "Train loss: tensor(0.1268)\n",
            "Train loss: tensor(0.1760)\n",
            "Train loss: tensor(0.1261)\n",
            "Train loss: tensor(0.1179)\n",
            "Train loss: tensor(0.1699)\n",
            "Train loss: tensor(0.2562)\n",
            "Train loss: tensor(0.1806)\n",
            "Train loss: tensor(0.1355)\n",
            "Train loss: tensor(0.1420)\n",
            "Train loss: tensor(0.1952)\n",
            "Train loss: tensor(0.2024)\n",
            "Train loss: tensor(0.1235)\n",
            "Train loss: tensor(0.1178)\n",
            "Train loss: tensor(0.1555)\n",
            "Train loss: tensor(0.2025)\n",
            "Train loss: tensor(0.2368)\n",
            "Train loss: tensor(0.1207)\n",
            "Train loss: tensor(0.1223)\n",
            "Train loss: tensor(0.1179)\n",
            "Train loss: tensor(0.1398)\n",
            "Train loss: tensor(0.1814)\n",
            "Train loss: tensor(0.1311)\n",
            "Train loss: tensor(0.2108)\n",
            "Train loss: tensor(0.1291)\n",
            "Train loss: tensor(0.1524)\n",
            "Train loss: tensor(0.2209)\n",
            "Train loss: tensor(0.1309)\n",
            "Train loss: tensor(0.1953)\n",
            "Train loss: tensor(0.1321)\n",
            "Train loss: tensor(0.1182)\n",
            "Train loss: tensor(0.1330)\n",
            "Train loss: tensor(0.1596)\n",
            "Train loss: tensor(0.1356)\n",
            "Train loss: tensor(0.1705)\n",
            "Best Model Saved!, loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  4\n",
            "Train loss: tensor(0.1693)\n",
            "Train loss: tensor(0.2069)\n",
            "Train loss: tensor(0.1117)\n",
            "Train loss: tensor(0.1213)\n",
            "Train loss: tensor(0.1707)\n",
            "Train loss: tensor(0.1357)\n",
            "Train loss: tensor(0.1645)\n",
            "Train loss: tensor(0.1515)\n",
            "Train loss: tensor(0.2243)\n",
            "Train loss: tensor(0.1212)\n",
            "Train loss: tensor(0.1763)\n",
            "Train loss: tensor(0.1025)\n",
            "Train loss: tensor(0.1877)\n",
            "Train loss: tensor(0.1465)\n",
            "Train loss: tensor(0.1496)\n",
            "Train loss: tensor(0.1447)\n",
            "Train loss: tensor(0.3033)\n",
            "Train loss: tensor(0.1808)\n",
            "Train loss: tensor(0.1339)\n",
            "Train loss: tensor(0.1234)\n",
            "Train loss: tensor(0.1659)\n",
            "Train loss: tensor(0.1312)\n",
            "Train loss: tensor(0.1285)\n",
            "Train loss: tensor(0.1343)\n",
            "Train loss: tensor(0.1495)\n",
            "Train loss: tensor(0.2148)\n",
            "Train loss: tensor(0.2198)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.1928)\n",
            "Train loss: tensor(0.1002)\n",
            "Train loss: tensor(0.1417)\n",
            "Train loss: tensor(0.1416)\n",
            "Train loss: tensor(0.3096)\n",
            "Train loss: tensor(0.1211)\n",
            "Train loss: tensor(0.1181)\n",
            "Train loss: tensor(0.1145)\n",
            "Train loss: tensor(0.1307)\n",
            "Train loss: tensor(0.1262)\n",
            "Train loss: tensor(0.1127)\n",
            "Train loss: tensor(0.1737)\n",
            "Train loss: tensor(0.1617)\n",
            "Model is bad!, Current loss: tensor(1.8266) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  5\n",
            "Train loss: tensor(0.1653)\n",
            "Train loss: tensor(0.1131)\n",
            "Train loss: tensor(0.1147)\n",
            "Train loss: tensor(0.2390)\n",
            "Train loss: tensor(0.1388)\n",
            "Train loss: tensor(0.1648)\n",
            "Train loss: tensor(0.2270)\n",
            "Train loss: tensor(0.1216)\n",
            "Train loss: tensor(0.1193)\n",
            "Train loss: tensor(0.2488)\n",
            "Train loss: tensor(0.1247)\n",
            "Train loss: tensor(0.1503)\n",
            "Train loss: tensor(0.2586)\n",
            "Train loss: tensor(0.1705)\n",
            "Train loss: tensor(0.1543)\n",
            "Train loss: tensor(0.1380)\n",
            "Train loss: tensor(0.1155)\n",
            "Train loss: tensor(0.1370)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.1322)\n",
            "Train loss: tensor(0.1122)\n",
            "Train loss: tensor(0.2038)\n",
            "Train loss: tensor(0.2036)\n",
            "Train loss: tensor(0.1112)\n",
            "Train loss: tensor(0.1206)\n",
            "Train loss: tensor(0.1376)\n",
            "Train loss: tensor(0.1287)\n",
            "Train loss: tensor(0.1637)\n",
            "Train loss: tensor(0.1153)\n",
            "Train loss: tensor(0.2195)\n",
            "Train loss: tensor(0.1080)\n",
            "Train loss: tensor(0.1639)\n",
            "Train loss: tensor(0.1262)\n",
            "Train loss: tensor(0.1401)\n",
            "Train loss: tensor(0.1736)\n",
            "Train loss: tensor(0.1071)\n",
            "Train loss: tensor(0.1630)\n",
            "Train loss: tensor(0.2083)\n",
            "Train loss: tensor(0.1036)\n",
            "Train loss: tensor(0.1254)\n",
            "Train loss: tensor(0.1306)\n",
            "Model is bad!, Current loss: tensor(2.7141) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  6\n",
            "Train loss: tensor(0.1253)\n",
            "Train loss: tensor(0.1277)\n",
            "Train loss: tensor(0.1175)\n",
            "Train loss: tensor(0.1747)\n",
            "Train loss: tensor(0.1017)\n",
            "Train loss: tensor(0.2440)\n",
            "Train loss: tensor(0.1445)\n",
            "Train loss: tensor(0.1085)\n",
            "Train loss: tensor(0.1608)\n",
            "Train loss: tensor(0.1194)\n",
            "Train loss: tensor(0.1249)\n",
            "Train loss: tensor(0.1531)\n",
            "Train loss: tensor(0.1170)\n",
            "Train loss: tensor(0.1095)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.2062)\n",
            "Train loss: tensor(0.1213)\n",
            "Train loss: tensor(0.1244)\n",
            "Train loss: tensor(0.1090)\n",
            "Train loss: tensor(0.1270)\n",
            "Train loss: tensor(0.1154)\n",
            "Train loss: tensor(0.1516)\n",
            "Train loss: tensor(0.1372)\n",
            "Train loss: tensor(0.1052)\n",
            "Train loss: tensor(0.1407)\n",
            "Train loss: tensor(0.1544)\n",
            "Train loss: tensor(0.2021)\n",
            "Train loss: tensor(0.1255)\n",
            "Train loss: tensor(0.1112)\n",
            "Train loss: tensor(0.1183)\n",
            "Train loss: tensor(0.1116)\n",
            "Train loss: tensor(0.1107)\n",
            "Train loss: tensor(0.1020)\n",
            "Train loss: tensor(0.1197)\n",
            "Train loss: tensor(0.0855)\n",
            "Train loss: tensor(0.1941)\n",
            "Train loss: tensor(0.2118)\n",
            "Train loss: tensor(0.1523)\n",
            "Train loss: tensor(0.1404)\n",
            "Train loss: tensor(0.1961)\n",
            "Train loss: tensor(0.1694)\n",
            "Model is bad!, Current loss: tensor(4.4582) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  7\n",
            "Train loss: tensor(0.1203)\n",
            "Train loss: tensor(0.1656)\n",
            "Train loss: tensor(0.1318)\n",
            "Train loss: tensor(0.2477)\n",
            "Train loss: tensor(0.1633)\n",
            "Train loss: tensor(0.1197)\n",
            "Train loss: tensor(0.1497)\n",
            "Train loss: tensor(0.1237)\n",
            "Train loss: tensor(0.1338)\n",
            "Train loss: tensor(0.3145)\n",
            "Train loss: tensor(0.1327)\n",
            "Train loss: tensor(0.1146)\n",
            "Train loss: tensor(0.2120)\n",
            "Train loss: tensor(0.2417)\n",
            "Train loss: tensor(0.1124)\n",
            "Train loss: tensor(0.1240)\n",
            "Train loss: tensor(0.1093)\n",
            "Train loss: tensor(0.1955)\n",
            "Train loss: tensor(0.1335)\n",
            "Train loss: tensor(0.1422)\n",
            "Train loss: tensor(0.1026)\n",
            "Train loss: tensor(0.1548)\n",
            "Train loss: tensor(0.1652)\n",
            "Train loss: tensor(0.1172)\n",
            "Train loss: tensor(0.1270)\n",
            "Train loss: tensor(0.1158)\n",
            "Train loss: tensor(0.1251)\n",
            "Train loss: tensor(0.1139)\n",
            "Train loss: tensor(0.1295)\n",
            "Train loss: tensor(0.1895)\n",
            "Train loss: tensor(0.1206)\n",
            "Train loss: tensor(0.1097)\n",
            "Train loss: tensor(0.1337)\n",
            "Train loss: tensor(0.1514)\n",
            "Train loss: tensor(0.2091)\n",
            "Train loss: tensor(0.1646)\n",
            "Train loss: tensor(0.1435)\n",
            "Train loss: tensor(0.1222)\n",
            "Train loss: tensor(0.1716)\n",
            "Train loss: tensor(0.2066)\n",
            "Train loss: tensor(0.1408)\n",
            "Model is bad!, Current loss: tensor(4.5244) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  8\n",
            "Train loss: tensor(0.1100)\n",
            "Train loss: tensor(0.1674)\n",
            "Train loss: tensor(0.1265)\n",
            "Train loss: tensor(0.1159)\n",
            "Train loss: tensor(0.1560)\n",
            "Train loss: tensor(0.1112)\n",
            "Train loss: tensor(0.1402)\n",
            "Train loss: tensor(0.1452)\n",
            "Train loss: tensor(0.1109)\n",
            "Train loss: tensor(0.1274)\n",
            "Train loss: tensor(0.1265)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.0973)\n",
            "Train loss: tensor(0.1096)\n",
            "Train loss: tensor(0.1165)\n",
            "Train loss: tensor(0.1963)\n",
            "Train loss: tensor(0.2510)\n",
            "Train loss: tensor(0.1100)\n",
            "Train loss: tensor(0.1822)\n",
            "Train loss: tensor(0.1715)\n",
            "Train loss: tensor(0.1359)\n",
            "Train loss: tensor(0.1343)\n",
            "Train loss: tensor(0.1510)\n",
            "Train loss: tensor(0.1555)\n",
            "Train loss: tensor(0.1184)\n",
            "Train loss: tensor(0.1108)\n",
            "Train loss: tensor(0.0999)\n",
            "Train loss: tensor(0.1321)\n",
            "Train loss: tensor(0.1190)\n",
            "Train loss: tensor(0.1319)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0954)\n",
            "Train loss: tensor(0.1393)\n",
            "Train loss: tensor(0.1606)\n",
            "Train loss: tensor(0.1730)\n",
            "Train loss: tensor(0.1094)\n",
            "Train loss: tensor(0.1014)\n",
            "Train loss: tensor(0.1114)\n",
            "Train loss: tensor(0.1618)\n",
            "Train loss: tensor(0.2957)\n",
            "Train loss: tensor(0.1312)\n",
            "Model is bad!, Current loss: tensor(2.6129) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  9\n",
            "Train loss: tensor(0.1568)\n",
            "Train loss: tensor(0.1526)\n",
            "Train loss: tensor(0.2037)\n",
            "Train loss: tensor(0.1263)\n",
            "Train loss: tensor(0.1298)\n",
            "Train loss: tensor(0.1216)\n",
            "Train loss: tensor(0.0937)\n",
            "Train loss: tensor(0.1914)\n",
            "Train loss: tensor(0.1979)\n",
            "Train loss: tensor(0.1206)\n",
            "Train loss: tensor(0.1457)\n",
            "Train loss: tensor(0.1166)\n",
            "Train loss: tensor(0.1480)\n",
            "Train loss: tensor(0.1344)\n",
            "Train loss: tensor(0.1978)\n",
            "Train loss: tensor(0.2163)\n",
            "Train loss: tensor(0.1230)\n",
            "Train loss: tensor(0.1295)\n",
            "Train loss: tensor(0.1876)\n",
            "Train loss: tensor(0.1123)\n",
            "Train loss: tensor(0.1051)\n",
            "Train loss: tensor(0.1315)\n",
            "Train loss: tensor(0.2228)\n",
            "Train loss: tensor(0.1579)\n",
            "Train loss: tensor(0.1200)\n",
            "Train loss: tensor(0.0835)\n",
            "Train loss: tensor(0.1705)\n",
            "Train loss: tensor(0.3289)\n",
            "Train loss: tensor(0.1456)\n",
            "Train loss: tensor(0.1524)\n",
            "Train loss: tensor(0.1250)\n",
            "Train loss: tensor(0.1177)\n",
            "Train loss: tensor(0.1170)\n",
            "Train loss: tensor(0.1086)\n",
            "Train loss: tensor(0.1409)\n",
            "Train loss: tensor(0.1690)\n",
            "Train loss: tensor(0.1283)\n",
            "Train loss: tensor(0.1281)\n",
            "Train loss: tensor(0.1254)\n",
            "Train loss: tensor(0.1178)\n",
            "Train loss: tensor(0.1538)\n",
            "Model is bad!, Current loss: tensor(3.5547) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  10\n",
            "Train loss: tensor(0.2115)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.1007)\n",
            "Train loss: tensor(0.1836)\n",
            "Train loss: tensor(0.1287)\n",
            "Train loss: tensor(0.1376)\n",
            "Train loss: tensor(0.1057)\n",
            "Train loss: tensor(0.2204)\n",
            "Train loss: tensor(0.2767)\n",
            "Train loss: tensor(0.1354)\n",
            "Train loss: tensor(0.1608)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.1865)\n",
            "Train loss: tensor(0.1523)\n",
            "Train loss: tensor(0.2156)\n",
            "Train loss: tensor(0.1175)\n",
            "Train loss: tensor(0.1469)\n",
            "Train loss: tensor(0.1254)\n",
            "Train loss: tensor(0.1312)\n",
            "Train loss: tensor(0.1490)\n",
            "Train loss: tensor(0.1570)\n",
            "Train loss: tensor(0.1106)\n",
            "Train loss: tensor(0.1713)\n",
            "Train loss: tensor(0.1039)\n",
            "Train loss: tensor(0.1204)\n",
            "Train loss: tensor(0.1114)\n",
            "Train loss: tensor(0.1457)\n",
            "Train loss: tensor(0.2089)\n",
            "Train loss: tensor(0.1305)\n",
            "Train loss: tensor(0.1130)\n",
            "Train loss: tensor(0.1099)\n",
            "Train loss: tensor(0.1173)\n",
            "Train loss: tensor(0.1605)\n",
            "Train loss: tensor(0.1119)\n",
            "Train loss: tensor(0.1097)\n",
            "Train loss: tensor(0.1392)\n",
            "Train loss: tensor(0.1847)\n",
            "Train loss: tensor(0.1681)\n",
            "Train loss: tensor(0.1478)\n",
            "Train loss: tensor(0.1819)\n",
            "Train loss: tensor(0.1155)\n",
            "Model is bad!, Current loss: tensor(3.0523) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  11\n",
            "Train loss: tensor(0.1385)\n",
            "Train loss: tensor(0.1710)\n",
            "Train loss: tensor(0.1505)\n",
            "Train loss: tensor(0.1620)\n",
            "Train loss: tensor(0.1586)\n",
            "Train loss: tensor(0.1276)\n",
            "Train loss: tensor(0.1604)\n",
            "Train loss: tensor(0.1258)\n",
            "Train loss: tensor(0.1148)\n",
            "Train loss: tensor(0.1272)\n",
            "Train loss: tensor(0.1703)\n",
            "Train loss: tensor(0.0969)\n",
            "Train loss: tensor(0.1165)\n",
            "Train loss: tensor(0.1040)\n",
            "Train loss: tensor(0.1236)\n",
            "Train loss: tensor(0.1213)\n",
            "Train loss: tensor(0.1589)\n",
            "Train loss: tensor(0.1377)\n",
            "Train loss: tensor(0.1145)\n",
            "Train loss: tensor(0.1514)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.1156)\n",
            "Train loss: tensor(0.1168)\n",
            "Train loss: tensor(0.1768)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.1268)\n",
            "Train loss: tensor(0.1508)\n",
            "Train loss: tensor(0.1289)\n",
            "Train loss: tensor(0.1160)\n",
            "Train loss: tensor(0.1475)\n",
            "Train loss: tensor(0.1128)\n",
            "Train loss: tensor(0.1129)\n",
            "Train loss: tensor(0.1229)\n",
            "Train loss: tensor(0.0995)\n",
            "Train loss: tensor(0.1195)\n",
            "Train loss: tensor(0.0974)\n",
            "Train loss: tensor(0.0956)\n",
            "Train loss: tensor(0.1605)\n",
            "Train loss: tensor(0.1364)\n",
            "Train loss: tensor(0.0995)\n",
            "Model is bad!, Current loss: tensor(2.2437) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  12\n",
            "Train loss: tensor(0.1863)\n",
            "Train loss: tensor(0.2343)\n",
            "Train loss: tensor(0.0959)\n",
            "Train loss: tensor(0.1105)\n",
            "Train loss: tensor(0.1389)\n",
            "Train loss: tensor(0.0986)\n",
            "Train loss: tensor(0.1006)\n",
            "Train loss: tensor(0.1921)\n",
            "Train loss: tensor(0.1164)\n",
            "Train loss: tensor(0.1297)\n",
            "Train loss: tensor(0.1191)\n",
            "Train loss: tensor(0.1053)\n",
            "Train loss: tensor(0.1241)\n",
            "Train loss: tensor(0.1541)\n",
            "Train loss: tensor(0.0808)\n",
            "Train loss: tensor(0.1197)\n",
            "Train loss: tensor(0.1109)\n",
            "Train loss: tensor(0.1108)\n",
            "Train loss: tensor(0.1430)\n",
            "Train loss: tensor(0.1943)\n",
            "Train loss: tensor(0.1099)\n",
            "Train loss: tensor(0.2190)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.1385)\n",
            "Train loss: tensor(0.1240)\n",
            "Train loss: tensor(0.1226)\n",
            "Train loss: tensor(0.1142)\n",
            "Train loss: tensor(0.0909)\n",
            "Train loss: tensor(0.1200)\n",
            "Train loss: tensor(0.1030)\n",
            "Train loss: tensor(0.1031)\n",
            "Train loss: tensor(0.1074)\n",
            "Train loss: tensor(0.1190)\n",
            "Train loss: tensor(0.1810)\n",
            "Train loss: tensor(0.1291)\n",
            "Train loss: tensor(0.1225)\n",
            "Train loss: tensor(0.0949)\n",
            "Train loss: tensor(0.1871)\n",
            "Train loss: tensor(0.1323)\n",
            "Train loss: tensor(0.1704)\n",
            "Train loss: tensor(0.1457)\n",
            "Model is bad!, Current loss: tensor(2.2371) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  13\n",
            "Train loss: tensor(0.1059)\n",
            "Train loss: tensor(0.1715)\n",
            "Train loss: tensor(0.1253)\n",
            "Train loss: tensor(0.1146)\n",
            "Train loss: tensor(0.1350)\n",
            "Train loss: tensor(0.1249)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.1652)\n",
            "Train loss: tensor(0.1032)\n",
            "Train loss: tensor(0.0812)\n",
            "Train loss: tensor(0.1221)\n",
            "Train loss: tensor(0.1333)\n",
            "Train loss: tensor(0.1154)\n",
            "Train loss: tensor(0.1283)\n",
            "Train loss: tensor(0.1300)\n",
            "Train loss: tensor(0.1589)\n",
            "Train loss: tensor(0.0798)\n",
            "Train loss: tensor(0.0906)\n",
            "Train loss: tensor(0.1070)\n",
            "Train loss: tensor(0.0916)\n",
            "Train loss: tensor(0.1206)\n",
            "Train loss: tensor(0.1107)\n",
            "Train loss: tensor(0.0944)\n",
            "Train loss: tensor(0.1040)\n",
            "Train loss: tensor(0.1558)\n",
            "Train loss: tensor(0.1213)\n",
            "Train loss: tensor(0.1061)\n",
            "Train loss: tensor(0.1347)\n",
            "Train loss: tensor(0.1278)\n",
            "Train loss: tensor(0.1323)\n",
            "Train loss: tensor(0.1369)\n",
            "Train loss: tensor(0.1469)\n",
            "Train loss: tensor(0.1361)\n",
            "Train loss: tensor(0.0776)\n",
            "Train loss: tensor(0.1855)\n",
            "Train loss: tensor(0.1115)\n",
            "Train loss: tensor(0.1193)\n",
            "Train loss: tensor(0.1058)\n",
            "Train loss: tensor(0.1745)\n",
            "Train loss: tensor(0.1504)\n",
            "Train loss: tensor(0.1075)\n",
            "Model is bad!, Current loss: tensor(2.8518) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  14\n",
            "Train loss: tensor(0.1712)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.1177)\n",
            "Train loss: tensor(0.1679)\n",
            "Train loss: tensor(0.1125)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.0938)\n",
            "Train loss: tensor(0.1014)\n",
            "Train loss: tensor(0.1159)\n",
            "Train loss: tensor(0.1076)\n",
            "Train loss: tensor(0.0860)\n",
            "Train loss: tensor(0.1177)\n",
            "Train loss: tensor(0.1244)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.1139)\n",
            "Train loss: tensor(0.1872)\n",
            "Train loss: tensor(0.1451)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.1927)\n",
            "Train loss: tensor(0.1392)\n",
            "Train loss: tensor(0.1348)\n",
            "Train loss: tensor(0.1277)\n",
            "Train loss: tensor(0.1096)\n",
            "Train loss: tensor(0.1191)\n",
            "Train loss: tensor(0.1048)\n",
            "Train loss: tensor(0.1237)\n",
            "Train loss: tensor(0.0777)\n",
            "Train loss: tensor(0.1029)\n",
            "Train loss: tensor(0.1076)\n",
            "Train loss: tensor(0.1297)\n",
            "Train loss: tensor(0.1049)\n",
            "Train loss: tensor(0.1374)\n",
            "Train loss: tensor(0.1363)\n",
            "Train loss: tensor(0.1850)\n",
            "Train loss: tensor(0.2541)\n",
            "Train loss: tensor(0.2388)\n",
            "Train loss: tensor(0.1201)\n",
            "Train loss: tensor(0.1069)\n",
            "Train loss: tensor(0.1665)\n",
            "Train loss: tensor(0.1372)\n",
            "Train loss: tensor(0.0956)\n",
            "Model is bad!, Current loss: tensor(2.7088) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  15\n",
            "Train loss: tensor(0.1592)\n",
            "Train loss: tensor(0.0950)\n",
            "Train loss: tensor(0.1022)\n",
            "Train loss: tensor(0.1451)\n",
            "Train loss: tensor(0.1378)\n",
            "Train loss: tensor(0.1387)\n",
            "Train loss: tensor(0.1165)\n",
            "Train loss: tensor(0.1176)\n",
            "Train loss: tensor(0.1738)\n",
            "Train loss: tensor(0.1141)\n",
            "Train loss: tensor(0.1159)\n",
            "Train loss: tensor(0.1233)\n",
            "Train loss: tensor(0.1208)\n",
            "Train loss: tensor(0.1024)\n",
            "Train loss: tensor(0.0948)\n",
            "Train loss: tensor(0.1026)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.1214)\n",
            "Train loss: tensor(0.1045)\n",
            "Train loss: tensor(0.1908)\n",
            "Train loss: tensor(0.1206)\n",
            "Train loss: tensor(0.0880)\n",
            "Train loss: tensor(0.1020)\n",
            "Train loss: tensor(0.1430)\n",
            "Train loss: tensor(0.1464)\n",
            "Train loss: tensor(0.1010)\n",
            "Train loss: tensor(0.1309)\n",
            "Train loss: tensor(0.1149)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.1080)\n",
            "Train loss: tensor(0.1266)\n",
            "Train loss: tensor(0.1042)\n",
            "Train loss: tensor(0.1246)\n",
            "Train loss: tensor(0.1205)\n",
            "Train loss: tensor(0.1137)\n",
            "Train loss: tensor(0.1040)\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.1089)\n",
            "Train loss: tensor(0.1184)\n",
            "Train loss: tensor(0.1919)\n",
            "Train loss: tensor(0.1177)\n",
            "Model is bad!, Current loss: tensor(2.3048) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  16\n",
            "Train loss: tensor(0.0970)\n",
            "Train loss: tensor(0.1830)\n",
            "Train loss: tensor(0.1069)\n",
            "Train loss: tensor(0.0989)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.1204)\n",
            "Train loss: tensor(0.1273)\n",
            "Train loss: tensor(0.1470)\n",
            "Train loss: tensor(0.1134)\n",
            "Train loss: tensor(0.1248)\n",
            "Train loss: tensor(0.1574)\n",
            "Train loss: tensor(0.1392)\n",
            "Train loss: tensor(0.1031)\n",
            "Train loss: tensor(0.1047)\n",
            "Train loss: tensor(0.0971)\n",
            "Train loss: tensor(0.0821)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.1059)\n",
            "Train loss: tensor(0.1032)\n",
            "Train loss: tensor(0.1355)\n",
            "Train loss: tensor(0.1472)\n",
            "Train loss: tensor(0.1147)\n",
            "Train loss: tensor(0.1058)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.1036)\n",
            "Train loss: tensor(0.1055)\n",
            "Train loss: tensor(0.1159)\n",
            "Train loss: tensor(0.1480)\n",
            "Train loss: tensor(0.1119)\n",
            "Train loss: tensor(0.1780)\n",
            "Train loss: tensor(0.0941)\n",
            "Train loss: tensor(0.1028)\n",
            "Train loss: tensor(0.1275)\n",
            "Train loss: tensor(0.1118)\n",
            "Train loss: tensor(0.0809)\n",
            "Train loss: tensor(0.1156)\n",
            "Train loss: tensor(0.1188)\n",
            "Train loss: tensor(0.0717)\n",
            "Train loss: tensor(0.0761)\n",
            "Train loss: tensor(0.1177)\n",
            "Train loss: tensor(0.0970)\n",
            "Model is bad!, Current loss: tensor(4.3229) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  17\n",
            "Train loss: tensor(0.1094)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.1485)\n",
            "Train loss: tensor(0.1000)\n",
            "Train loss: tensor(0.1210)\n",
            "Train loss: tensor(0.1064)\n",
            "Train loss: tensor(0.1453)\n",
            "Train loss: tensor(0.0738)\n",
            "Train loss: tensor(0.1198)\n",
            "Train loss: tensor(0.1567)\n",
            "Train loss: tensor(0.1134)\n",
            "Train loss: tensor(0.1036)\n",
            "Train loss: tensor(0.0958)\n",
            "Train loss: tensor(0.1151)\n",
            "Train loss: tensor(0.1453)\n",
            "Train loss: tensor(0.1069)\n",
            "Train loss: tensor(0.0988)\n",
            "Train loss: tensor(0.1567)\n",
            "Train loss: tensor(0.1237)\n",
            "Train loss: tensor(0.1353)\n",
            "Train loss: tensor(0.1353)\n",
            "Train loss: tensor(0.0996)\n",
            "Train loss: tensor(0.1121)\n",
            "Train loss: tensor(0.1209)\n",
            "Train loss: tensor(0.1268)\n",
            "Train loss: tensor(0.1223)\n",
            "Train loss: tensor(0.1055)\n",
            "Train loss: tensor(0.1246)\n",
            "Train loss: tensor(0.0805)\n",
            "Train loss: tensor(0.1131)\n",
            "Train loss: tensor(0.1154)\n",
            "Train loss: tensor(0.1008)\n",
            "Train loss: tensor(0.0938)\n",
            "Train loss: tensor(0.0944)\n",
            "Train loss: tensor(0.0990)\n",
            "Train loss: tensor(0.1119)\n",
            "Train loss: tensor(0.0971)\n",
            "Train loss: tensor(0.0753)\n",
            "Train loss: tensor(0.0962)\n",
            "Train loss: tensor(0.0744)\n",
            "Train loss: tensor(0.1007)\n",
            "Model is bad!, Current loss: tensor(2.6572) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  18\n",
            "Train loss: tensor(0.1069)\n",
            "Train loss: tensor(0.1468)\n",
            "Train loss: tensor(0.0913)\n",
            "Train loss: tensor(0.2040)\n",
            "Train loss: tensor(0.1070)\n",
            "Train loss: tensor(0.0905)\n",
            "Train loss: tensor(0.1094)\n",
            "Train loss: tensor(0.1051)\n",
            "Train loss: tensor(0.1174)\n",
            "Train loss: tensor(0.0984)\n",
            "Train loss: tensor(0.0897)\n",
            "Train loss: tensor(0.1817)\n",
            "Train loss: tensor(0.1160)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.1176)\n",
            "Train loss: tensor(0.1329)\n",
            "Train loss: tensor(0.1058)\n",
            "Train loss: tensor(0.1133)\n",
            "Train loss: tensor(0.0883)\n",
            "Train loss: tensor(0.1397)\n",
            "Train loss: tensor(0.0811)\n",
            "Train loss: tensor(0.0930)\n",
            "Train loss: tensor(0.1167)\n",
            "Train loss: tensor(0.1165)\n",
            "Train loss: tensor(0.1760)\n",
            "Train loss: tensor(0.1227)\n",
            "Train loss: tensor(0.0953)\n",
            "Train loss: tensor(0.0999)\n",
            "Train loss: tensor(0.1397)\n",
            "Train loss: tensor(0.1357)\n",
            "Train loss: tensor(0.1010)\n",
            "Train loss: tensor(0.1114)\n",
            "Train loss: tensor(0.0763)\n",
            "Train loss: tensor(0.0963)\n",
            "Train loss: tensor(0.1039)\n",
            "Train loss: tensor(0.1022)\n",
            "Train loss: tensor(0.1432)\n",
            "Train loss: tensor(0.0711)\n",
            "Train loss: tensor(0.1025)\n",
            "Train loss: tensor(0.1072)\n",
            "Train loss: tensor(0.0949)\n",
            "Model is bad!, Current loss: tensor(2.7318) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  19\n",
            "Train loss: tensor(0.1037)\n",
            "Train loss: tensor(0.1064)\n",
            "Train loss: tensor(0.1113)\n",
            "Train loss: tensor(0.1154)\n",
            "Train loss: tensor(0.0963)\n",
            "Train loss: tensor(0.0925)\n",
            "Train loss: tensor(0.1005)\n",
            "Train loss: tensor(0.0937)\n",
            "Train loss: tensor(0.1027)\n",
            "Train loss: tensor(0.1126)\n",
            "Train loss: tensor(0.0764)\n",
            "Train loss: tensor(0.1331)\n",
            "Train loss: tensor(0.1295)\n",
            "Train loss: tensor(0.0763)\n",
            "Train loss: tensor(0.1017)\n",
            "Train loss: tensor(0.1181)\n",
            "Train loss: tensor(0.1930)\n",
            "Train loss: tensor(0.1001)\n",
            "Train loss: tensor(0.1736)\n",
            "Train loss: tensor(0.1114)\n",
            "Train loss: tensor(0.1698)\n",
            "Train loss: tensor(0.1150)\n",
            "Train loss: tensor(0.1422)\n",
            "Train loss: tensor(0.0898)\n",
            "Train loss: tensor(0.1268)\n",
            "Train loss: tensor(0.1250)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.0913)\n",
            "Train loss: tensor(0.1242)\n",
            "Train loss: tensor(0.1314)\n",
            "Train loss: tensor(0.1617)\n",
            "Train loss: tensor(0.0723)\n",
            "Train loss: tensor(0.1374)\n",
            "Train loss: tensor(0.0986)\n",
            "Train loss: tensor(0.0930)\n",
            "Train loss: tensor(0.1133)\n",
            "Train loss: tensor(0.1310)\n",
            "Train loss: tensor(0.1202)\n",
            "Train loss: tensor(0.0825)\n",
            "Train loss: tensor(0.0984)\n",
            "Train loss: tensor(0.1134)\n",
            "Model is bad!, Current loss: tensor(2.2667) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  20\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.0955)\n",
            "Train loss: tensor(0.1308)\n",
            "Train loss: tensor(0.1053)\n",
            "Train loss: tensor(0.1449)\n",
            "Train loss: tensor(0.0982)\n",
            "Train loss: tensor(0.0709)\n",
            "Train loss: tensor(0.1039)\n",
            "Train loss: tensor(0.0982)\n",
            "Train loss: tensor(0.1276)\n",
            "Train loss: tensor(0.0984)\n",
            "Train loss: tensor(0.1123)\n",
            "Train loss: tensor(0.0706)\n",
            "Train loss: tensor(0.1283)\n",
            "Train loss: tensor(0.1177)\n",
            "Train loss: tensor(0.1103)\n",
            "Train loss: tensor(0.1108)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0905)\n",
            "Train loss: tensor(0.1142)\n",
            "Train loss: tensor(0.1021)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.1621)\n",
            "Train loss: tensor(0.0920)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.1155)\n",
            "Train loss: tensor(0.0958)\n",
            "Train loss: tensor(0.1210)\n",
            "Train loss: tensor(0.1188)\n",
            "Train loss: tensor(0.1043)\n",
            "Train loss: tensor(0.1104)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0856)\n",
            "Train loss: tensor(0.1627)\n",
            "Train loss: tensor(0.1566)\n",
            "Train loss: tensor(0.1338)\n",
            "Train loss: tensor(0.1324)\n",
            "Train loss: tensor(0.1120)\n",
            "Model is bad!, Current loss: tensor(2.7400) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  21\n",
            "Train loss: tensor(0.1070)\n",
            "Train loss: tensor(0.1002)\n",
            "Train loss: tensor(0.1159)\n",
            "Train loss: tensor(0.1310)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.1042)\n",
            "Train loss: tensor(0.1253)\n",
            "Train loss: tensor(0.0785)\n",
            "Train loss: tensor(0.1085)\n",
            "Train loss: tensor(0.1322)\n",
            "Train loss: tensor(0.2366)\n",
            "Train loss: tensor(0.1130)\n",
            "Train loss: tensor(0.0996)\n",
            "Train loss: tensor(0.0872)\n",
            "Train loss: tensor(0.1692)\n",
            "Train loss: tensor(0.1238)\n",
            "Train loss: tensor(0.1136)\n",
            "Train loss: tensor(0.1158)\n",
            "Train loss: tensor(0.1089)\n",
            "Train loss: tensor(0.1177)\n",
            "Train loss: tensor(0.1711)\n",
            "Train loss: tensor(0.2420)\n",
            "Train loss: tensor(0.1342)\n",
            "Train loss: tensor(0.1056)\n",
            "Train loss: tensor(0.1647)\n",
            "Train loss: tensor(0.1688)\n",
            "Train loss: tensor(0.1094)\n",
            "Train loss: tensor(0.1173)\n",
            "Train loss: tensor(0.1388)\n",
            "Train loss: tensor(0.1129)\n",
            "Train loss: tensor(0.1192)\n",
            "Train loss: tensor(0.1872)\n",
            "Train loss: tensor(0.1316)\n",
            "Train loss: tensor(0.1321)\n",
            "Train loss: tensor(0.1256)\n",
            "Train loss: tensor(0.1142)\n",
            "Train loss: tensor(0.1081)\n",
            "Train loss: tensor(0.2052)\n",
            "Train loss: tensor(0.2020)\n",
            "Train loss: tensor(0.1505)\n",
            "Train loss: tensor(0.1223)\n",
            "Model is bad!, Current loss: tensor(2.1945) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  22\n",
            "Train loss: tensor(0.1640)\n",
            "Train loss: tensor(0.1236)\n",
            "Train loss: tensor(0.1511)\n",
            "Train loss: tensor(0.1469)\n",
            "Train loss: tensor(0.1271)\n",
            "Train loss: tensor(0.1347)\n",
            "Train loss: tensor(0.1141)\n",
            "Train loss: tensor(0.1050)\n",
            "Train loss: tensor(0.1001)\n",
            "Train loss: tensor(0.1102)\n",
            "Train loss: tensor(0.1939)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.1046)\n",
            "Train loss: tensor(0.1160)\n",
            "Train loss: tensor(0.1131)\n",
            "Train loss: tensor(0.1344)\n",
            "Train loss: tensor(0.0999)\n",
            "Train loss: tensor(0.1118)\n",
            "Train loss: tensor(0.0799)\n",
            "Train loss: tensor(0.0970)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.1330)\n",
            "Train loss: tensor(0.1220)\n",
            "Train loss: tensor(0.1932)\n",
            "Train loss: tensor(0.1136)\n",
            "Train loss: tensor(0.1897)\n",
            "Train loss: tensor(0.1705)\n",
            "Train loss: tensor(0.1129)\n",
            "Train loss: tensor(0.1104)\n",
            "Train loss: tensor(0.1487)\n",
            "Train loss: tensor(0.0873)\n",
            "Train loss: tensor(0.1029)\n",
            "Train loss: tensor(0.1382)\n",
            "Train loss: tensor(0.1063)\n",
            "Train loss: tensor(0.1378)\n",
            "Train loss: tensor(0.1768)\n",
            "Train loss: tensor(0.1904)\n",
            "Train loss: tensor(0.1848)\n",
            "Train loss: tensor(0.0933)\n",
            "Train loss: tensor(0.1350)\n",
            "Train loss: tensor(0.1078)\n",
            "Model is bad!, Current loss: tensor(5.2623) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  23\n",
            "Train loss: tensor(0.1625)\n",
            "Train loss: tensor(0.1138)\n",
            "Train loss: tensor(0.1048)\n",
            "Train loss: tensor(0.1199)\n",
            "Train loss: tensor(0.0961)\n",
            "Train loss: tensor(0.1090)\n",
            "Train loss: tensor(0.1764)\n",
            "Train loss: tensor(0.0831)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.1074)\n",
            "Train loss: tensor(0.1048)\n",
            "Train loss: tensor(0.1699)\n",
            "Train loss: tensor(0.1040)\n",
            "Train loss: tensor(0.0898)\n",
            "Train loss: tensor(0.1419)\n",
            "Train loss: tensor(0.1211)\n",
            "Train loss: tensor(0.0978)\n",
            "Train loss: tensor(0.1388)\n",
            "Train loss: tensor(0.1062)\n",
            "Train loss: tensor(0.1256)\n",
            "Train loss: tensor(0.2343)\n",
            "Train loss: tensor(0.1214)\n",
            "Train loss: tensor(0.1115)\n",
            "Train loss: tensor(0.1488)\n",
            "Train loss: tensor(0.0951)\n",
            "Train loss: tensor(0.1151)\n",
            "Train loss: tensor(0.1226)\n",
            "Train loss: tensor(0.1388)\n",
            "Train loss: tensor(0.0898)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.0791)\n",
            "Train loss: tensor(0.1950)\n",
            "Train loss: tensor(0.1912)\n",
            "Train loss: tensor(0.0769)\n",
            "Train loss: tensor(0.1285)\n",
            "Train loss: tensor(0.1087)\n",
            "Train loss: tensor(0.1807)\n",
            "Train loss: tensor(0.1131)\n",
            "Train loss: tensor(0.1053)\n",
            "Train loss: tensor(0.0997)\n",
            "Train loss: tensor(0.1320)\n",
            "Model is bad!, Current loss: tensor(2.6049) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  24\n",
            "Train loss: tensor(0.1377)\n",
            "Train loss: tensor(0.1152)\n",
            "Train loss: tensor(0.1502)\n",
            "Train loss: tensor(0.1476)\n",
            "Train loss: tensor(0.1148)\n",
            "Train loss: tensor(0.1160)\n",
            "Train loss: tensor(0.2002)\n",
            "Train loss: tensor(0.1694)\n",
            "Train loss: tensor(0.2131)\n",
            "Train loss: tensor(0.1007)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.1461)\n",
            "Train loss: tensor(0.1231)\n",
            "Train loss: tensor(0.1288)\n",
            "Train loss: tensor(0.1119)\n",
            "Train loss: tensor(0.0839)\n",
            "Train loss: tensor(0.1141)\n",
            "Train loss: tensor(0.0958)\n",
            "Train loss: tensor(0.1512)\n",
            "Train loss: tensor(0.0977)\n",
            "Train loss: tensor(0.1282)\n",
            "Train loss: tensor(0.1102)\n",
            "Train loss: tensor(0.1031)\n",
            "Train loss: tensor(0.1666)\n",
            "Train loss: tensor(0.0919)\n",
            "Train loss: tensor(0.1393)\n",
            "Train loss: tensor(0.0996)\n",
            "Train loss: tensor(0.1187)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.1761)\n",
            "Train loss: tensor(0.1041)\n",
            "Train loss: tensor(0.1139)\n",
            "Train loss: tensor(0.0924)\n",
            "Train loss: tensor(0.1808)\n",
            "Train loss: tensor(0.1519)\n",
            "Train loss: tensor(0.1084)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.1558)\n",
            "Train loss: tensor(0.1085)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.1661)\n",
            "Model is bad!, Current loss: tensor(7.8031) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  25\n",
            "Train loss: tensor(0.1094)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.0757)\n",
            "Train loss: tensor(0.0977)\n",
            "Train loss: tensor(0.1189)\n",
            "Train loss: tensor(0.1914)\n",
            "Train loss: tensor(0.1276)\n",
            "Train loss: tensor(0.1622)\n",
            "Train loss: tensor(0.1536)\n",
            "Train loss: tensor(0.1072)\n",
            "Train loss: tensor(0.0983)\n",
            "Train loss: tensor(0.1356)\n",
            "Train loss: tensor(0.1073)\n",
            "Train loss: tensor(0.1010)\n",
            "Train loss: tensor(0.1246)\n",
            "Train loss: tensor(0.1036)\n",
            "Train loss: tensor(0.1252)\n",
            "Train loss: tensor(0.1010)\n",
            "Train loss: tensor(0.0853)\n",
            "Train loss: tensor(0.1285)\n",
            "Train loss: tensor(0.0800)\n",
            "Train loss: tensor(0.1087)\n",
            "Train loss: tensor(0.1279)\n",
            "Train loss: tensor(0.1973)\n",
            "Train loss: tensor(0.1062)\n",
            "Train loss: tensor(0.0743)\n",
            "Train loss: tensor(0.1116)\n",
            "Train loss: tensor(0.0896)\n",
            "Train loss: tensor(0.0728)\n",
            "Train loss: tensor(0.0905)\n",
            "Train loss: tensor(0.1058)\n",
            "Train loss: tensor(0.0938)\n",
            "Train loss: tensor(0.0896)\n",
            "Train loss: tensor(0.1468)\n",
            "Train loss: tensor(0.0882)\n",
            "Train loss: tensor(0.1216)\n",
            "Train loss: tensor(0.1443)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.1175)\n",
            "Train loss: tensor(0.1147)\n",
            "Train loss: tensor(0.1175)\n",
            "Model is bad!, Current loss: tensor(2.2327) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  26\n",
            "Train loss: tensor(0.1385)\n",
            "Train loss: tensor(0.1053)\n",
            "Train loss: tensor(0.0911)\n",
            "Train loss: tensor(0.0958)\n",
            "Train loss: tensor(0.1108)\n",
            "Train loss: tensor(0.0724)\n",
            "Train loss: tensor(0.1072)\n",
            "Train loss: tensor(0.1015)\n",
            "Train loss: tensor(0.1368)\n",
            "Train loss: tensor(0.1364)\n",
            "Train loss: tensor(0.1422)\n",
            "Train loss: tensor(0.1125)\n",
            "Train loss: tensor(0.0945)\n",
            "Train loss: tensor(0.1197)\n",
            "Train loss: tensor(0.1258)\n",
            "Train loss: tensor(0.1219)\n",
            "Train loss: tensor(0.0978)\n",
            "Train loss: tensor(0.1139)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.0951)\n",
            "Train loss: tensor(0.0758)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.1135)\n",
            "Train loss: tensor(0.1046)\n",
            "Train loss: tensor(0.1657)\n",
            "Train loss: tensor(0.0773)\n",
            "Train loss: tensor(0.1089)\n",
            "Train loss: tensor(0.1485)\n",
            "Train loss: tensor(0.0924)\n",
            "Train loss: tensor(0.1691)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.1004)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.0878)\n",
            "Train loss: tensor(0.1407)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.0964)\n",
            "Train loss: tensor(0.1132)\n",
            "Train loss: tensor(0.1123)\n",
            "Train loss: tensor(0.1372)\n",
            "Train loss: tensor(0.1121)\n",
            "Model is bad!, Current loss: tensor(2.7621) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  27\n",
            "Train loss: tensor(0.1088)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.0949)\n",
            "Train loss: tensor(0.0889)\n",
            "Train loss: tensor(0.1003)\n",
            "Train loss: tensor(0.1018)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.1167)\n",
            "Train loss: tensor(0.1245)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.1053)\n",
            "Train loss: tensor(0.2278)\n",
            "Train loss: tensor(0.1095)\n",
            "Train loss: tensor(0.1175)\n",
            "Train loss: tensor(0.1261)\n",
            "Train loss: tensor(0.1050)\n",
            "Train loss: tensor(0.1909)\n",
            "Train loss: tensor(0.1140)\n",
            "Train loss: tensor(0.1865)\n",
            "Train loss: tensor(0.1137)\n",
            "Train loss: tensor(0.0949)\n",
            "Train loss: tensor(0.1281)\n",
            "Train loss: tensor(0.0712)\n",
            "Train loss: tensor(0.1679)\n",
            "Train loss: tensor(0.0748)\n",
            "Train loss: tensor(0.1143)\n",
            "Train loss: tensor(0.1102)\n",
            "Train loss: tensor(0.1556)\n",
            "Train loss: tensor(0.1161)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.1038)\n",
            "Train loss: tensor(0.1080)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0738)\n",
            "Train loss: tensor(0.1024)\n",
            "Train loss: tensor(0.1017)\n",
            "Train loss: tensor(0.1397)\n",
            "Train loss: tensor(0.1043)\n",
            "Train loss: tensor(0.1086)\n",
            "Train loss: tensor(0.1166)\n",
            "Model is bad!, Current loss: tensor(3.5558) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  28\n",
            "Train loss: tensor(0.1229)\n",
            "Train loss: tensor(0.1353)\n",
            "Train loss: tensor(0.1178)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.1337)\n",
            "Train loss: tensor(0.1303)\n",
            "Train loss: tensor(0.1202)\n",
            "Train loss: tensor(0.0706)\n",
            "Train loss: tensor(0.1923)\n",
            "Train loss: tensor(0.1549)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.0870)\n",
            "Train loss: tensor(0.1576)\n",
            "Train loss: tensor(0.1156)\n",
            "Train loss: tensor(0.0711)\n",
            "Train loss: tensor(0.1021)\n",
            "Train loss: tensor(0.0759)\n",
            "Train loss: tensor(0.0855)\n",
            "Train loss: tensor(0.1015)\n",
            "Train loss: tensor(0.1444)\n",
            "Train loss: tensor(0.1001)\n",
            "Train loss: tensor(0.0886)\n",
            "Train loss: tensor(0.1359)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.0883)\n",
            "Train loss: tensor(0.1626)\n",
            "Train loss: tensor(0.1070)\n",
            "Train loss: tensor(0.1006)\n",
            "Train loss: tensor(0.0957)\n",
            "Train loss: tensor(0.0936)\n",
            "Train loss: tensor(0.0954)\n",
            "Train loss: tensor(0.0945)\n",
            "Train loss: tensor(0.0983)\n",
            "Train loss: tensor(0.0903)\n",
            "Train loss: tensor(0.1018)\n",
            "Train loss: tensor(0.0669)\n",
            "Train loss: tensor(0.0939)\n",
            "Train loss: tensor(0.0909)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.1015)\n",
            "Train loss: tensor(0.1081)\n",
            "Model is bad!, Current loss: tensor(2.3907) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  29\n",
            "Train loss: tensor(0.1082)\n",
            "Train loss: tensor(0.0905)\n",
            "Train loss: tensor(0.0929)\n",
            "Train loss: tensor(0.0913)\n",
            "Train loss: tensor(0.1222)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.0677)\n",
            "Train loss: tensor(0.0687)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.1149)\n",
            "Train loss: tensor(0.1298)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.0879)\n",
            "Train loss: tensor(0.1196)\n",
            "Train loss: tensor(0.1164)\n",
            "Train loss: tensor(0.2040)\n",
            "Train loss: tensor(0.1344)\n",
            "Train loss: tensor(0.1107)\n",
            "Train loss: tensor(0.1052)\n",
            "Train loss: tensor(0.1059)\n",
            "Train loss: tensor(0.1509)\n",
            "Train loss: tensor(0.1243)\n",
            "Train loss: tensor(0.1187)\n",
            "Train loss: tensor(0.1079)\n",
            "Train loss: tensor(0.1180)\n",
            "Train loss: tensor(0.1406)\n",
            "Train loss: tensor(0.1074)\n",
            "Train loss: tensor(0.1269)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.1755)\n",
            "Train loss: tensor(0.1100)\n",
            "Train loss: tensor(0.1212)\n",
            "Train loss: tensor(0.1128)\n",
            "Train loss: tensor(0.0790)\n",
            "Train loss: tensor(0.0734)\n",
            "Train loss: tensor(0.1181)\n",
            "Train loss: tensor(0.0910)\n",
            "Train loss: tensor(0.1249)\n",
            "Train loss: tensor(0.1195)\n",
            "Train loss: tensor(0.1609)\n",
            "Train loss: tensor(0.0924)\n",
            "Model is bad!, Current loss: tensor(3.2834) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  30\n",
            "Train loss: tensor(0.1070)\n",
            "Train loss: tensor(0.1303)\n",
            "Train loss: tensor(0.1576)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.1115)\n",
            "Train loss: tensor(0.0957)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.1517)\n",
            "Train loss: tensor(0.0963)\n",
            "Train loss: tensor(0.0945)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.1013)\n",
            "Train loss: tensor(0.1158)\n",
            "Train loss: tensor(0.0745)\n",
            "Train loss: tensor(0.1489)\n",
            "Train loss: tensor(0.0835)\n",
            "Train loss: tensor(0.1063)\n",
            "Train loss: tensor(0.0918)\n",
            "Train loss: tensor(0.1045)\n",
            "Train loss: tensor(0.1501)\n",
            "Train loss: tensor(0.1087)\n",
            "Train loss: tensor(0.1101)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.1080)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.1441)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0999)\n",
            "Train loss: tensor(0.1241)\n",
            "Train loss: tensor(0.1121)\n",
            "Train loss: tensor(0.1135)\n",
            "Train loss: tensor(0.1028)\n",
            "Train loss: tensor(0.0971)\n",
            "Train loss: tensor(0.1167)\n",
            "Train loss: tensor(0.1455)\n",
            "Train loss: tensor(0.1033)\n",
            "Train loss: tensor(0.0913)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.1103)\n",
            "Model is bad!, Current loss: tensor(2.9427) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  31\n",
            "Train loss: tensor(0.1001)\n",
            "Train loss: tensor(0.1572)\n",
            "Train loss: tensor(0.1479)\n",
            "Train loss: tensor(0.1093)\n",
            "Train loss: tensor(0.1059)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.1004)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.1121)\n",
            "Train loss: tensor(0.1747)\n",
            "Train loss: tensor(0.1051)\n",
            "Train loss: tensor(0.0958)\n",
            "Train loss: tensor(0.1763)\n",
            "Train loss: tensor(0.0959)\n",
            "Train loss: tensor(0.1055)\n",
            "Train loss: tensor(0.1339)\n",
            "Train loss: tensor(0.1033)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0686)\n",
            "Train loss: tensor(0.1093)\n",
            "Train loss: tensor(0.1265)\n",
            "Train loss: tensor(0.0941)\n",
            "Train loss: tensor(0.0889)\n",
            "Train loss: tensor(0.0860)\n",
            "Train loss: tensor(0.0918)\n",
            "Train loss: tensor(0.0924)\n",
            "Train loss: tensor(0.0957)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.1108)\n",
            "Train loss: tensor(0.1042)\n",
            "Train loss: tensor(0.1100)\n",
            "Train loss: tensor(0.0697)\n",
            "Train loss: tensor(0.1109)\n",
            "Train loss: tensor(0.1357)\n",
            "Train loss: tensor(0.0911)\n",
            "Train loss: tensor(0.0969)\n",
            "Train loss: tensor(0.0961)\n",
            "Train loss: tensor(0.1045)\n",
            "Train loss: tensor(0.0675)\n",
            "Train loss: tensor(0.1077)\n",
            "Model is bad!, Current loss: tensor(3.5554) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  32\n",
            "Train loss: tensor(0.1477)\n",
            "Train loss: tensor(0.1027)\n",
            "Train loss: tensor(0.1442)\n",
            "Train loss: tensor(0.1156)\n",
            "Train loss: tensor(0.1274)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.0967)\n",
            "Train loss: tensor(0.1044)\n",
            "Train loss: tensor(0.1330)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.0900)\n",
            "Train loss: tensor(0.0865)\n",
            "Train loss: tensor(0.0903)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.1169)\n",
            "Train loss: tensor(0.0900)\n",
            "Train loss: tensor(0.1500)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.0884)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.1053)\n",
            "Train loss: tensor(0.0960)\n",
            "Train loss: tensor(0.0934)\n",
            "Train loss: tensor(0.1037)\n",
            "Train loss: tensor(0.0833)\n",
            "Train loss: tensor(0.1039)\n",
            "Train loss: tensor(0.1309)\n",
            "Train loss: tensor(0.0665)\n",
            "Train loss: tensor(0.1042)\n",
            "Train loss: tensor(0.1131)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.1097)\n",
            "Train loss: tensor(0.1406)\n",
            "Train loss: tensor(0.1177)\n",
            "Train loss: tensor(0.0898)\n",
            "Train loss: tensor(0.0854)\n",
            "Train loss: tensor(0.0704)\n",
            "Train loss: tensor(0.0948)\n",
            "Train loss: tensor(0.1006)\n",
            "Train loss: tensor(0.1023)\n",
            "Train loss: tensor(0.1165)\n",
            "Model is bad!, Current loss: tensor(2.5187) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  33\n",
            "Train loss: tensor(0.1051)\n",
            "Train loss: tensor(0.1015)\n",
            "Train loss: tensor(0.0970)\n",
            "Train loss: tensor(0.1204)\n",
            "Train loss: tensor(0.0707)\n",
            "Train loss: tensor(0.0847)\n",
            "Train loss: tensor(0.0849)\n",
            "Train loss: tensor(0.1047)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.1207)\n",
            "Train loss: tensor(0.1056)\n",
            "Train loss: tensor(0.1195)\n",
            "Train loss: tensor(0.1218)\n",
            "Train loss: tensor(0.1420)\n",
            "Train loss: tensor(0.1018)\n",
            "Train loss: tensor(0.1224)\n",
            "Train loss: tensor(0.0653)\n",
            "Train loss: tensor(0.0694)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.1102)\n",
            "Train loss: tensor(0.1453)\n",
            "Train loss: tensor(0.0716)\n",
            "Train loss: tensor(0.1081)\n",
            "Train loss: tensor(0.1060)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.1144)\n",
            "Train loss: tensor(0.1008)\n",
            "Train loss: tensor(0.1297)\n",
            "Train loss: tensor(0.0671)\n",
            "Train loss: tensor(0.0835)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.0963)\n",
            "Train loss: tensor(0.1007)\n",
            "Train loss: tensor(0.1994)\n",
            "Train loss: tensor(0.1126)\n",
            "Train loss: tensor(0.1035)\n",
            "Train loss: tensor(0.0906)\n",
            "Train loss: tensor(0.1010)\n",
            "Train loss: tensor(0.1359)\n",
            "Train loss: tensor(0.1058)\n",
            "Model is bad!, Current loss: tensor(1.7259) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  34\n",
            "Train loss: tensor(0.1010)\n",
            "Train loss: tensor(0.0856)\n",
            "Train loss: tensor(0.1181)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.1026)\n",
            "Train loss: tensor(0.0879)\n",
            "Train loss: tensor(0.0911)\n",
            "Train loss: tensor(0.1266)\n",
            "Train loss: tensor(0.1110)\n",
            "Train loss: tensor(0.1192)\n",
            "Train loss: tensor(0.0701)\n",
            "Train loss: tensor(0.1099)\n",
            "Train loss: tensor(0.1052)\n",
            "Train loss: tensor(0.0647)\n",
            "Train loss: tensor(0.1229)\n",
            "Train loss: tensor(0.1046)\n",
            "Train loss: tensor(0.1503)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.0808)\n",
            "Train loss: tensor(0.1152)\n",
            "Train loss: tensor(0.0891)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.0974)\n",
            "Train loss: tensor(0.1460)\n",
            "Train loss: tensor(0.1020)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.1073)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.1038)\n",
            "Train loss: tensor(0.1116)\n",
            "Train loss: tensor(0.1761)\n",
            "Train loss: tensor(0.1415)\n",
            "Train loss: tensor(0.0824)\n",
            "Train loss: tensor(0.1178)\n",
            "Train loss: tensor(0.0919)\n",
            "Train loss: tensor(0.0736)\n",
            "Train loss: tensor(0.1046)\n",
            "Train loss: tensor(0.0883)\n",
            "Train loss: tensor(0.1543)\n",
            "Train loss: tensor(0.0629)\n",
            "Model is bad!, Current loss: tensor(2.6950) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  35\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0783)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.1047)\n",
            "Train loss: tensor(0.1035)\n",
            "Train loss: tensor(0.1010)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.1053)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.0832)\n",
            "Train loss: tensor(0.0846)\n",
            "Train loss: tensor(0.0661)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.1176)\n",
            "Train loss: tensor(0.1056)\n",
            "Train loss: tensor(0.1851)\n",
            "Train loss: tensor(0.1008)\n",
            "Train loss: tensor(0.1419)\n",
            "Train loss: tensor(0.1269)\n",
            "Train loss: tensor(0.1278)\n",
            "Train loss: tensor(0.1045)\n",
            "Train loss: tensor(0.1047)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.1267)\n",
            "Train loss: tensor(0.1069)\n",
            "Train loss: tensor(0.0993)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.1076)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.0684)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.0938)\n",
            "Train loss: tensor(0.1117)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0820)\n",
            "Train loss: tensor(0.1069)\n",
            "Train loss: tensor(0.1324)\n",
            "Model is bad!, Current loss: tensor(2.7605) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.5\n",
            "Epoch:  36\n",
            "Train loss: tensor(0.0983)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.1109)\n",
            "Train loss: tensor(0.1363)\n",
            "Train loss: tensor(0.0930)\n",
            "Train loss: tensor(0.1078)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.0967)\n",
            "Train loss: tensor(0.1000)\n",
            "Train loss: tensor(0.0956)\n",
            "Train loss: tensor(0.0682)\n",
            "Train loss: tensor(0.0859)\n",
            "Train loss: tensor(0.1520)\n",
            "Train loss: tensor(0.0801)\n",
            "Train loss: tensor(0.1061)\n",
            "Train loss: tensor(0.1185)\n",
            "Train loss: tensor(0.0986)\n",
            "Train loss: tensor(0.1063)\n",
            "Train loss: tensor(0.0962)\n",
            "Train loss: tensor(0.1305)\n",
            "Train loss: tensor(0.1368)\n",
            "Train loss: tensor(0.1460)\n",
            "Train loss: tensor(0.0667)\n",
            "Train loss: tensor(0.1047)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.1090)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.0882)\n",
            "Train loss: tensor(0.0858)\n",
            "Train loss: tensor(0.1418)\n",
            "Train loss: tensor(0.0852)\n",
            "Train loss: tensor(0.1129)\n",
            "Train loss: tensor(0.0862)\n",
            "Train loss: tensor(0.1090)\n",
            "Train loss: tensor(0.1217)\n",
            "Train loss: tensor(0.0677)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.1138)\n",
            "Train loss: tensor(0.0821)\n",
            "Train loss: tensor(0.0958)\n",
            "Train loss: tensor(0.1205)\n",
            "Model is bad!, Current loss: tensor(5.1176) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.5\n",
            "Epoch:  37\n",
            "Train loss: tensor(0.1110)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.0957)\n",
            "Train loss: tensor(0.1083)\n",
            "Train loss: tensor(0.1033)\n",
            "Train loss: tensor(0.0902)\n",
            "Train loss: tensor(0.1307)\n",
            "Train loss: tensor(0.0862)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.1311)\n",
            "Train loss: tensor(0.0997)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.1371)\n",
            "Train loss: tensor(0.0865)\n",
            "Train loss: tensor(0.0934)\n",
            "Train loss: tensor(0.0653)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.0830)\n",
            "Train loss: tensor(0.0948)\n",
            "Train loss: tensor(0.1198)\n",
            "Train loss: tensor(0.1042)\n",
            "Train loss: tensor(0.1049)\n",
            "Train loss: tensor(0.1200)\n",
            "Train loss: tensor(0.1022)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0639)\n",
            "Train loss: tensor(0.1285)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.1515)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.0789)\n",
            "Train loss: tensor(0.1185)\n",
            "Train loss: tensor(0.0970)\n",
            "Train loss: tensor(0.0745)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.0971)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.1256)\n",
            "Train loss: tensor(0.0969)\n",
            "Train loss: tensor(0.0869)\n",
            "Train loss: tensor(0.0970)\n",
            "Model is bad!, Current loss: tensor(3.6557) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.5\n",
            "Epoch:  38\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.1269)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.1225)\n",
            "Train loss: tensor(0.0841)\n",
            "Train loss: tensor(0.0909)\n",
            "Train loss: tensor(0.0932)\n",
            "Train loss: tensor(0.1083)\n",
            "Train loss: tensor(0.0999)\n",
            "Train loss: tensor(0.0889)\n",
            "Train loss: tensor(0.0739)\n",
            "Train loss: tensor(0.0896)\n",
            "Train loss: tensor(0.1029)\n",
            "Train loss: tensor(0.1217)\n",
            "Train loss: tensor(0.0706)\n",
            "Train loss: tensor(0.0828)\n",
            "Train loss: tensor(0.1167)\n",
            "Train loss: tensor(0.1096)\n",
            "Train loss: tensor(0.1314)\n",
            "Train loss: tensor(0.0889)\n",
            "Train loss: tensor(0.1168)\n",
            "Train loss: tensor(0.1056)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.0758)\n",
            "Train loss: tensor(0.1691)\n",
            "Train loss: tensor(0.0970)\n",
            "Train loss: tensor(0.1108)\n",
            "Train loss: tensor(0.1295)\n",
            "Train loss: tensor(0.1323)\n",
            "Train loss: tensor(0.0912)\n",
            "Train loss: tensor(0.1172)\n",
            "Train loss: tensor(0.0816)\n",
            "Train loss: tensor(0.1002)\n",
            "Train loss: tensor(0.1048)\n",
            "Train loss: tensor(0.1117)\n",
            "Train loss: tensor(0.1084)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.0908)\n",
            "Train loss: tensor(0.1649)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.0819)\n",
            "Model is bad!, Current loss: tensor(3.1130) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.5\n",
            "Epoch:  39\n",
            "Train loss: tensor(0.1104)\n",
            "Train loss: tensor(0.1232)\n",
            "Train loss: tensor(0.0730)\n",
            "Train loss: tensor(0.1218)\n",
            "Train loss: tensor(0.0643)\n",
            "Train loss: tensor(0.0644)\n",
            "Train loss: tensor(0.0995)\n",
            "Train loss: tensor(0.1105)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.0987)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.1022)\n",
            "Train loss: tensor(0.1038)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.1265)\n",
            "Train loss: tensor(0.1038)\n",
            "Train loss: tensor(0.0720)\n",
            "Train loss: tensor(0.1153)\n",
            "Train loss: tensor(0.0795)\n",
            "Train loss: tensor(0.1125)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.1097)\n",
            "Train loss: tensor(0.0993)\n",
            "Train loss: tensor(0.0916)\n",
            "Train loss: tensor(0.1655)\n",
            "Train loss: tensor(0.0788)\n",
            "Train loss: tensor(0.1117)\n",
            "Train loss: tensor(0.0850)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.1014)\n",
            "Train loss: tensor(0.1556)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.0883)\n",
            "Train loss: tensor(0.0792)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.1161)\n",
            "Train loss: tensor(0.0728)\n",
            "Train loss: tensor(0.0759)\n",
            "Train loss: tensor(0.0838)\n",
            "Model is bad!, Current loss: tensor(2.2581) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.5\n",
            "Epoch:  40\n",
            "Train loss: tensor(0.0945)\n",
            "Train loss: tensor(0.0993)\n",
            "Train loss: tensor(0.0736)\n",
            "Train loss: tensor(0.1269)\n",
            "Train loss: tensor(0.1251)\n",
            "Train loss: tensor(0.0995)\n",
            "Train loss: tensor(0.0767)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.0989)\n",
            "Train loss: tensor(0.0978)\n",
            "Train loss: tensor(0.0984)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.0964)\n",
            "Train loss: tensor(0.0726)\n",
            "Train loss: tensor(0.1222)\n",
            "Train loss: tensor(0.0954)\n",
            "Train loss: tensor(0.0637)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.0847)\n",
            "Train loss: tensor(0.1052)\n",
            "Train loss: tensor(0.1296)\n",
            "Train loss: tensor(0.1325)\n",
            "Train loss: tensor(0.0957)\n",
            "Train loss: tensor(0.0812)\n",
            "Train loss: tensor(0.0790)\n",
            "Train loss: tensor(0.0865)\n",
            "Train loss: tensor(0.0959)\n",
            "Train loss: tensor(0.0891)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.0662)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.2686)\n",
            "Train loss: tensor(0.0921)\n",
            "Train loss: tensor(0.0822)\n",
            "Train loss: tensor(0.1044)\n",
            "Train loss: tensor(0.0996)\n",
            "Train loss: tensor(0.1422)\n",
            "Train loss: tensor(0.1086)\n",
            "Train loss: tensor(0.0788)\n",
            "Train loss: tensor(0.1545)\n",
            "Train loss: tensor(0.1325)\n",
            "Model is bad!, Current loss: tensor(4.2209) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.5\n",
            "Epoch:  41\n",
            "Train loss: tensor(0.0941)\n",
            "Train loss: tensor(0.1023)\n",
            "Train loss: tensor(0.0903)\n",
            "Train loss: tensor(0.0984)\n",
            "Train loss: tensor(0.1936)\n",
            "Train loss: tensor(0.0870)\n",
            "Train loss: tensor(0.1121)\n",
            "Train loss: tensor(0.1048)\n",
            "Train loss: tensor(0.0742)\n",
            "Train loss: tensor(0.0873)\n",
            "Train loss: tensor(0.1054)\n",
            "Train loss: tensor(0.1122)\n",
            "Train loss: tensor(0.1354)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.0822)\n",
            "Train loss: tensor(0.1227)\n",
            "Train loss: tensor(0.1007)\n",
            "Train loss: tensor(0.1245)\n",
            "Train loss: tensor(0.0830)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0997)\n",
            "Train loss: tensor(0.0983)\n",
            "Train loss: tensor(0.1292)\n",
            "Train loss: tensor(0.0891)\n",
            "Train loss: tensor(0.1113)\n",
            "Train loss: tensor(0.0693)\n",
            "Train loss: tensor(0.1055)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0888)\n",
            "Train loss: tensor(0.1138)\n",
            "Train loss: tensor(0.1034)\n",
            "Train loss: tensor(0.0865)\n",
            "Train loss: tensor(0.1140)\n",
            "Train loss: tensor(0.1128)\n",
            "Train loss: tensor(0.0738)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.0841)\n",
            "Train loss: tensor(0.1630)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.1133)\n",
            "Model is bad!, Current loss: tensor(2.4547) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.5\n",
            "Epoch:  42\n",
            "Train loss: tensor(0.1215)\n",
            "Train loss: tensor(0.0998)\n",
            "Train loss: tensor(0.1053)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.0824)\n",
            "Train loss: tensor(0.1348)\n",
            "Train loss: tensor(0.0710)\n",
            "Train loss: tensor(0.1451)\n",
            "Train loss: tensor(0.1245)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.1483)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.0881)\n",
            "Train loss: tensor(0.0846)\n",
            "Train loss: tensor(0.0955)\n",
            "Train loss: tensor(0.1054)\n",
            "Train loss: tensor(0.0822)\n",
            "Train loss: tensor(0.1222)\n",
            "Train loss: tensor(0.0843)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.0802)\n",
            "Train loss: tensor(0.1146)\n",
            "Train loss: tensor(0.1202)\n",
            "Train loss: tensor(0.0947)\n",
            "Train loss: tensor(0.0921)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.1094)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.0973)\n",
            "Train loss: tensor(0.1027)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.0833)\n",
            "Train loss: tensor(0.0961)\n",
            "Train loss: tensor(0.1157)\n",
            "Train loss: tensor(0.0988)\n",
            "Train loss: tensor(0.0882)\n",
            "Train loss: tensor(0.1006)\n",
            "Train loss: tensor(0.0910)\n",
            "Train loss: tensor(0.0756)\n",
            "Train loss: tensor(0.0978)\n",
            "Train loss: tensor(0.0943)\n",
            "Model is bad!, Current loss: tensor(2.8817) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  43\n",
            "Train loss: tensor(0.1015)\n",
            "Train loss: tensor(0.1082)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.1068)\n",
            "Train loss: tensor(0.1254)\n",
            "Train loss: tensor(0.0977)\n",
            "Train loss: tensor(0.0963)\n",
            "Train loss: tensor(0.0978)\n",
            "Train loss: tensor(0.0978)\n",
            "Train loss: tensor(0.1022)\n",
            "Train loss: tensor(0.1308)\n",
            "Train loss: tensor(0.1348)\n",
            "Train loss: tensor(0.1102)\n",
            "Train loss: tensor(0.1091)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.0784)\n",
            "Train loss: tensor(0.1116)\n",
            "Train loss: tensor(0.0880)\n",
            "Train loss: tensor(0.0669)\n",
            "Train loss: tensor(0.1232)\n",
            "Train loss: tensor(0.0913)\n",
            "Train loss: tensor(0.1262)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.1113)\n",
            "Train loss: tensor(0.1035)\n",
            "Train loss: tensor(0.1365)\n",
            "Train loss: tensor(0.0884)\n",
            "Train loss: tensor(0.1097)\n",
            "Train loss: tensor(0.1071)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.1084)\n",
            "Train loss: tensor(0.0717)\n",
            "Train loss: tensor(0.0702)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.0987)\n",
            "Train loss: tensor(0.1056)\n",
            "Train loss: tensor(0.1515)\n",
            "Train loss: tensor(0.0627)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.0621)\n",
            "Model is bad!, Current loss: tensor(2.1505) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  44\n",
            "Train loss: tensor(0.1003)\n",
            "Train loss: tensor(0.1128)\n",
            "Train loss: tensor(0.0876)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.0906)\n",
            "Train loss: tensor(0.0888)\n",
            "Train loss: tensor(0.0747)\n",
            "Train loss: tensor(0.0678)\n",
            "Train loss: tensor(0.1114)\n",
            "Train loss: tensor(0.1310)\n",
            "Train loss: tensor(0.0699)\n",
            "Train loss: tensor(0.0830)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.0973)\n",
            "Train loss: tensor(0.0644)\n",
            "Train loss: tensor(0.0852)\n",
            "Train loss: tensor(0.0832)\n",
            "Train loss: tensor(0.1459)\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.0644)\n",
            "Train loss: tensor(0.1095)\n",
            "Train loss: tensor(0.0712)\n",
            "Train loss: tensor(0.0796)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.0772)\n",
            "Train loss: tensor(0.1028)\n",
            "Train loss: tensor(0.1033)\n",
            "Train loss: tensor(0.0650)\n",
            "Train loss: tensor(0.1029)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.1567)\n",
            "Train loss: tensor(0.1145)\n",
            "Train loss: tensor(0.0886)\n",
            "Train loss: tensor(0.1036)\n",
            "Train loss: tensor(0.1044)\n",
            "Train loss: tensor(0.1170)\n",
            "Train loss: tensor(0.1306)\n",
            "Train loss: tensor(0.1210)\n",
            "Train loss: tensor(0.0919)\n",
            "Model is bad!, Current loss: tensor(2.3746) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  45\n",
            "Train loss: tensor(0.1042)\n",
            "Train loss: tensor(0.1158)\n",
            "Train loss: tensor(0.0662)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.1036)\n",
            "Train loss: tensor(0.0944)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0970)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.0869)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.0732)\n",
            "Train loss: tensor(0.0953)\n",
            "Train loss: tensor(0.0720)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.0900)\n",
            "Train loss: tensor(0.0882)\n",
            "Train loss: tensor(0.1237)\n",
            "Train loss: tensor(0.1089)\n",
            "Train loss: tensor(0.0603)\n",
            "Train loss: tensor(0.0784)\n",
            "Train loss: tensor(0.0821)\n",
            "Train loss: tensor(0.0914)\n",
            "Train loss: tensor(0.0630)\n",
            "Train loss: tensor(0.1244)\n",
            "Train loss: tensor(0.0957)\n",
            "Train loss: tensor(0.1276)\n",
            "Train loss: tensor(0.0878)\n",
            "Train loss: tensor(0.1162)\n",
            "Train loss: tensor(0.0981)\n",
            "Train loss: tensor(0.0682)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.0742)\n",
            "Train loss: tensor(0.0942)\n",
            "Train loss: tensor(0.0992)\n",
            "Train loss: tensor(0.1258)\n",
            "Train loss: tensor(0.1041)\n",
            "Train loss: tensor(0.1725)\n",
            "Model is bad!, Current loss: tensor(2.8481) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  46\n",
            "Train loss: tensor(0.1104)\n",
            "Train loss: tensor(0.0774)\n",
            "Train loss: tensor(0.1023)\n",
            "Train loss: tensor(0.0863)\n",
            "Train loss: tensor(0.1046)\n",
            "Train loss: tensor(0.1000)\n",
            "Train loss: tensor(0.0964)\n",
            "Train loss: tensor(0.0642)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.1356)\n",
            "Train loss: tensor(0.0805)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.1320)\n",
            "Train loss: tensor(0.0996)\n",
            "Train loss: tensor(0.1435)\n",
            "Train loss: tensor(0.0914)\n",
            "Train loss: tensor(0.1278)\n",
            "Train loss: tensor(0.0799)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.1516)\n",
            "Train loss: tensor(0.0768)\n",
            "Train loss: tensor(0.0973)\n",
            "Train loss: tensor(0.1015)\n",
            "Train loss: tensor(0.1405)\n",
            "Train loss: tensor(0.0880)\n",
            "Train loss: tensor(0.1532)\n",
            "Train loss: tensor(0.1314)\n",
            "Train loss: tensor(0.1078)\n",
            "Train loss: tensor(0.1275)\n",
            "Train loss: tensor(0.1087)\n",
            "Train loss: tensor(0.1127)\n",
            "Train loss: tensor(0.1295)\n",
            "Train loss: tensor(0.1028)\n",
            "Train loss: tensor(0.0837)\n",
            "Train loss: tensor(0.1117)\n",
            "Train loss: tensor(0.0713)\n",
            "Train loss: tensor(0.0730)\n",
            "Train loss: tensor(0.0983)\n",
            "Train loss: tensor(0.0755)\n",
            "Train loss: tensor(0.0879)\n",
            "Train loss: tensor(0.1092)\n",
            "Model is bad!, Current loss: tensor(2.3835) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  47\n",
            "Train loss: tensor(0.1308)\n",
            "Train loss: tensor(0.0956)\n",
            "Train loss: tensor(0.1246)\n",
            "Train loss: tensor(0.1105)\n",
            "Train loss: tensor(0.1077)\n",
            "Train loss: tensor(0.0918)\n",
            "Train loss: tensor(0.1619)\n",
            "Train loss: tensor(0.1019)\n",
            "Train loss: tensor(0.1408)\n",
            "Train loss: tensor(0.0994)\n",
            "Train loss: tensor(0.0683)\n",
            "Train loss: tensor(0.1111)\n",
            "Train loss: tensor(0.0873)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.0925)\n",
            "Train loss: tensor(0.0878)\n",
            "Train loss: tensor(0.0821)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.0646)\n",
            "Train loss: tensor(0.0908)\n",
            "Train loss: tensor(0.0969)\n",
            "Train loss: tensor(0.1073)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.0898)\n",
            "Train loss: tensor(0.0924)\n",
            "Train loss: tensor(0.1059)\n",
            "Train loss: tensor(0.0629)\n",
            "Train loss: tensor(0.1227)\n",
            "Train loss: tensor(0.1417)\n",
            "Train loss: tensor(0.1570)\n",
            "Train loss: tensor(0.1043)\n",
            "Train loss: tensor(0.0957)\n",
            "Train loss: tensor(0.1032)\n",
            "Train loss: tensor(0.0944)\n",
            "Train loss: tensor(0.0918)\n",
            "Train loss: tensor(0.0995)\n",
            "Train loss: tensor(0.0919)\n",
            "Train loss: tensor(0.0750)\n",
            "Train loss: tensor(0.0849)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.0807)\n",
            "Model is bad!, Current loss: tensor(2.0464) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  48\n",
            "Train loss: tensor(0.0870)\n",
            "Train loss: tensor(0.1012)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.1136)\n",
            "Train loss: tensor(0.0909)\n",
            "Train loss: tensor(0.0635)\n",
            "Train loss: tensor(0.0953)\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.1169)\n",
            "Train loss: tensor(0.0896)\n",
            "Train loss: tensor(0.1201)\n",
            "Train loss: tensor(0.1113)\n",
            "Train loss: tensor(0.0976)\n",
            "Train loss: tensor(0.1236)\n",
            "Train loss: tensor(0.1427)\n",
            "Train loss: tensor(0.0905)\n",
            "Train loss: tensor(0.0929)\n",
            "Train loss: tensor(0.0685)\n",
            "Train loss: tensor(0.0615)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0971)\n",
            "Train loss: tensor(0.0983)\n",
            "Train loss: tensor(0.1077)\n",
            "Train loss: tensor(0.1013)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.0722)\n",
            "Train loss: tensor(0.1496)\n",
            "Train loss: tensor(0.1227)\n",
            "Train loss: tensor(0.1317)\n",
            "Train loss: tensor(0.0619)\n",
            "Train loss: tensor(0.0951)\n",
            "Train loss: tensor(0.0844)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0888)\n",
            "Train loss: tensor(0.0934)\n",
            "Train loss: tensor(0.1004)\n",
            "Train loss: tensor(0.1012)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.0704)\n",
            "Train loss: tensor(0.0853)\n",
            "Train loss: tensor(0.0998)\n",
            "Model is bad!, Current loss: tensor(2.4231) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  49\n",
            "Train loss: tensor(0.0712)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.0770)\n",
            "Train loss: tensor(0.0951)\n",
            "Train loss: tensor(0.1100)\n",
            "Train loss: tensor(0.0884)\n",
            "Train loss: tensor(0.0932)\n",
            "Train loss: tensor(0.1082)\n",
            "Train loss: tensor(0.1062)\n",
            "Train loss: tensor(0.1121)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.1169)\n",
            "Train loss: tensor(0.0982)\n",
            "Train loss: tensor(0.0627)\n",
            "Train loss: tensor(0.1064)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0971)\n",
            "Train loss: tensor(0.1051)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.1107)\n",
            "Train loss: tensor(0.1038)\n",
            "Train loss: tensor(0.0878)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.1186)\n",
            "Train loss: tensor(0.1730)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0936)\n",
            "Train loss: tensor(0.0669)\n",
            "Train loss: tensor(0.0849)\n",
            "Train loss: tensor(0.1355)\n",
            "Train loss: tensor(0.0798)\n",
            "Train loss: tensor(0.0957)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.1413)\n",
            "Train loss: tensor(0.0701)\n",
            "Train loss: tensor(0.1059)\n",
            "Train loss: tensor(0.0808)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.0657)\n",
            "Train loss: tensor(0.0916)\n",
            "Model is bad!, Current loss: tensor(4.4527) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  50\n",
            "Train loss: tensor(0.0895)\n",
            "Train loss: tensor(0.0614)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.0864)\n",
            "Train loss: tensor(0.0788)\n",
            "Train loss: tensor(0.0930)\n",
            "Train loss: tensor(0.1167)\n",
            "Train loss: tensor(0.0789)\n",
            "Train loss: tensor(0.0831)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.0640)\n",
            "Train loss: tensor(0.1128)\n",
            "Train loss: tensor(0.1158)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.1203)\n",
            "Train loss: tensor(0.1152)\n",
            "Train loss: tensor(0.1112)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.0783)\n",
            "Train loss: tensor(0.0849)\n",
            "Train loss: tensor(0.0716)\n",
            "Train loss: tensor(0.1228)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.1107)\n",
            "Train loss: tensor(0.1047)\n",
            "Train loss: tensor(0.1079)\n",
            "Train loss: tensor(0.0782)\n",
            "Train loss: tensor(0.1003)\n",
            "Train loss: tensor(0.1164)\n",
            "Train loss: tensor(0.0718)\n",
            "Train loss: tensor(0.0667)\n",
            "Train loss: tensor(0.1149)\n",
            "Train loss: tensor(0.0883)\n",
            "Train loss: tensor(0.1288)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.1226)\n",
            "Train loss: tensor(0.0761)\n",
            "Train loss: tensor(0.1042)\n",
            "Train loss: tensor(0.0848)\n",
            "Model is bad!, Current loss: tensor(4.3186) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  51\n",
            "Train loss: tensor(0.1052)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.1023)\n",
            "Train loss: tensor(0.0947)\n",
            "Train loss: tensor(0.0798)\n",
            "Train loss: tensor(0.1335)\n",
            "Train loss: tensor(0.0660)\n",
            "Train loss: tensor(0.1174)\n",
            "Train loss: tensor(0.1087)\n",
            "Train loss: tensor(0.0932)\n",
            "Train loss: tensor(0.1275)\n",
            "Train loss: tensor(0.1042)\n",
            "Train loss: tensor(0.0895)\n",
            "Train loss: tensor(0.0837)\n",
            "Train loss: tensor(0.0779)\n",
            "Train loss: tensor(0.1225)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.1368)\n",
            "Train loss: tensor(0.1043)\n",
            "Train loss: tensor(0.0863)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.0832)\n",
            "Train loss: tensor(0.0816)\n",
            "Train loss: tensor(0.0705)\n",
            "Train loss: tensor(0.1003)\n",
            "Train loss: tensor(0.1181)\n",
            "Train loss: tensor(0.0955)\n",
            "Train loss: tensor(0.0621)\n",
            "Train loss: tensor(0.0742)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.1249)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.1150)\n",
            "Train loss: tensor(0.0608)\n",
            "Train loss: tensor(0.0863)\n",
            "Train loss: tensor(0.0802)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.1340)\n",
            "Train loss: tensor(0.0921)\n",
            "Model is bad!, Current loss: tensor(3.3638) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  52\n",
            "Train loss: tensor(0.0955)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.0993)\n",
            "Train loss: tensor(0.1130)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0810)\n",
            "Train loss: tensor(0.0858)\n",
            "Train loss: tensor(0.1250)\n",
            "Train loss: tensor(0.1016)\n",
            "Train loss: tensor(0.0916)\n",
            "Train loss: tensor(0.0956)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.0805)\n",
            "Train loss: tensor(0.0791)\n",
            "Train loss: tensor(0.0959)\n",
            "Train loss: tensor(0.1259)\n",
            "Train loss: tensor(0.0737)\n",
            "Train loss: tensor(0.0978)\n",
            "Train loss: tensor(0.0840)\n",
            "Train loss: tensor(0.0878)\n",
            "Train loss: tensor(0.0750)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.0984)\n",
            "Train loss: tensor(0.0997)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.1047)\n",
            "Train loss: tensor(0.1393)\n",
            "Train loss: tensor(0.0710)\n",
            "Train loss: tensor(0.0627)\n",
            "Train loss: tensor(0.1056)\n",
            "Train loss: tensor(0.0944)\n",
            "Train loss: tensor(0.0619)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.0973)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.0667)\n",
            "Train loss: tensor(0.0642)\n",
            "Train loss: tensor(0.1252)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.0759)\n",
            "Model is bad!, Current loss: tensor(1.9547) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  53\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.1028)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.1307)\n",
            "Train loss: tensor(0.0982)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.0934)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0704)\n",
            "Train loss: tensor(0.0781)\n",
            "Train loss: tensor(0.0888)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0848)\n",
            "Train loss: tensor(0.0599)\n",
            "Train loss: tensor(0.0930)\n",
            "Train loss: tensor(0.0603)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.1314)\n",
            "Train loss: tensor(0.0691)\n",
            "Train loss: tensor(0.0664)\n",
            "Train loss: tensor(0.1037)\n",
            "Train loss: tensor(0.1077)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.0723)\n",
            "Train loss: tensor(0.1049)\n",
            "Train loss: tensor(0.0877)\n",
            "Train loss: tensor(0.0710)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.1166)\n",
            "Train loss: tensor(0.0711)\n",
            "Train loss: tensor(0.1090)\n",
            "Train loss: tensor(0.1034)\n",
            "Train loss: tensor(0.0897)\n",
            "Train loss: tensor(0.0916)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.1158)\n",
            "Train loss: tensor(0.0942)\n",
            "Model is bad!, Current loss: tensor(3.5764) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  54\n",
            "Train loss: tensor(0.0790)\n",
            "Train loss: tensor(0.1106)\n",
            "Train loss: tensor(0.0862)\n",
            "Train loss: tensor(0.0850)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.0873)\n",
            "Train loss: tensor(0.0925)\n",
            "Train loss: tensor(0.0835)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.0657)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.0846)\n",
            "Train loss: tensor(0.1195)\n",
            "Train loss: tensor(0.1117)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.0976)\n",
            "Train loss: tensor(0.1167)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.0857)\n",
            "Train loss: tensor(0.1035)\n",
            "Train loss: tensor(0.0987)\n",
            "Train loss: tensor(0.0955)\n",
            "Train loss: tensor(0.0939)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.0599)\n",
            "Train loss: tensor(0.0847)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.0849)\n",
            "Train loss: tensor(0.0625)\n",
            "Train loss: tensor(0.1055)\n",
            "Train loss: tensor(0.0697)\n",
            "Train loss: tensor(0.0944)\n",
            "Train loss: tensor(0.0732)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0602)\n",
            "Train loss: tensor(0.1041)\n",
            "Train loss: tensor(0.0752)\n",
            "Train loss: tensor(0.0704)\n",
            "Train loss: tensor(0.1378)\n",
            "Model is bad!, Current loss: tensor(2.3994) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  55\n",
            "Train loss: tensor(0.0823)\n",
            "Train loss: tensor(0.0896)\n",
            "Train loss: tensor(0.1335)\n",
            "Train loss: tensor(0.1051)\n",
            "Train loss: tensor(0.0919)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.0643)\n",
            "Train loss: tensor(0.1109)\n",
            "Train loss: tensor(0.0900)\n",
            "Train loss: tensor(0.1086)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.1165)\n",
            "Train loss: tensor(0.0708)\n",
            "Train loss: tensor(0.0921)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0945)\n",
            "Train loss: tensor(0.1408)\n",
            "Train loss: tensor(0.0922)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.0856)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.1076)\n",
            "Train loss: tensor(0.0591)\n",
            "Train loss: tensor(0.0996)\n",
            "Train loss: tensor(0.1107)\n",
            "Train loss: tensor(0.0852)\n",
            "Train loss: tensor(0.0615)\n",
            "Train loss: tensor(0.0774)\n",
            "Train loss: tensor(0.1276)\n",
            "Train loss: tensor(0.0611)\n",
            "Train loss: tensor(0.0603)\n",
            "Train loss: tensor(0.0761)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.0995)\n",
            "Train loss: tensor(0.1033)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.1094)\n",
            "Train loss: tensor(0.0903)\n",
            "Train loss: tensor(0.0898)\n",
            "Train loss: tensor(0.0704)\n",
            "Train loss: tensor(0.0773)\n",
            "Model is bad!, Current loss: tensor(4.0914) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  56\n",
            "Train loss: tensor(0.0671)\n",
            "Train loss: tensor(0.0745)\n",
            "Train loss: tensor(0.0963)\n",
            "Train loss: tensor(0.0902)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.1137)\n",
            "Train loss: tensor(0.0685)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.1153)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.0840)\n",
            "Train loss: tensor(0.0764)\n",
            "Train loss: tensor(0.0830)\n",
            "Train loss: tensor(0.0753)\n",
            "Train loss: tensor(0.0599)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.1096)\n",
            "Train loss: tensor(0.0929)\n",
            "Train loss: tensor(0.1019)\n",
            "Train loss: tensor(0.0954)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.1050)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.1210)\n",
            "Train loss: tensor(0.1166)\n",
            "Train loss: tensor(0.1162)\n",
            "Train loss: tensor(0.0884)\n",
            "Train loss: tensor(0.0709)\n",
            "Train loss: tensor(0.1241)\n",
            "Train loss: tensor(0.0983)\n",
            "Train loss: tensor(0.1117)\n",
            "Train loss: tensor(0.1123)\n",
            "Train loss: tensor(0.0948)\n",
            "Train loss: tensor(0.0841)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.0657)\n",
            "Train loss: tensor(0.0839)\n",
            "Train loss: tensor(0.0601)\n",
            "Train loss: tensor(0.1112)\n",
            "Model is bad!, Current loss: tensor(2.6685) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  57\n",
            "Train loss: tensor(0.1138)\n",
            "Train loss: tensor(0.1039)\n",
            "Train loss: tensor(0.0861)\n",
            "Train loss: tensor(0.1043)\n",
            "Train loss: tensor(0.0748)\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.0605)\n",
            "Train loss: tensor(0.0790)\n",
            "Train loss: tensor(0.0870)\n",
            "Train loss: tensor(0.1426)\n",
            "Train loss: tensor(0.0726)\n",
            "Train loss: tensor(0.0981)\n",
            "Train loss: tensor(0.0900)\n",
            "Train loss: tensor(0.1535)\n",
            "Train loss: tensor(0.1264)\n",
            "Train loss: tensor(0.0869)\n",
            "Train loss: tensor(0.0960)\n",
            "Train loss: tensor(0.0950)\n",
            "Train loss: tensor(0.1070)\n",
            "Train loss: tensor(0.0739)\n",
            "Train loss: tensor(0.1195)\n",
            "Train loss: tensor(0.1114)\n",
            "Train loss: tensor(0.1614)\n",
            "Train loss: tensor(0.1008)\n",
            "Train loss: tensor(0.1747)\n",
            "Train loss: tensor(0.1419)\n",
            "Train loss: tensor(0.1357)\n",
            "Train loss: tensor(0.0659)\n",
            "Train loss: tensor(0.0675)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.1360)\n",
            "Train loss: tensor(0.1725)\n",
            "Train loss: tensor(0.1051)\n",
            "Train loss: tensor(0.0981)\n",
            "Train loss: tensor(0.1005)\n",
            "Train loss: tensor(0.0948)\n",
            "Train loss: tensor(0.1158)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.1083)\n",
            "Train loss: tensor(0.0953)\n",
            "Train loss: tensor(0.0930)\n",
            "Model is bad!, Current loss: tensor(4.7165) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  58\n",
            "Train loss: tensor(0.0976)\n",
            "Train loss: tensor(0.1026)\n",
            "Train loss: tensor(0.0889)\n",
            "Train loss: tensor(0.1821)\n",
            "Train loss: tensor(0.0785)\n",
            "Train loss: tensor(0.0652)\n",
            "Train loss: tensor(0.0993)\n",
            "Train loss: tensor(0.0923)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.0914)\n",
            "Train loss: tensor(0.0988)\n",
            "Train loss: tensor(0.1418)\n",
            "Train loss: tensor(0.0654)\n",
            "Train loss: tensor(0.1195)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.1073)\n",
            "Train loss: tensor(0.1267)\n",
            "Train loss: tensor(0.1476)\n",
            "Train loss: tensor(0.1158)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.1013)\n",
            "Train loss: tensor(0.1003)\n",
            "Train loss: tensor(0.0962)\n",
            "Train loss: tensor(0.1106)\n",
            "Train loss: tensor(0.0879)\n",
            "Train loss: tensor(0.1045)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.1018)\n",
            "Train loss: tensor(0.1026)\n",
            "Train loss: tensor(0.0949)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.1638)\n",
            "Train loss: tensor(0.0904)\n",
            "Train loss: tensor(0.0969)\n",
            "Train loss: tensor(0.1115)\n",
            "Train loss: tensor(0.0909)\n",
            "Train loss: tensor(0.1652)\n",
            "Train loss: tensor(0.1039)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.1635)\n",
            "Model is bad!, Current loss: tensor(2.7151) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  59\n",
            "Train loss: tensor(0.1236)\n",
            "Train loss: tensor(0.1102)\n",
            "Train loss: tensor(0.0934)\n",
            "Train loss: tensor(0.1348)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.0686)\n",
            "Train loss: tensor(0.0843)\n",
            "Train loss: tensor(0.0778)\n",
            "Train loss: tensor(0.1091)\n",
            "Train loss: tensor(0.1384)\n",
            "Train loss: tensor(0.0721)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.0921)\n",
            "Train loss: tensor(0.1133)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.0651)\n",
            "Train loss: tensor(0.1837)\n",
            "Train loss: tensor(0.1006)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.1000)\n",
            "Train loss: tensor(0.0993)\n",
            "Train loss: tensor(0.1317)\n",
            "Train loss: tensor(0.1293)\n",
            "Train loss: tensor(0.1025)\n",
            "Train loss: tensor(0.0757)\n",
            "Train loss: tensor(0.1190)\n",
            "Train loss: tensor(0.0739)\n",
            "Train loss: tensor(0.1014)\n",
            "Train loss: tensor(0.1430)\n",
            "Train loss: tensor(0.0904)\n",
            "Train loss: tensor(0.0878)\n",
            "Train loss: tensor(0.1064)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0856)\n",
            "Train loss: tensor(0.1308)\n",
            "Train loss: tensor(0.0933)\n",
            "Train loss: tensor(0.1136)\n",
            "Train loss: tensor(0.1047)\n",
            "Train loss: tensor(0.0869)\n",
            "Train loss: tensor(0.1063)\n",
            "Train loss: tensor(0.1073)\n",
            "Model is bad!, Current loss: tensor(2.2700) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  60\n",
            "Train loss: tensor(0.1236)\n",
            "Train loss: tensor(0.0962)\n",
            "Train loss: tensor(0.1031)\n",
            "Train loss: tensor(0.0989)\n",
            "Train loss: tensor(0.0882)\n",
            "Train loss: tensor(0.0768)\n",
            "Train loss: tensor(0.0692)\n",
            "Train loss: tensor(0.0732)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.0912)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.0660)\n",
            "Train loss: tensor(0.0859)\n",
            "Train loss: tensor(0.1017)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.0760)\n",
            "Train loss: tensor(0.0987)\n",
            "Train loss: tensor(0.0758)\n",
            "Train loss: tensor(0.0956)\n",
            "Train loss: tensor(0.0942)\n",
            "Train loss: tensor(0.1291)\n",
            "Train loss: tensor(0.0837)\n",
            "Train loss: tensor(0.0716)\n",
            "Train loss: tensor(0.1133)\n",
            "Train loss: tensor(0.0652)\n",
            "Train loss: tensor(0.1132)\n",
            "Train loss: tensor(0.1109)\n",
            "Train loss: tensor(0.1099)\n",
            "Train loss: tensor(0.0877)\n",
            "Train loss: tensor(0.1117)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.0945)\n",
            "Train loss: tensor(0.0615)\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.1174)\n",
            "Train loss: tensor(0.1208)\n",
            "Train loss: tensor(0.0720)\n",
            "Train loss: tensor(0.0848)\n",
            "Train loss: tensor(0.1089)\n",
            "Model is bad!, Current loss: tensor(2.8149) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  61\n",
            "Train loss: tensor(0.0659)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.1232)\n",
            "Train loss: tensor(0.1059)\n",
            "Train loss: tensor(0.0856)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.0981)\n",
            "Train loss: tensor(0.0870)\n",
            "Train loss: tensor(0.1036)\n",
            "Train loss: tensor(0.0789)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.1118)\n",
            "Train loss: tensor(0.0625)\n",
            "Train loss: tensor(0.1098)\n",
            "Train loss: tensor(0.0824)\n",
            "Train loss: tensor(0.0902)\n",
            "Train loss: tensor(0.0850)\n",
            "Train loss: tensor(0.0891)\n",
            "Train loss: tensor(0.0852)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.1012)\n",
            "Train loss: tensor(0.0883)\n",
            "Train loss: tensor(0.0820)\n",
            "Train loss: tensor(0.0811)\n",
            "Train loss: tensor(0.1165)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.0644)\n",
            "Train loss: tensor(0.0808)\n",
            "Train loss: tensor(0.1267)\n",
            "Train loss: tensor(0.0631)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.1282)\n",
            "Train loss: tensor(0.0856)\n",
            "Train loss: tensor(0.0744)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.0862)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.0677)\n",
            "Train loss: tensor(0.0934)\n",
            "Train loss: tensor(0.1056)\n",
            "Model is bad!, Current loss: tensor(3.1658) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  62\n",
            "Train loss: tensor(0.0877)\n",
            "Train loss: tensor(0.0755)\n",
            "Train loss: tensor(0.1201)\n",
            "Train loss: tensor(0.1082)\n",
            "Train loss: tensor(0.1438)\n",
            "Train loss: tensor(0.0642)\n",
            "Train loss: tensor(0.0882)\n",
            "Train loss: tensor(0.0980)\n",
            "Train loss: tensor(0.0906)\n",
            "Train loss: tensor(0.1149)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.0945)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.0637)\n",
            "Train loss: tensor(0.0884)\n",
            "Train loss: tensor(0.1234)\n",
            "Train loss: tensor(0.0837)\n",
            "Train loss: tensor(0.0799)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.0890)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0857)\n",
            "Train loss: tensor(0.0841)\n",
            "Train loss: tensor(0.0989)\n",
            "Train loss: tensor(0.1047)\n",
            "Train loss: tensor(0.0963)\n",
            "Train loss: tensor(0.0878)\n",
            "Train loss: tensor(0.0823)\n",
            "Train loss: tensor(0.1237)\n",
            "Train loss: tensor(0.1032)\n",
            "Train loss: tensor(0.0758)\n",
            "Train loss: tensor(0.0699)\n",
            "Train loss: tensor(0.0864)\n",
            "Train loss: tensor(0.0923)\n",
            "Train loss: tensor(0.0959)\n",
            "Train loss: tensor(0.0888)\n",
            "Train loss: tensor(0.1002)\n",
            "Train loss: tensor(0.0604)\n",
            "Train loss: tensor(0.1023)\n",
            "Train loss: tensor(0.0806)\n",
            "Train loss: tensor(0.0849)\n",
            "Model is bad!, Current loss: tensor(3.3130) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  63\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.0941)\n",
            "Train loss: tensor(0.1108)\n",
            "Train loss: tensor(0.1088)\n",
            "Train loss: tensor(0.1279)\n",
            "Train loss: tensor(0.0896)\n",
            "Train loss: tensor(0.1217)\n",
            "Train loss: tensor(0.0848)\n",
            "Train loss: tensor(0.0816)\n",
            "Train loss: tensor(0.0855)\n",
            "Train loss: tensor(0.1093)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0914)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.0758)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.0831)\n",
            "Train loss: tensor(0.0779)\n",
            "Train loss: tensor(0.1099)\n",
            "Train loss: tensor(0.0856)\n",
            "Train loss: tensor(0.0647)\n",
            "Train loss: tensor(0.1049)\n",
            "Train loss: tensor(0.0879)\n",
            "Train loss: tensor(0.0888)\n",
            "Train loss: tensor(0.0656)\n",
            "Train loss: tensor(0.0609)\n",
            "Train loss: tensor(0.1329)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0825)\n",
            "Train loss: tensor(0.1101)\n",
            "Train loss: tensor(0.0782)\n",
            "Train loss: tensor(0.0953)\n",
            "Train loss: tensor(0.1298)\n",
            "Train loss: tensor(0.0682)\n",
            "Train loss: tensor(0.0843)\n",
            "Train loss: tensor(0.0757)\n",
            "Train loss: tensor(0.1191)\n",
            "Train loss: tensor(0.0974)\n",
            "Train loss: tensor(0.1041)\n",
            "Train loss: tensor(0.0624)\n",
            "Model is bad!, Current loss: tensor(8.2244) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.5\n",
            "Epoch:  64\n",
            "Train loss: tensor(0.1099)\n",
            "Train loss: tensor(0.0667)\n",
            "Train loss: tensor(0.0590)\n",
            "Train loss: tensor(0.1008)\n",
            "Train loss: tensor(0.1098)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.0791)\n",
            "Train loss: tensor(0.0802)\n",
            "Train loss: tensor(0.0735)\n",
            "Train loss: tensor(0.1227)\n",
            "Train loss: tensor(0.0882)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.1125)\n",
            "Train loss: tensor(0.1020)\n",
            "Train loss: tensor(0.1052)\n",
            "Train loss: tensor(0.0921)\n",
            "Train loss: tensor(0.0978)\n",
            "Train loss: tensor(0.1594)\n",
            "Train loss: tensor(0.0715)\n",
            "Train loss: tensor(0.0793)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.1110)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.0607)\n",
            "Train loss: tensor(0.0964)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.1262)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.0864)\n",
            "Train loss: tensor(0.0732)\n",
            "Train loss: tensor(0.0833)\n",
            "Train loss: tensor(0.0824)\n",
            "Train loss: tensor(0.0639)\n",
            "Train loss: tensor(0.1118)\n",
            "Train loss: tensor(0.0709)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.0960)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.0881)\n",
            "Model is bad!, Current loss: tensor(5.0399) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  65\n",
            "Train loss: tensor(0.0947)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.1019)\n",
            "Train loss: tensor(0.0608)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.0913)\n",
            "Train loss: tensor(0.1255)\n",
            "Train loss: tensor(0.0855)\n",
            "Train loss: tensor(0.0919)\n",
            "Train loss: tensor(0.1106)\n",
            "Train loss: tensor(0.1108)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0934)\n",
            "Train loss: tensor(0.0920)\n",
            "Train loss: tensor(0.0925)\n",
            "Train loss: tensor(0.1034)\n",
            "Train loss: tensor(0.1094)\n",
            "Train loss: tensor(0.0906)\n",
            "Train loss: tensor(0.1254)\n",
            "Train loss: tensor(0.0825)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.1133)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.1417)\n",
            "Train loss: tensor(0.0913)\n",
            "Train loss: tensor(0.0984)\n",
            "Train loss: tensor(0.1105)\n",
            "Train loss: tensor(0.0796)\n",
            "Train loss: tensor(0.0923)\n",
            "Train loss: tensor(0.1137)\n",
            "Train loss: tensor(0.0853)\n",
            "Train loss: tensor(0.1367)\n",
            "Train loss: tensor(0.0660)\n",
            "Train loss: tensor(0.0833)\n",
            "Train loss: tensor(0.1064)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.0611)\n",
            "Train loss: tensor(0.1321)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.1085)\n",
            "Model is bad!, Current loss: tensor(2.8405) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  66\n",
            "Train loss: tensor(0.0631)\n",
            "Train loss: tensor(0.1112)\n",
            "Train loss: tensor(0.1177)\n",
            "Train loss: tensor(0.0718)\n",
            "Train loss: tensor(0.0792)\n",
            "Train loss: tensor(0.0942)\n",
            "Train loss: tensor(0.1048)\n",
            "Train loss: tensor(0.1153)\n",
            "Train loss: tensor(0.0895)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.0669)\n",
            "Train loss: tensor(0.1081)\n",
            "Train loss: tensor(0.0910)\n",
            "Train loss: tensor(0.1401)\n",
            "Train loss: tensor(0.1141)\n",
            "Train loss: tensor(0.0776)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.1083)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.0986)\n",
            "Train loss: tensor(0.0853)\n",
            "Train loss: tensor(0.1023)\n",
            "Train loss: tensor(0.1132)\n",
            "Train loss: tensor(0.0883)\n",
            "Train loss: tensor(0.0673)\n",
            "Train loss: tensor(0.0900)\n",
            "Train loss: tensor(0.0857)\n",
            "Train loss: tensor(0.0903)\n",
            "Train loss: tensor(0.1079)\n",
            "Train loss: tensor(0.0839)\n",
            "Train loss: tensor(0.0619)\n",
            "Train loss: tensor(0.1418)\n",
            "Train loss: tensor(0.0760)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.0586)\n",
            "Train loss: tensor(0.0793)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.0963)\n",
            "Train loss: tensor(0.0950)\n",
            "Train loss: tensor(0.0919)\n",
            "Model is bad!, Current loss: tensor(3.7051) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  67\n",
            "Train loss: tensor(0.0848)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.1444)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.0890)\n",
            "Train loss: tensor(0.0918)\n",
            "Train loss: tensor(0.0811)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0979)\n",
            "Train loss: tensor(0.0876)\n",
            "Train loss: tensor(0.0620)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.0726)\n",
            "Train loss: tensor(0.0910)\n",
            "Train loss: tensor(0.0835)\n",
            "Train loss: tensor(0.0759)\n",
            "Train loss: tensor(0.0697)\n",
            "Train loss: tensor(0.0742)\n",
            "Train loss: tensor(0.1276)\n",
            "Train loss: tensor(0.1676)\n",
            "Train loss: tensor(0.1148)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.1113)\n",
            "Train loss: tensor(0.1027)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.1383)\n",
            "Train loss: tensor(0.0829)\n",
            "Train loss: tensor(0.1092)\n",
            "Train loss: tensor(0.0603)\n",
            "Train loss: tensor(0.0951)\n",
            "Train loss: tensor(0.0830)\n",
            "Train loss: tensor(0.1302)\n",
            "Train loss: tensor(0.1073)\n",
            "Train loss: tensor(0.0997)\n",
            "Train loss: tensor(0.1234)\n",
            "Train loss: tensor(0.0597)\n",
            "Train loss: tensor(0.1212)\n",
            "Train loss: tensor(0.1314)\n",
            "Train loss: tensor(0.0984)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0964)\n",
            "Model is bad!, Current loss: tensor(3.2033) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  68\n",
            "Train loss: tensor(0.0840)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.0872)\n",
            "Train loss: tensor(0.0782)\n",
            "Train loss: tensor(0.0925)\n",
            "Train loss: tensor(0.0640)\n",
            "Train loss: tensor(0.0941)\n",
            "Train loss: tensor(0.0820)\n",
            "Train loss: tensor(0.1021)\n",
            "Train loss: tensor(0.0895)\n",
            "Train loss: tensor(0.0732)\n",
            "Train loss: tensor(0.1498)\n",
            "Train loss: tensor(0.0766)\n",
            "Train loss: tensor(0.0684)\n",
            "Train loss: tensor(0.0848)\n",
            "Train loss: tensor(0.1022)\n",
            "Train loss: tensor(0.1334)\n",
            "Train loss: tensor(0.0850)\n",
            "Train loss: tensor(0.0839)\n",
            "Train loss: tensor(0.0687)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.0782)\n",
            "Train loss: tensor(0.0968)\n",
            "Train loss: tensor(0.0767)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.1085)\n",
            "Train loss: tensor(0.0916)\n",
            "Train loss: tensor(0.0857)\n",
            "Train loss: tensor(0.0924)\n",
            "Train loss: tensor(0.0731)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.0886)\n",
            "Train loss: tensor(0.0675)\n",
            "Train loss: tensor(0.0968)\n",
            "Train loss: tensor(0.1058)\n",
            "Train loss: tensor(0.0953)\n",
            "Train loss: tensor(0.1468)\n",
            "Train loss: tensor(0.1000)\n",
            "Train loss: tensor(0.0849)\n",
            "Train loss: tensor(0.0849)\n",
            "Train loss: tensor(0.1293)\n",
            "Model is bad!, Current loss: tensor(4.5118) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  69\n",
            "Train loss: tensor(0.0664)\n",
            "Train loss: tensor(0.0860)\n",
            "Train loss: tensor(0.1112)\n",
            "Train loss: tensor(0.0930)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.0753)\n",
            "Train loss: tensor(0.0773)\n",
            "Train loss: tensor(0.1023)\n",
            "Train loss: tensor(0.0882)\n",
            "Train loss: tensor(0.0643)\n",
            "Train loss: tensor(0.1101)\n",
            "Train loss: tensor(0.1101)\n",
            "Train loss: tensor(0.1173)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.1108)\n",
            "Train loss: tensor(0.0752)\n",
            "Train loss: tensor(0.0764)\n",
            "Train loss: tensor(0.0864)\n",
            "Train loss: tensor(0.0929)\n",
            "Train loss: tensor(0.0822)\n",
            "Train loss: tensor(0.0872)\n",
            "Train loss: tensor(0.1140)\n",
            "Train loss: tensor(0.1141)\n",
            "Train loss: tensor(0.1088)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.0844)\n",
            "Train loss: tensor(0.0647)\n",
            "Train loss: tensor(0.0759)\n",
            "Train loss: tensor(0.1191)\n",
            "Train loss: tensor(0.1022)\n",
            "Train loss: tensor(0.0997)\n",
            "Train loss: tensor(0.0802)\n",
            "Train loss: tensor(0.0700)\n",
            "Train loss: tensor(0.1148)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.0933)\n",
            "Train loss: tensor(0.1059)\n",
            "Train loss: tensor(0.0613)\n",
            "Train loss: tensor(0.0791)\n",
            "Train loss: tensor(0.0895)\n",
            "Train loss: tensor(0.0835)\n",
            "Model is bad!, Current loss: tensor(2.7565) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  70\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.0636)\n",
            "Train loss: tensor(0.0761)\n",
            "Train loss: tensor(0.0676)\n",
            "Train loss: tensor(0.0766)\n",
            "Train loss: tensor(0.0600)\n",
            "Train loss: tensor(0.0967)\n",
            "Train loss: tensor(0.0613)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0730)\n",
            "Train loss: tensor(0.1043)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.0684)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.0916)\n",
            "Train loss: tensor(0.0884)\n",
            "Train loss: tensor(0.0938)\n",
            "Train loss: tensor(0.0609)\n",
            "Train loss: tensor(0.0953)\n",
            "Train loss: tensor(0.1213)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.0683)\n",
            "Train loss: tensor(0.1021)\n",
            "Train loss: tensor(0.0773)\n",
            "Train loss: tensor(0.1007)\n",
            "Train loss: tensor(0.0795)\n",
            "Train loss: tensor(0.0587)\n",
            "Train loss: tensor(0.0957)\n",
            "Train loss: tensor(0.0822)\n",
            "Train loss: tensor(0.1066)\n",
            "Train loss: tensor(0.0623)\n",
            "Train loss: tensor(0.1531)\n",
            "Train loss: tensor(0.1060)\n",
            "Train loss: tensor(0.0864)\n",
            "Train loss: tensor(0.0995)\n",
            "Train loss: tensor(0.0769)\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.1137)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.1350)\n",
            "Model is bad!, Current loss: tensor(2.6752) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  71\n",
            "Train loss: tensor(0.1081)\n",
            "Train loss: tensor(0.0711)\n",
            "Train loss: tensor(0.0971)\n",
            "Train loss: tensor(0.1187)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.0987)\n",
            "Train loss: tensor(0.0832)\n",
            "Train loss: tensor(0.1347)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.0600)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.1086)\n",
            "Train loss: tensor(0.0576)\n",
            "Train loss: tensor(0.0705)\n",
            "Train loss: tensor(0.0809)\n",
            "Train loss: tensor(0.0905)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.0857)\n",
            "Train loss: tensor(0.0683)\n",
            "Train loss: tensor(0.0880)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.1012)\n",
            "Train loss: tensor(0.0920)\n",
            "Train loss: tensor(0.0752)\n",
            "Train loss: tensor(0.1161)\n",
            "Train loss: tensor(0.0566)\n",
            "Train loss: tensor(0.0739)\n",
            "Train loss: tensor(0.0932)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.0857)\n",
            "Train loss: tensor(0.0747)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.0841)\n",
            "Train loss: tensor(0.0992)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.0852)\n",
            "Train loss: tensor(0.0673)\n",
            "Train loss: tensor(0.0705)\n",
            "Model is bad!, Current loss: tensor(2.7104) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  72\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0846)\n",
            "Train loss: tensor(0.1060)\n",
            "Train loss: tensor(0.0708)\n",
            "Train loss: tensor(0.0714)\n",
            "Train loss: tensor(0.0801)\n",
            "Train loss: tensor(0.0990)\n",
            "Train loss: tensor(0.0579)\n",
            "Train loss: tensor(0.1187)\n",
            "Train loss: tensor(0.0551)\n",
            "Train loss: tensor(0.0735)\n",
            "Train loss: tensor(0.0966)\n",
            "Train loss: tensor(0.0773)\n",
            "Train loss: tensor(0.0977)\n",
            "Train loss: tensor(0.1045)\n",
            "Train loss: tensor(0.0969)\n",
            "Train loss: tensor(0.0561)\n",
            "Train loss: tensor(0.0586)\n",
            "Train loss: tensor(0.1041)\n",
            "Train loss: tensor(0.0788)\n",
            "Train loss: tensor(0.1134)\n",
            "Train loss: tensor(0.1054)\n",
            "Train loss: tensor(0.0816)\n",
            "Train loss: tensor(0.0745)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0697)\n",
            "Train loss: tensor(0.0960)\n",
            "Train loss: tensor(0.0768)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0587)\n",
            "Train loss: tensor(0.1126)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0948)\n",
            "Train loss: tensor(0.0726)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0945)\n",
            "Train loss: tensor(0.0840)\n",
            "Train loss: tensor(0.0691)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0951)\n",
            "Train loss: tensor(0.0947)\n",
            "Model is bad!, Current loss: tensor(3.4654) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  73\n",
            "Train loss: tensor(0.0950)\n",
            "Train loss: tensor(0.0741)\n",
            "Train loss: tensor(0.0757)\n",
            "Train loss: tensor(0.0661)\n",
            "Train loss: tensor(0.1007)\n",
            "Train loss: tensor(0.0916)\n",
            "Train loss: tensor(0.0994)\n",
            "Train loss: tensor(0.0730)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0919)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0855)\n",
            "Train loss: tensor(0.1055)\n",
            "Train loss: tensor(0.0579)\n",
            "Train loss: tensor(0.1282)\n",
            "Train loss: tensor(0.0876)\n",
            "Train loss: tensor(0.0811)\n",
            "Train loss: tensor(0.0698)\n",
            "Train loss: tensor(0.0693)\n",
            "Train loss: tensor(0.0558)\n",
            "Train loss: tensor(0.0754)\n",
            "Train loss: tensor(0.0732)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.0831)\n",
            "Train loss: tensor(0.0732)\n",
            "Train loss: tensor(0.0986)\n",
            "Train loss: tensor(0.1043)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.0837)\n",
            "Train loss: tensor(0.0779)\n",
            "Train loss: tensor(0.1186)\n",
            "Train loss: tensor(0.0628)\n",
            "Train loss: tensor(0.1020)\n",
            "Train loss: tensor(0.0609)\n",
            "Train loss: tensor(0.0937)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.0732)\n",
            "Train loss: tensor(0.0802)\n",
            "Train loss: tensor(0.0973)\n",
            "Train loss: tensor(0.0572)\n",
            "Train loss: tensor(0.1231)\n",
            "Model is bad!, Current loss: tensor(2.4651) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  74\n",
            "Train loss: tensor(0.0872)\n",
            "Train loss: tensor(0.0865)\n",
            "Train loss: tensor(0.0855)\n",
            "Train loss: tensor(0.0799)\n",
            "Train loss: tensor(0.0758)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.1045)\n",
            "Train loss: tensor(0.0895)\n",
            "Train loss: tensor(0.0607)\n",
            "Train loss: tensor(0.0967)\n",
            "Train loss: tensor(0.0989)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0785)\n",
            "Train loss: tensor(0.0639)\n",
            "Train loss: tensor(0.0805)\n",
            "Train loss: tensor(0.0592)\n",
            "Train loss: tensor(0.0601)\n",
            "Train loss: tensor(0.1209)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0775)\n",
            "Train loss: tensor(0.1113)\n",
            "Train loss: tensor(0.1033)\n",
            "Train loss: tensor(0.0583)\n",
            "Train loss: tensor(0.0924)\n",
            "Train loss: tensor(0.0616)\n",
            "Train loss: tensor(0.0796)\n",
            "Train loss: tensor(0.0630)\n",
            "Train loss: tensor(0.0977)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.0906)\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.0710)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.0762)\n",
            "Train loss: tensor(0.0832)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.1064)\n",
            "Train loss: tensor(0.1148)\n",
            "Train loss: tensor(0.0873)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.0766)\n",
            "Model is bad!, Current loss: tensor(5.3172) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  75\n",
            "Train loss: tensor(0.0723)\n",
            "Train loss: tensor(0.0598)\n",
            "Train loss: tensor(0.0656)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.0889)\n",
            "Train loss: tensor(0.0773)\n",
            "Train loss: tensor(0.0737)\n",
            "Train loss: tensor(0.0756)\n",
            "Train loss: tensor(0.0762)\n",
            "Train loss: tensor(0.0774)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.0637)\n",
            "Train loss: tensor(0.1026)\n",
            "Train loss: tensor(0.0997)\n",
            "Train loss: tensor(0.1157)\n",
            "Train loss: tensor(0.0750)\n",
            "Train loss: tensor(0.0833)\n",
            "Train loss: tensor(0.1123)\n",
            "Train loss: tensor(0.0756)\n",
            "Train loss: tensor(0.0695)\n",
            "Train loss: tensor(0.0744)\n",
            "Train loss: tensor(0.0757)\n",
            "Train loss: tensor(0.0735)\n",
            "Train loss: tensor(0.1036)\n",
            "Train loss: tensor(0.0561)\n",
            "Train loss: tensor(0.1143)\n",
            "Train loss: tensor(0.0878)\n",
            "Train loss: tensor(0.1314)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0906)\n",
            "Train loss: tensor(0.0769)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.0823)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.0745)\n",
            "Train loss: tensor(0.0752)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0761)\n",
            "Train loss: tensor(0.0565)\n",
            "Train loss: tensor(0.0819)\n",
            "Model is bad!, Current loss: tensor(4.0024) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  76\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.1016)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.1029)\n",
            "Train loss: tensor(0.0870)\n",
            "Train loss: tensor(0.0768)\n",
            "Train loss: tensor(0.0777)\n",
            "Train loss: tensor(0.0744)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.0922)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.0585)\n",
            "Train loss: tensor(0.1279)\n",
            "Train loss: tensor(0.0642)\n",
            "Train loss: tensor(0.0634)\n",
            "Train loss: tensor(0.1447)\n",
            "Train loss: tensor(0.0824)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.0696)\n",
            "Train loss: tensor(0.0710)\n",
            "Train loss: tensor(0.0905)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.0756)\n",
            "Train loss: tensor(0.0636)\n",
            "Train loss: tensor(0.0858)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.0817)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.0999)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.0562)\n",
            "Train loss: tensor(0.0720)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.0832)\n",
            "Train loss: tensor(0.0577)\n",
            "Train loss: tensor(0.0782)\n",
            "Train loss: tensor(0.0623)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.1120)\n",
            "Train loss: tensor(0.0764)\n",
            "Train loss: tensor(0.0785)\n",
            "Model is bad!, Current loss: tensor(3.1764) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  77\n",
            "Train loss: tensor(0.0883)\n",
            "Train loss: tensor(0.0654)\n",
            "Train loss: tensor(0.0764)\n",
            "Train loss: tensor(0.0686)\n",
            "Train loss: tensor(0.1170)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0668)\n",
            "Train loss: tensor(0.1186)\n",
            "Train loss: tensor(0.0585)\n",
            "Train loss: tensor(0.0697)\n",
            "Train loss: tensor(0.0738)\n",
            "Train loss: tensor(0.0570)\n",
            "Train loss: tensor(0.1084)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0781)\n",
            "Train loss: tensor(0.0770)\n",
            "Train loss: tensor(0.0758)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.0799)\n",
            "Train loss: tensor(0.0829)\n",
            "Train loss: tensor(0.0835)\n",
            "Train loss: tensor(0.0688)\n",
            "Train loss: tensor(0.0775)\n",
            "Train loss: tensor(0.0586)\n",
            "Train loss: tensor(0.0917)\n",
            "Train loss: tensor(0.0773)\n",
            "Train loss: tensor(0.1072)\n",
            "Train loss: tensor(0.0964)\n",
            "Train loss: tensor(0.1069)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0848)\n",
            "Train loss: tensor(0.0942)\n",
            "Train loss: tensor(0.1077)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.1042)\n",
            "Train loss: tensor(0.0790)\n",
            "Train loss: tensor(0.0745)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.1033)\n",
            "Train loss: tensor(0.0812)\n",
            "Model is bad!, Current loss: tensor(2.6745) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  78\n",
            "Train loss: tensor(0.0847)\n",
            "Train loss: tensor(0.1072)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.0938)\n",
            "Train loss: tensor(0.0904)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.1143)\n",
            "Train loss: tensor(0.0837)\n",
            "Train loss: tensor(0.0969)\n",
            "Train loss: tensor(0.0582)\n",
            "Train loss: tensor(0.0657)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0811)\n",
            "Train loss: tensor(0.0607)\n",
            "Train loss: tensor(0.1090)\n",
            "Train loss: tensor(0.0746)\n",
            "Train loss: tensor(0.0918)\n",
            "Train loss: tensor(0.0613)\n",
            "Train loss: tensor(0.0528)\n",
            "Train loss: tensor(0.0666)\n",
            "Train loss: tensor(0.0784)\n",
            "Train loss: tensor(0.0787)\n",
            "Train loss: tensor(0.0979)\n",
            "Train loss: tensor(0.0614)\n",
            "Train loss: tensor(0.0937)\n",
            "Train loss: tensor(0.0770)\n",
            "Train loss: tensor(0.0831)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.0713)\n",
            "Train loss: tensor(0.0728)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.0827)\n",
            "Train loss: tensor(0.0762)\n",
            "Train loss: tensor(0.1041)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.1217)\n",
            "Train loss: tensor(0.0737)\n",
            "Train loss: tensor(0.0707)\n",
            "Model is bad!, Current loss: tensor(3.7773) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  79\n",
            "Train loss: tensor(0.0699)\n",
            "Train loss: tensor(0.0564)\n",
            "Train loss: tensor(0.0660)\n",
            "Train loss: tensor(0.0773)\n",
            "Train loss: tensor(0.0970)\n",
            "Train loss: tensor(0.0547)\n",
            "Train loss: tensor(0.0839)\n",
            "Train loss: tensor(0.0998)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.1088)\n",
            "Train loss: tensor(0.0727)\n",
            "Train loss: tensor(0.0723)\n",
            "Train loss: tensor(0.0796)\n",
            "Train loss: tensor(0.0910)\n",
            "Train loss: tensor(0.0801)\n",
            "Train loss: tensor(0.1137)\n",
            "Train loss: tensor(0.1193)\n",
            "Train loss: tensor(0.0869)\n",
            "Train loss: tensor(0.1048)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.0758)\n",
            "Train loss: tensor(0.0840)\n",
            "Train loss: tensor(0.0659)\n",
            "Train loss: tensor(0.0567)\n",
            "Train loss: tensor(0.0837)\n",
            "Train loss: tensor(0.0844)\n",
            "Train loss: tensor(0.0657)\n",
            "Train loss: tensor(0.0756)\n",
            "Train loss: tensor(0.0767)\n",
            "Train loss: tensor(0.0912)\n",
            "Train loss: tensor(0.0890)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.0936)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0674)\n",
            "Train loss: tensor(0.0665)\n",
            "Train loss: tensor(0.0999)\n",
            "Train loss: tensor(0.0755)\n",
            "Model is bad!, Current loss: tensor(2.9754) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  80\n",
            "Train loss: tensor(0.0932)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.1224)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.0947)\n",
            "Train loss: tensor(0.0543)\n",
            "Train loss: tensor(0.0643)\n",
            "Train loss: tensor(0.0788)\n",
            "Train loss: tensor(0.1098)\n",
            "Train loss: tensor(0.0776)\n",
            "Train loss: tensor(0.0869)\n",
            "Train loss: tensor(0.0825)\n",
            "Train loss: tensor(0.0840)\n",
            "Train loss: tensor(0.0929)\n",
            "Train loss: tensor(0.0828)\n",
            "Train loss: tensor(0.1055)\n",
            "Train loss: tensor(0.0792)\n",
            "Train loss: tensor(0.0716)\n",
            "Train loss: tensor(0.0983)\n",
            "Train loss: tensor(0.1153)\n",
            "Train loss: tensor(0.0630)\n",
            "Train loss: tensor(0.0711)\n",
            "Train loss: tensor(0.0737)\n",
            "Train loss: tensor(0.1179)\n",
            "Train loss: tensor(0.0576)\n",
            "Train loss: tensor(0.0865)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.0881)\n",
            "Train loss: tensor(0.1157)\n",
            "Train loss: tensor(0.0768)\n",
            "Train loss: tensor(0.1007)\n",
            "Train loss: tensor(0.1115)\n",
            "Train loss: tensor(0.1133)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.1315)\n",
            "Train loss: tensor(0.1046)\n",
            "Train loss: tensor(0.0931)\n",
            "Train loss: tensor(0.0760)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.0973)\n",
            "Train loss: tensor(0.0866)\n",
            "Model is bad!, Current loss: tensor(5.9319) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  81\n",
            "Train loss: tensor(0.1106)\n",
            "Train loss: tensor(0.1159)\n",
            "Train loss: tensor(0.0751)\n",
            "Train loss: tensor(0.0636)\n",
            "Train loss: tensor(0.0611)\n",
            "Train loss: tensor(0.0876)\n",
            "Train loss: tensor(0.0781)\n",
            "Train loss: tensor(0.1206)\n",
            "Train loss: tensor(0.0739)\n",
            "Train loss: tensor(0.0919)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.0816)\n",
            "Train loss: tensor(0.0821)\n",
            "Train loss: tensor(0.0803)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.1010)\n",
            "Train loss: tensor(0.0659)\n",
            "Train loss: tensor(0.0663)\n",
            "Train loss: tensor(0.0679)\n",
            "Train loss: tensor(0.0775)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.0694)\n",
            "Train loss: tensor(0.0902)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.1143)\n",
            "Train loss: tensor(0.0657)\n",
            "Train loss: tensor(0.0784)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.1273)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.0840)\n",
            "Train loss: tensor(0.0680)\n",
            "Train loss: tensor(0.0850)\n",
            "Train loss: tensor(0.0886)\n",
            "Train loss: tensor(0.0780)\n",
            "Train loss: tensor(0.0817)\n",
            "Train loss: tensor(0.0992)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.0843)\n",
            "Train loss: tensor(0.0860)\n",
            "Train loss: tensor(0.0845)\n",
            "Model is bad!, Current loss: tensor(5.3398) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  82\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.1248)\n",
            "Train loss: tensor(0.0828)\n",
            "Train loss: tensor(0.1078)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.1215)\n",
            "Train loss: tensor(0.0616)\n",
            "Train loss: tensor(0.1236)\n",
            "Train loss: tensor(0.0861)\n",
            "Train loss: tensor(0.0861)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.0900)\n",
            "Train loss: tensor(0.1133)\n",
            "Train loss: tensor(0.0827)\n",
            "Train loss: tensor(0.0958)\n",
            "Train loss: tensor(0.1053)\n",
            "Train loss: tensor(0.1124)\n",
            "Train loss: tensor(0.0892)\n",
            "Train loss: tensor(0.1216)\n",
            "Train loss: tensor(0.1127)\n",
            "Train loss: tensor(0.0949)\n",
            "Train loss: tensor(0.0713)\n",
            "Train loss: tensor(0.0800)\n",
            "Train loss: tensor(0.1242)\n",
            "Train loss: tensor(0.1057)\n",
            "Train loss: tensor(0.1213)\n",
            "Train loss: tensor(0.1234)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.1180)\n",
            "Train loss: tensor(0.0652)\n",
            "Train loss: tensor(0.1363)\n",
            "Train loss: tensor(0.0816)\n",
            "Train loss: tensor(0.0869)\n",
            "Train loss: tensor(0.1627)\n",
            "Train loss: tensor(0.1050)\n",
            "Train loss: tensor(0.0938)\n",
            "Train loss: tensor(0.1020)\n",
            "Train loss: tensor(0.1365)\n",
            "Train loss: tensor(0.0959)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.0830)\n",
            "Model is bad!, Current loss: tensor(4.7205) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  83\n",
            "Train loss: tensor(0.1021)\n",
            "Train loss: tensor(0.1160)\n",
            "Train loss: tensor(0.1018)\n",
            "Train loss: tensor(0.0880)\n",
            "Train loss: tensor(0.0936)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.1001)\n",
            "Train loss: tensor(0.0726)\n",
            "Train loss: tensor(0.0657)\n",
            "Train loss: tensor(0.1075)\n",
            "Train loss: tensor(0.0619)\n",
            "Train loss: tensor(0.0797)\n",
            "Train loss: tensor(0.1143)\n",
            "Train loss: tensor(0.0788)\n",
            "Train loss: tensor(0.0896)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.1205)\n",
            "Train loss: tensor(0.1602)\n",
            "Train loss: tensor(0.0995)\n",
            "Train loss: tensor(0.0743)\n",
            "Train loss: tensor(0.1311)\n",
            "Train loss: tensor(0.1011)\n",
            "Train loss: tensor(0.0839)\n",
            "Train loss: tensor(0.1319)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.1065)\n",
            "Train loss: tensor(0.1222)\n",
            "Train loss: tensor(0.1403)\n",
            "Train loss: tensor(0.1014)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.1147)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.0613)\n",
            "Train loss: tensor(0.0884)\n",
            "Train loss: tensor(0.1189)\n",
            "Train loss: tensor(0.1098)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0908)\n",
            "Train loss: tensor(0.1213)\n",
            "Train loss: tensor(0.1202)\n",
            "Model is bad!, Current loss: tensor(2.0291) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  84\n",
            "Train loss: tensor(0.0925)\n",
            "Train loss: tensor(0.0843)\n",
            "Train loss: tensor(0.0876)\n",
            "Train loss: tensor(0.0833)\n",
            "Train loss: tensor(0.1369)\n",
            "Train loss: tensor(0.0863)\n",
            "Train loss: tensor(0.0950)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.1241)\n",
            "Train loss: tensor(0.0858)\n",
            "Train loss: tensor(0.1377)\n",
            "Train loss: tensor(0.0843)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.0972)\n",
            "Train loss: tensor(0.1483)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.0604)\n",
            "Train loss: tensor(0.0728)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.0793)\n",
            "Train loss: tensor(0.1024)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.1084)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.1679)\n",
            "Train loss: tensor(0.0616)\n",
            "Train loss: tensor(0.0944)\n",
            "Train loss: tensor(0.0711)\n",
            "Train loss: tensor(0.0932)\n",
            "Train loss: tensor(0.0965)\n",
            "Train loss: tensor(0.1003)\n",
            "Train loss: tensor(0.0665)\n",
            "Train loss: tensor(0.0785)\n",
            "Train loss: tensor(0.1068)\n",
            "Train loss: tensor(0.1034)\n",
            "Train loss: tensor(0.0715)\n",
            "Train loss: tensor(0.1414)\n",
            "Train loss: tensor(0.1061)\n",
            "Model is bad!, Current loss: tensor(4.2897) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  85\n",
            "Train loss: tensor(0.0906)\n",
            "Train loss: tensor(0.1093)\n",
            "Train loss: tensor(0.0776)\n",
            "Train loss: tensor(0.0910)\n",
            "Train loss: tensor(0.0889)\n",
            "Train loss: tensor(0.1159)\n",
            "Train loss: tensor(0.0590)\n",
            "Train loss: tensor(0.0830)\n",
            "Train loss: tensor(0.1274)\n",
            "Train loss: tensor(0.0772)\n",
            "Train loss: tensor(0.0828)\n",
            "Train loss: tensor(0.1004)\n",
            "Train loss: tensor(0.0949)\n",
            "Train loss: tensor(0.0651)\n",
            "Train loss: tensor(0.0850)\n",
            "Train loss: tensor(0.0935)\n",
            "Train loss: tensor(0.1113)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0761)\n",
            "Train loss: tensor(0.0924)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.0973)\n",
            "Train loss: tensor(0.1089)\n",
            "Train loss: tensor(0.0835)\n",
            "Train loss: tensor(0.0970)\n",
            "Train loss: tensor(0.0922)\n",
            "Train loss: tensor(0.0693)\n",
            "Train loss: tensor(0.0789)\n",
            "Train loss: tensor(0.0770)\n",
            "Train loss: tensor(0.0922)\n",
            "Train loss: tensor(0.0954)\n",
            "Train loss: tensor(0.1048)\n",
            "Train loss: tensor(0.0708)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.1037)\n",
            "Train loss: tensor(0.1432)\n",
            "Train loss: tensor(0.0789)\n",
            "Train loss: tensor(0.0808)\n",
            "Train loss: tensor(0.0805)\n",
            "Train loss: tensor(0.0577)\n",
            "Train loss: tensor(0.1084)\n",
            "Model is bad!, Current loss: tensor(3.0657) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  86\n",
            "Train loss: tensor(0.0768)\n",
            "Train loss: tensor(0.0700)\n",
            "Train loss: tensor(0.0566)\n",
            "Train loss: tensor(0.0628)\n",
            "Train loss: tensor(0.1139)\n",
            "Train loss: tensor(0.1002)\n",
            "Train loss: tensor(0.0858)\n",
            "Train loss: tensor(0.0990)\n",
            "Train loss: tensor(0.0632)\n",
            "Train loss: tensor(0.0657)\n",
            "Train loss: tensor(0.0812)\n",
            "Train loss: tensor(0.0843)\n",
            "Train loss: tensor(0.0968)\n",
            "Train loss: tensor(0.0827)\n",
            "Train loss: tensor(0.0574)\n",
            "Train loss: tensor(0.0722)\n",
            "Train loss: tensor(0.1037)\n",
            "Train loss: tensor(0.0846)\n",
            "Train loss: tensor(0.0646)\n",
            "Train loss: tensor(0.1126)\n",
            "Train loss: tensor(0.0772)\n",
            "Train loss: tensor(0.0792)\n",
            "Train loss: tensor(0.1056)\n",
            "Train loss: tensor(0.0848)\n",
            "Train loss: tensor(0.0941)\n",
            "Train loss: tensor(0.0573)\n",
            "Train loss: tensor(0.0832)\n",
            "Train loss: tensor(0.0952)\n",
            "Train loss: tensor(0.0739)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0802)\n",
            "Train loss: tensor(0.0639)\n",
            "Train loss: tensor(0.0808)\n",
            "Train loss: tensor(0.1017)\n",
            "Train loss: tensor(0.0834)\n",
            "Train loss: tensor(0.1123)\n",
            "Train loss: tensor(0.0808)\n",
            "Train loss: tensor(0.0942)\n",
            "Train loss: tensor(0.0887)\n",
            "Train loss: tensor(0.0717)\n",
            "Train loss: tensor(0.0760)\n",
            "Model is bad!, Current loss: tensor(3.5741) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  87\n",
            "Train loss: tensor(0.0988)\n",
            "Train loss: tensor(0.0824)\n",
            "Train loss: tensor(0.0949)\n",
            "Train loss: tensor(0.0961)\n",
            "Train loss: tensor(0.0653)\n",
            "Train loss: tensor(0.0792)\n",
            "Train loss: tensor(0.0725)\n",
            "Train loss: tensor(0.0996)\n",
            "Train loss: tensor(0.1500)\n",
            "Train loss: tensor(0.0581)\n",
            "Train loss: tensor(0.0817)\n",
            "Train loss: tensor(0.0762)\n",
            "Train loss: tensor(0.0988)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0809)\n",
            "Train loss: tensor(0.0697)\n",
            "Train loss: tensor(0.1054)\n",
            "Train loss: tensor(0.0648)\n",
            "Train loss: tensor(0.0781)\n",
            "Train loss: tensor(0.1012)\n",
            "Train loss: tensor(0.1015)\n",
            "Train loss: tensor(0.1284)\n",
            "Train loss: tensor(0.0774)\n",
            "Train loss: tensor(0.1007)\n",
            "Train loss: tensor(0.0670)\n",
            "Train loss: tensor(0.1062)\n",
            "Train loss: tensor(0.0776)\n",
            "Train loss: tensor(0.1008)\n",
            "Train loss: tensor(0.0589)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.0910)\n",
            "Train loss: tensor(0.0738)\n",
            "Train loss: tensor(0.0977)\n",
            "Train loss: tensor(0.0716)\n",
            "Train loss: tensor(0.1013)\n",
            "Train loss: tensor(0.0718)\n",
            "Train loss: tensor(0.0854)\n",
            "Train loss: tensor(0.0667)\n",
            "Train loss: tensor(0.0795)\n",
            "Train loss: tensor(0.0960)\n",
            "Train loss: tensor(0.0948)\n",
            "Model is bad!, Current loss: tensor(4.0141) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  88\n",
            "Train loss: tensor(0.0684)\n",
            "Train loss: tensor(0.0795)\n",
            "Train loss: tensor(0.0661)\n",
            "Train loss: tensor(0.0765)\n",
            "Train loss: tensor(0.0565)\n",
            "Train loss: tensor(0.0977)\n",
            "Train loss: tensor(0.0850)\n",
            "Train loss: tensor(0.1355)\n",
            "Train loss: tensor(0.0862)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0807)\n",
            "Train loss: tensor(0.0797)\n",
            "Train loss: tensor(0.0656)\n",
            "Train loss: tensor(0.0700)\n",
            "Train loss: tensor(0.0724)\n",
            "Train loss: tensor(0.1014)\n",
            "Train loss: tensor(0.0637)\n",
            "Train loss: tensor(0.1105)\n",
            "Train loss: tensor(0.0854)\n",
            "Train loss: tensor(0.0683)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.0949)\n",
            "Train loss: tensor(0.0770)\n",
            "Train loss: tensor(0.1037)\n",
            "Train loss: tensor(0.0792)\n",
            "Train loss: tensor(0.0837)\n",
            "Train loss: tensor(0.0833)\n",
            "Train loss: tensor(0.0560)\n",
            "Train loss: tensor(0.0736)\n",
            "Train loss: tensor(0.1171)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0950)\n",
            "Train loss: tensor(0.0916)\n",
            "Train loss: tensor(0.0785)\n",
            "Train loss: tensor(0.0809)\n",
            "Train loss: tensor(0.0647)\n",
            "Train loss: tensor(0.1013)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.0647)\n",
            "Train loss: tensor(0.0735)\n",
            "Train loss: tensor(0.0824)\n",
            "Model is bad!, Current loss: tensor(3.4146) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  89\n",
            "Train loss: tensor(0.0877)\n",
            "Train loss: tensor(0.0801)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.0578)\n",
            "Train loss: tensor(0.0862)\n",
            "Train loss: tensor(0.0531)\n",
            "Train loss: tensor(0.1254)\n",
            "Train loss: tensor(0.0738)\n",
            "Train loss: tensor(0.0592)\n",
            "Train loss: tensor(0.1056)\n",
            "Train loss: tensor(0.0793)\n",
            "Train loss: tensor(0.0565)\n",
            "Train loss: tensor(0.0872)\n",
            "Train loss: tensor(0.0797)\n",
            "Train loss: tensor(0.0607)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.0555)\n",
            "Train loss: tensor(0.0808)\n",
            "Train loss: tensor(0.0828)\n",
            "Train loss: tensor(0.0804)\n",
            "Train loss: tensor(0.0831)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.1095)\n",
            "Train loss: tensor(0.0706)\n",
            "Train loss: tensor(0.0716)\n",
            "Train loss: tensor(0.0696)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0886)\n",
            "Train loss: tensor(0.1009)\n",
            "Train loss: tensor(0.0950)\n",
            "Train loss: tensor(0.0844)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.0763)\n",
            "Train loss: tensor(0.0991)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.0736)\n",
            "Train loss: tensor(0.1307)\n",
            "Train loss: tensor(0.0713)\n",
            "Train loss: tensor(0.0728)\n",
            "Train loss: tensor(0.0555)\n",
            "Train loss: tensor(0.0731)\n",
            "Model is bad!, Current loss: tensor(4.3822) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  90\n",
            "Train loss: tensor(0.0727)\n",
            "Train loss: tensor(0.0721)\n",
            "Train loss: tensor(0.0602)\n",
            "Train loss: tensor(0.0676)\n",
            "Train loss: tensor(0.0896)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.1242)\n",
            "Train loss: tensor(0.0567)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.1029)\n",
            "Train loss: tensor(0.0929)\n",
            "Train loss: tensor(0.0782)\n",
            "Train loss: tensor(0.0956)\n",
            "Train loss: tensor(0.0843)\n",
            "Train loss: tensor(0.0676)\n",
            "Train loss: tensor(0.1179)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.0778)\n",
            "Train loss: tensor(0.0805)\n",
            "Train loss: tensor(0.0748)\n",
            "Train loss: tensor(0.0667)\n",
            "Train loss: tensor(0.0580)\n",
            "Train loss: tensor(0.0726)\n",
            "Train loss: tensor(0.0914)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.1012)\n",
            "Train loss: tensor(0.0796)\n",
            "Train loss: tensor(0.0651)\n",
            "Train loss: tensor(0.0893)\n",
            "Train loss: tensor(0.1092)\n",
            "Train loss: tensor(0.0806)\n",
            "Train loss: tensor(0.1021)\n",
            "Train loss: tensor(0.0698)\n",
            "Train loss: tensor(0.0838)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.0992)\n",
            "Train loss: tensor(0.0680)\n",
            "Train loss: tensor(0.0971)\n",
            "Train loss: tensor(0.0864)\n",
            "Train loss: tensor(0.0890)\n",
            "Train loss: tensor(0.0974)\n",
            "Model is bad!, Current loss: tensor(4.3158) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  91\n",
            "Train loss: tensor(0.0868)\n",
            "Train loss: tensor(0.0770)\n",
            "Train loss: tensor(0.1079)\n",
            "Train loss: tensor(0.0567)\n",
            "Train loss: tensor(0.1197)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.0915)\n",
            "Train loss: tensor(0.0537)\n",
            "Train loss: tensor(0.0723)\n",
            "Train loss: tensor(0.0782)\n",
            "Train loss: tensor(0.0734)\n",
            "Train loss: tensor(0.1130)\n",
            "Train loss: tensor(0.0762)\n",
            "Train loss: tensor(0.0542)\n",
            "Train loss: tensor(0.0717)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.0880)\n",
            "Train loss: tensor(0.0791)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.1130)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.0572)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.0586)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0827)\n",
            "Train loss: tensor(0.0551)\n",
            "Train loss: tensor(0.0749)\n",
            "Train loss: tensor(0.1089)\n",
            "Train loss: tensor(0.0894)\n",
            "Train loss: tensor(0.0705)\n",
            "Train loss: tensor(0.1206)\n",
            "Train loss: tensor(0.0774)\n",
            "Train loss: tensor(0.0819)\n",
            "Train loss: tensor(0.0961)\n",
            "Train loss: tensor(0.0700)\n",
            "Train loss: tensor(0.0809)\n",
            "Train loss: tensor(0.0834)\n",
            "Model is bad!, Current loss: tensor(4.4077) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  92\n",
            "Train loss: tensor(0.0582)\n",
            "Train loss: tensor(0.1100)\n",
            "Train loss: tensor(0.0559)\n",
            "Train loss: tensor(0.0945)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.1361)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0553)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.1029)\n",
            "Train loss: tensor(0.1235)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.0660)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.0787)\n",
            "Train loss: tensor(0.0777)\n",
            "Train loss: tensor(0.0833)\n",
            "Train loss: tensor(0.0678)\n",
            "Train loss: tensor(0.0933)\n",
            "Train loss: tensor(0.1100)\n",
            "Train loss: tensor(0.0707)\n",
            "Train loss: tensor(0.0787)\n",
            "Train loss: tensor(0.1043)\n",
            "Train loss: tensor(0.0570)\n",
            "Train loss: tensor(0.0855)\n",
            "Train loss: tensor(0.0900)\n",
            "Train loss: tensor(0.0754)\n",
            "Train loss: tensor(0.0918)\n",
            "Train loss: tensor(0.0770)\n",
            "Train loss: tensor(0.1024)\n",
            "Train loss: tensor(0.0826)\n",
            "Train loss: tensor(0.0768)\n",
            "Train loss: tensor(0.0811)\n",
            "Train loss: tensor(0.0561)\n",
            "Train loss: tensor(0.0754)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.0783)\n",
            "Train loss: tensor(0.0785)\n",
            "Train loss: tensor(0.0618)\n",
            "Train loss: tensor(0.1014)\n",
            "Model is bad!, Current loss: tensor(5.2333) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  93\n",
            "Train loss: tensor(0.0740)\n",
            "Train loss: tensor(0.0851)\n",
            "Train loss: tensor(0.0742)\n",
            "Train loss: tensor(0.0647)\n",
            "Train loss: tensor(0.0557)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0813)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.1151)\n",
            "Train loss: tensor(0.0892)\n",
            "Train loss: tensor(0.0810)\n",
            "Train loss: tensor(0.0764)\n",
            "Train loss: tensor(0.0650)\n",
            "Train loss: tensor(0.0678)\n",
            "Train loss: tensor(0.0750)\n",
            "Train loss: tensor(0.0724)\n",
            "Train loss: tensor(0.1016)\n",
            "Train loss: tensor(0.1017)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.0792)\n",
            "Train loss: tensor(0.0793)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.1061)\n",
            "Train loss: tensor(0.0723)\n",
            "Train loss: tensor(0.0574)\n",
            "Train loss: tensor(0.0986)\n",
            "Train loss: tensor(0.1252)\n",
            "Train loss: tensor(0.0985)\n",
            "Train loss: tensor(0.1173)\n",
            "Train loss: tensor(0.1043)\n",
            "Train loss: tensor(0.0807)\n",
            "Train loss: tensor(0.0829)\n",
            "Train loss: tensor(0.0646)\n",
            "Train loss: tensor(0.0824)\n",
            "Train loss: tensor(0.0748)\n",
            "Train loss: tensor(0.0559)\n",
            "Train loss: tensor(0.1032)\n",
            "Train loss: tensor(0.0739)\n",
            "Train loss: tensor(0.0567)\n",
            "Train loss: tensor(0.0785)\n",
            "Model is bad!, Current loss: tensor(2.7433) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  94\n",
            "Train loss: tensor(0.0719)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.0816)\n",
            "Train loss: tensor(0.0696)\n",
            "Train loss: tensor(0.0989)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.0545)\n",
            "Train loss: tensor(0.1028)\n",
            "Train loss: tensor(0.0736)\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.0754)\n",
            "Train loss: tensor(0.1037)\n",
            "Train loss: tensor(0.1006)\n",
            "Train loss: tensor(0.0651)\n",
            "Train loss: tensor(0.0564)\n",
            "Train loss: tensor(0.0901)\n",
            "Train loss: tensor(0.0595)\n",
            "Train loss: tensor(0.0688)\n",
            "Train loss: tensor(0.0933)\n",
            "Train loss: tensor(0.0963)\n",
            "Train loss: tensor(0.0954)\n",
            "Train loss: tensor(0.0690)\n",
            "Train loss: tensor(0.0744)\n",
            "Train loss: tensor(0.0831)\n",
            "Train loss: tensor(0.0811)\n",
            "Train loss: tensor(0.0859)\n",
            "Train loss: tensor(0.0567)\n",
            "Train loss: tensor(0.0948)\n",
            "Train loss: tensor(0.0777)\n",
            "Train loss: tensor(0.0899)\n",
            "Train loss: tensor(0.1382)\n",
            "Train loss: tensor(0.0716)\n",
            "Train loss: tensor(0.1177)\n",
            "Train loss: tensor(0.0743)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.0911)\n",
            "Train loss: tensor(0.0787)\n",
            "Train loss: tensor(0.0772)\n",
            "Train loss: tensor(0.0854)\n",
            "Train loss: tensor(0.0776)\n",
            "Train loss: tensor(0.1213)\n",
            "Model is bad!, Current loss: tensor(4.9572) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  95\n",
            "Train loss: tensor(0.0750)\n",
            "Train loss: tensor(0.0797)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.1062)\n",
            "Train loss: tensor(0.1027)\n",
            "Train loss: tensor(0.0875)\n",
            "Train loss: tensor(0.0970)\n",
            "Train loss: tensor(0.0833)\n",
            "Train loss: tensor(0.0696)\n",
            "Train loss: tensor(0.0775)\n",
            "Train loss: tensor(0.0854)\n",
            "Train loss: tensor(0.0815)\n",
            "Train loss: tensor(0.0824)\n",
            "Train loss: tensor(0.0791)\n",
            "Train loss: tensor(0.1313)\n",
            "Train loss: tensor(0.0794)\n",
            "Train loss: tensor(0.0765)\n",
            "Train loss: tensor(0.0677)\n",
            "Train loss: tensor(0.0740)\n",
            "Train loss: tensor(0.0682)\n",
            "Train loss: tensor(0.0732)\n",
            "Train loss: tensor(0.0989)\n",
            "Train loss: tensor(0.0988)\n",
            "Train loss: tensor(0.0768)\n",
            "Train loss: tensor(0.0628)\n",
            "Train loss: tensor(0.1069)\n",
            "Train loss: tensor(0.0726)\n",
            "Train loss: tensor(0.0715)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.0579)\n",
            "Train loss: tensor(0.0691)\n",
            "Train loss: tensor(0.0776)\n",
            "Train loss: tensor(0.0814)\n",
            "Train loss: tensor(0.1158)\n",
            "Train loss: tensor(0.0522)\n",
            "Train loss: tensor(0.0943)\n",
            "Train loss: tensor(0.0842)\n",
            "Train loss: tensor(0.0606)\n",
            "Train loss: tensor(0.0656)\n",
            "Train loss: tensor(0.0702)\n",
            "Train loss: tensor(0.0724)\n",
            "Model is bad!, Current loss: tensor(3.1520) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  96\n",
            "Train loss: tensor(0.0543)\n",
            "Train loss: tensor(0.0827)\n",
            "Train loss: tensor(0.0818)\n",
            "Train loss: tensor(0.0614)\n",
            "Train loss: tensor(0.0867)\n",
            "Train loss: tensor(0.1008)\n",
            "Train loss: tensor(0.0843)\n",
            "Train loss: tensor(0.0704)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.0796)\n",
            "Train loss: tensor(0.0871)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.0835)\n",
            "Train loss: tensor(0.0720)\n",
            "Train loss: tensor(0.0733)\n",
            "Train loss: tensor(0.1212)\n",
            "Train loss: tensor(0.0715)\n",
            "Train loss: tensor(0.1080)\n",
            "Train loss: tensor(0.0557)\n",
            "Train loss: tensor(0.0725)\n",
            "Train loss: tensor(0.0807)\n",
            "Train loss: tensor(0.0559)\n",
            "Train loss: tensor(0.0784)\n",
            "Train loss: tensor(0.0836)\n",
            "Train loss: tensor(0.1004)\n",
            "Train loss: tensor(0.0921)\n",
            "Train loss: tensor(0.0958)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.0612)\n",
            "Train loss: tensor(0.0912)\n",
            "Train loss: tensor(0.0900)\n",
            "Train loss: tensor(0.0748)\n",
            "Train loss: tensor(0.0839)\n",
            "Train loss: tensor(0.0590)\n",
            "Train loss: tensor(0.0715)\n",
            "Train loss: tensor(0.1052)\n",
            "Train loss: tensor(0.0632)\n",
            "Train loss: tensor(0.1142)\n",
            "Train loss: tensor(0.0669)\n",
            "Train loss: tensor(0.0727)\n",
            "Train loss: tensor(0.0756)\n",
            "Model is bad!, Current loss: tensor(2.9054) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  97\n",
            "Train loss: tensor(0.0913)\n",
            "Train loss: tensor(0.0705)\n",
            "Train loss: tensor(0.0850)\n",
            "Train loss: tensor(0.0655)\n",
            "Train loss: tensor(0.0771)\n",
            "Train loss: tensor(0.0721)\n",
            "Train loss: tensor(0.0904)\n",
            "Train loss: tensor(0.0630)\n",
            "Train loss: tensor(0.0928)\n",
            "Train loss: tensor(0.0592)\n",
            "Train loss: tensor(0.0597)\n",
            "Train loss: tensor(0.0750)\n",
            "Train loss: tensor(0.0740)\n",
            "Train loss: tensor(0.0553)\n",
            "Train loss: tensor(0.0736)\n",
            "Train loss: tensor(0.0572)\n",
            "Train loss: tensor(0.0637)\n",
            "Train loss: tensor(0.1109)\n",
            "Train loss: tensor(0.0741)\n",
            "Train loss: tensor(0.0913)\n",
            "Train loss: tensor(0.1039)\n",
            "Train loss: tensor(0.0861)\n",
            "Train loss: tensor(0.0687)\n",
            "Train loss: tensor(0.0874)\n",
            "Train loss: tensor(0.0653)\n",
            "Train loss: tensor(0.0791)\n",
            "Train loss: tensor(0.0797)\n",
            "Train loss: tensor(0.0789)\n",
            "Train loss: tensor(0.1183)\n",
            "Train loss: tensor(0.0927)\n",
            "Train loss: tensor(0.0845)\n",
            "Train loss: tensor(0.0752)\n",
            "Train loss: tensor(0.0786)\n",
            "Train loss: tensor(0.0795)\n",
            "Train loss: tensor(0.0828)\n",
            "Train loss: tensor(0.0907)\n",
            "Train loss: tensor(0.0885)\n",
            "Train loss: tensor(0.0585)\n",
            "Train loss: tensor(0.0864)\n",
            "Train loss: tensor(0.1070)\n",
            "Train loss: tensor(0.0961)\n",
            "Model is bad!, Current loss: tensor(3.7702) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.4\n",
            "Epoch:  98\n",
            "Train loss: tensor(0.0792)\n",
            "Train loss: tensor(0.0727)\n",
            "Train loss: tensor(0.0689)\n",
            "Train loss: tensor(0.0568)\n",
            "Train loss: tensor(0.0754)\n",
            "Train loss: tensor(0.0747)\n",
            "Train loss: tensor(0.0781)\n",
            "Train loss: tensor(0.0600)\n",
            "Train loss: tensor(0.0696)\n",
            "Train loss: tensor(0.0946)\n",
            "Train loss: tensor(0.0772)\n",
            "Train loss: tensor(0.0831)\n",
            "Train loss: tensor(0.0574)\n",
            "Train loss: tensor(0.1021)\n",
            "Train loss: tensor(0.0737)\n",
            "Train loss: tensor(0.0710)\n",
            "Train loss: tensor(0.0750)\n",
            "Train loss: tensor(0.0628)\n",
            "Train loss: tensor(0.0800)\n",
            "Train loss: tensor(0.0784)\n",
            "Train loss: tensor(0.0926)\n",
            "Train loss: tensor(0.0919)\n",
            "Train loss: tensor(0.0877)\n",
            "Train loss: tensor(0.0924)\n",
            "Train loss: tensor(0.0699)\n",
            "Train loss: tensor(0.0687)\n",
            "Train loss: tensor(0.0858)\n",
            "Train loss: tensor(0.0881)\n",
            "Train loss: tensor(0.0846)\n",
            "Train loss: tensor(0.0997)\n",
            "Train loss: tensor(0.0778)\n",
            "Train loss: tensor(0.0765)\n",
            "Train loss: tensor(0.0745)\n",
            "Train loss: tensor(0.0537)\n",
            "Train loss: tensor(0.1005)\n",
            "Train loss: tensor(0.0866)\n",
            "Train loss: tensor(0.0711)\n",
            "Train loss: tensor(0.1159)\n",
            "Train loss: tensor(0.0582)\n",
            "Train loss: tensor(0.0670)\n",
            "Train loss: tensor(0.0963)\n",
            "Model is bad!, Current loss: tensor(4.7229) Best loss: tensor(1.6420)\n",
            "\n",
            "\n",
            "20.5\n",
            "Epoch:  99\n",
            "Train loss: tensor(0.0911)\n",
            "Train loss: tensor(0.1067)\n",
            "Train loss: tensor(0.0961)\n",
            "Train loss: tensor(0.0565)\n",
            "Train loss: tensor(0.0531)\n",
            "Train loss: tensor(0.0685)\n",
            "Train loss: tensor(0.0659)\n",
            "Train loss: tensor(0.0530)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.0524)\n",
            "Train loss: tensor(0.0677)\n",
            "Train loss: tensor(0.0886)\n",
            "Train loss: tensor(0.0737)\n",
            "Train loss: tensor(0.0684)\n",
            "Train loss: tensor(0.0765)\n",
            "Train loss: tensor(0.0872)\n",
            "Train loss: tensor(0.0602)\n",
            "Train loss: tensor(0.0975)\n",
            "Train loss: tensor(0.0939)\n",
            "Train loss: tensor(0.0904)\n",
            "Train loss: tensor(0.0727)\n",
            "Train loss: tensor(0.0548)\n",
            "Train loss: tensor(0.0788)\n",
            "Train loss: tensor(0.0668)\n",
            "Train loss: tensor(0.0822)\n",
            "Train loss: tensor(0.0710)\n",
            "Train loss: tensor(0.0752)\n",
            "Train loss: tensor(0.0959)\n",
            "Train loss: tensor(0.0685)\n",
            "Train loss: tensor(0.0723)\n",
            "Train loss: tensor(0.0768)\n",
            "Train loss: tensor(0.0940)\n",
            "Train loss: tensor(0.0853)\n",
            "Train loss: tensor(0.0846)\n",
            "Train loss: tensor(0.0721)\n",
            "Train loss: tensor(0.0565)\n",
            "Train loss: tensor(0.0797)\n",
            "Train loss: tensor(0.0916)\n",
            "Train loss: tensor(0.0704)\n",
            "Train loss: tensor(0.0627)\n",
            "Train loss: tensor(0.1011)\n",
            "Model is bad!, Current loss: tensor(4.0577) Best loss: tensor(1.6420)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoZMPaNMWiFh"
      },
      "source": [
        "# **Validation**\n",
        "Please do not alter this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j5vZp9w0nW8k",
        "outputId": "fb225847-17c5-4157-9898-656e7eea97c1"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision.models.segmentation.fcn import FCNHead\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "#from statistics import mean\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# interim_list=[]\n",
        "modeldata = pd.DataFrame(columns=[\"name\", \"precision\", \"recall\", \"accuracy\", \"f1\"])\n",
        "# for mat in enumerate(materials):\n",
        "#   modeldata=pd.DataFrame(columns=['model_group',mat.name + \" precision\",mat.name + \" recall\",mat.name + \" accuracy\",mat.name + \" f1\"])\n",
        "# num_models=num_models\n",
        " \n",
        "for s in range(num_models):\n",
        "  # model=torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True, progress=True)\n",
        " \n",
        " \n",
        "  model=torchvision.models.segmentation.fcn_resnet101(pretrained=False)\n",
        "  #!!!!!!!!!!!!!!!!!Specify Layer # here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  model.classifier=FCNHead(2048, num_materials)\n",
        "  # model.classifier=DeepLabHead(2048, 6)\n",
        "  device = torch.device('cuda')\n",
        " \n",
        "  outputs=[]\n",
        "  model.to(device)\n",
        " \n",
        "  #!!!!!!!!!!!!!!!!!!!!!Select Correct Model from the best models directory!!!!!!!!!!!!!!!!!!!!!!!!!1\n",
        " \n",
        "  model.load_state_dict(torch.load(models_directory+model_group + current_model_name+str(s+1)+\".pth\"), strict=False)\n",
        " \n",
        " \n",
        "  model.train()\n",
        " \n",
        "  dataset_val = BasicDataset(test_images, test_masks, scale=scale, transform=False)\n",
        "  val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)#, collate_fn=pad_collate)\n",
        " \n",
        "  prop_list = []\n",
        "  for mat in materials:\n",
        "    prop_list.append([[],[],[],[]])\n",
        " \n",
        "  for images, target in val_loader:\n",
        "    images = images.to(device=device, dtype=torch.float32)\n",
        "    target = target.to(device=device, dtype=torch.float32)\n",
        " \n",
        "    with torch.no_grad():\n",
        "      pred=model(images)['out'].cuda()\n",
        "      pred=nn.Sigmoid()(pred)\n",
        "    \n",
        "    for i, mat in enumerate(materials):\n",
        "      material_target=target[:,i,:,:]\n",
        "      material_pred = pred[:, i, :, :]\n",
        "      material_pred[material_pred >=mat.confidence_threshold] = 1\n",
        "      material_pred[material_pred <=mat.confidence_threshold] = 0\n",
        "      pred[:, i, :, :]=material_pred\n",
        " \n",
        "      material_tp=torch.sum(material_target*material_pred, (1,2))\n",
        "      material_fp=torch.sum((1-material_target)*material_pred, (1,2))\n",
        "      material_fn=torch.sum(material_target*(1-material_pred), (1,2))\n",
        "      material_tn=torch.sum((1-material_target)*(1-material_pred), (1,2))\n",
        " \n",
        "     \n",
        " \n",
        "      material_precision=torch.mean(material_tp/(material_tp+material_fp))\n",
        "      material_recall=torch.mean(material_tp/(material_tp+material_fn))\n",
        "      material_accuracy=torch.mean((material_tp+material_tn)/(material_tp+material_tn+material_fp+material_fn))\n",
        "      material_f1=torch.mean((material_tp)/(material_tp+0.5*(material_fp+material_fn)))\n",
        " \n",
        "    \n",
        "      prop_list[i][0].append(material_precision.cpu().detach().numpy())\n",
        "      prop_list[i][1].append(material_recall.cpu().detach().numpy())\n",
        "      prop_list[i][2].append(material_accuracy.cpu().detach().numpy())\n",
        "      prop_list[i][3].append(material_f1.cpu().detach().numpy())\n",
        " \n",
        "          \n",
        " \n",
        " \n",
        " \n",
        "  # print(current_model_name+str(s+1))\n",
        "  model_name=current_model_name\n",
        "  model_number=(str(s+1))\n",
        "  print(model_name)\n",
        " \n",
        "  #printing with pandas\n",
        "  properties = {\"name\" : [mat.name for mat in materials],\n",
        "                \"precision\" : [str(np.mean(prop_list[i][0])) for i in range(num_materials)],\n",
        "                \"recall\" : [str(np.mean(prop_list[i][1])) for i in range(num_materials)],\n",
        "                \"accuracy\" : [str(np.mean(prop_list[i][2])) for i in range(num_materials)],\n",
        "                \"f1\" : [str(np.mean(prop_list[i][3])) for i in range(num_materials)]}\n",
        "  df = pd.DataFrame(properties, columns = [\"name\", \"precision\", \"recall\", \"accuracy\", \"f1\"])\n",
        "  df=pd.concat([df, pd.DataFrame(columns=[\"model number\",\"model name\"])])\n",
        "  df[[\"model number\",\"model name\"]]=[model_number, model_name]\n",
        "  # display(df)\n",
        "  \n",
        "  modeldata=modeldata.append([df], ignore_index=True)\n",
        "\n",
        "\n",
        " \n",
        "#   for i, mat in enumerate(materials):\n",
        "#     precision_final = np.mean(prop_list[i][0])\n",
        "#     print(mat.name + \" precision: \" + str(precision_final))\n",
        "#     recall_final = np.mean(prop_list[i][1])\n",
        "#     print(mat.name + \" recall: \" + str(recall_final))\n",
        "#     accuracy_final = np.mean(prop_list[i][2])\n",
        "#     print(mat.name + \" accuracy: \" + str(accuracy_final))\n",
        "#     f1_final = np.mean(prop_list[i][3])\n",
        "#     print(mat.name + \" f1: \" + str(f1_final))\n",
        "#     # modeldata1=modeldata.append({'name': mat.name, mat.name + \" precision\": precision_final, mat.name + \" recall\": recall_final, mat.name + \" accuracy\": accuracy_final, mat.name + \" f1\": f1_final}, ignore_index=True)\n",
        "#     # model_data=modeldata.append(modeldata1)\n",
        "# # model_data=df.append(interim_list)\n",
        "# print(modeldata)\n",
        "# md=pd.concat([modeldata, pd.DataFrame(columns=[\"model name\"])])\n",
        "# md[[\"model name\"]]=[current_model_name]\n",
        "display(modeldata)\n",
        "\n",
        "#   display(modeldata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 leaf bce p2 100 epoch__\n",
            "10 leaf bce p2 100 epoch__\n",
            "10 leaf bce p2 100 epoch__\n",
            "10 leaf bce p2 100 epoch__\n",
            "10 leaf bce p2 100 epoch__\n",
            "10 leaf bce p2 100 epoch__\n",
            "10 leaf bce p2 100 epoch__\n",
            "10 leaf bce p2 100 epoch__\n",
            "10 leaf bce p2 100 epoch__\n",
            "10 leaf bce p2 100 epoch__\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>model number</th>\n",
              "      <th>model name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>background</td>\n",
              "      <td>0.9891449</td>\n",
              "      <td>0.978951</td>\n",
              "      <td>0.98869836</td>\n",
              "      <td>0.98402023</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.8334789</td>\n",
              "      <td>0.93416774</td>\n",
              "      <td>0.9788316</td>\n",
              "      <td>0.88068295</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.85370314</td>\n",
              "      <td>0.85329354</td>\n",
              "      <td>0.91249764</td>\n",
              "      <td>0.8532683</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.7612357</td>\n",
              "      <td>0.78674287</td>\n",
              "      <td>0.93720657</td>\n",
              "      <td>0.7731284</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.7947765</td>\n",
              "      <td>0.82899123</td>\n",
              "      <td>0.9603858</td>\n",
              "      <td>0.805474</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.5848458</td>\n",
              "      <td>0.5973344</td>\n",
              "      <td>0.98347235</td>\n",
              "      <td>0.5836266</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>background</td>\n",
              "      <td>0.9720894</td>\n",
              "      <td>0.9803872</td>\n",
              "      <td>0.9829499</td>\n",
              "      <td>0.97618246</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.76074743</td>\n",
              "      <td>0.9142331</td>\n",
              "      <td>0.9687332</td>\n",
              "      <td>0.8302668</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8314152</td>\n",
              "      <td>0.8348781</td>\n",
              "      <td>0.9000164</td>\n",
              "      <td>0.8330386</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.78356063</td>\n",
              "      <td>0.66796744</td>\n",
              "      <td>0.92928183</td>\n",
              "      <td>0.72075015</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.6911211</td>\n",
              "      <td>0.83071744</td>\n",
              "      <td>0.9438694</td>\n",
              "      <td>0.7453248</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.4999949</td>\n",
              "      <td>0.30961272</td>\n",
              "      <td>0.9806613</td>\n",
              "      <td>0.3733444</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>background</td>\n",
              "      <td>0.98999405</td>\n",
              "      <td>0.9757571</td>\n",
              "      <td>0.9879486</td>\n",
              "      <td>0.98282146</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.77777916</td>\n",
              "      <td>0.9718127</td>\n",
              "      <td>0.97438985</td>\n",
              "      <td>0.8638998</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.89473945</td>\n",
              "      <td>0.7942634</td>\n",
              "      <td>0.9108225</td>\n",
              "      <td>0.8414815</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.6951082</td>\n",
              "      <td>0.8441415</td>\n",
              "      <td>0.9282716</td>\n",
              "      <td>0.7618119</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.853063</td>\n",
              "      <td>0.7533709</td>\n",
              "      <td>0.9592848</td>\n",
              "      <td>0.79559547</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.45355314</td>\n",
              "      <td>0.7920189</td>\n",
              "      <td>0.97642165</td>\n",
              "      <td>0.57316977</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>background</td>\n",
              "      <td>0.9850481</td>\n",
              "      <td>0.97276294</td>\n",
              "      <td>0.98517114</td>\n",
              "      <td>0.978862</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.7917539</td>\n",
              "      <td>0.8944381</td>\n",
              "      <td>0.9714629</td>\n",
              "      <td>0.839822</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8178379</td>\n",
              "      <td>0.8111397</td>\n",
              "      <td>0.8891085</td>\n",
              "      <td>0.8137638</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.71030736</td>\n",
              "      <td>0.69480145</td>\n",
              "      <td>0.9192463</td>\n",
              "      <td>0.7010785</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.7006907</td>\n",
              "      <td>0.8206617</td>\n",
              "      <td>0.9456712</td>\n",
              "      <td>0.7443942</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>vein</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9804614</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>background</td>\n",
              "      <td>0.98424435</td>\n",
              "      <td>0.9859316</td>\n",
              "      <td>0.98944265</td>\n",
              "      <td>0.9850853</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.7976248</td>\n",
              "      <td>0.96231854</td>\n",
              "      <td>0.9764166</td>\n",
              "      <td>0.8721735</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8990737</td>\n",
              "      <td>0.8074497</td>\n",
              "      <td>0.9155838</td>\n",
              "      <td>0.8507307</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.7436389</td>\n",
              "      <td>0.8272622</td>\n",
              "      <td>0.93755543</td>\n",
              "      <td>0.7828784</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.85274774</td>\n",
              "      <td>0.8304554</td>\n",
              "      <td>0.9672812</td>\n",
              "      <td>0.8402403</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.5985856</td>\n",
              "      <td>0.7335698</td>\n",
              "      <td>0.9843464</td>\n",
              "      <td>0.6528429</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>background</td>\n",
              "      <td>0.9839018</td>\n",
              "      <td>0.985082</td>\n",
              "      <td>0.98900425</td>\n",
              "      <td>0.98448914</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.8164691</td>\n",
              "      <td>0.9525248</td>\n",
              "      <td>0.9780709</td>\n",
              "      <td>0.87901896</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.85787886</td>\n",
              "      <td>0.8415599</td>\n",
              "      <td>0.9110141</td>\n",
              "      <td>0.8495842</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.7780288</td>\n",
              "      <td>0.768083</td>\n",
              "      <td>0.938382</td>\n",
              "      <td>0.772691</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.8088106</td>\n",
              "      <td>0.7703899</td>\n",
              "      <td>0.9569801</td>\n",
              "      <td>0.78206795</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.53505164</td>\n",
              "      <td>0.7810178</td>\n",
              "      <td>0.981382</td>\n",
              "      <td>0.6235921</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>background</td>\n",
              "      <td>0.968657</td>\n",
              "      <td>0.98359716</td>\n",
              "      <td>0.9827449</td>\n",
              "      <td>0.9760269</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.8180636</td>\n",
              "      <td>0.9283899</td>\n",
              "      <td>0.9766811</td>\n",
              "      <td>0.86950016</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8697109</td>\n",
              "      <td>0.8176443</td>\n",
              "      <td>0.9091628</td>\n",
              "      <td>0.84282064</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.74927557</td>\n",
              "      <td>0.79095316</td>\n",
              "      <td>0.93540347</td>\n",
              "      <td>0.76892644</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.7921652</td>\n",
              "      <td>0.74519587</td>\n",
              "      <td>0.9516484</td>\n",
              "      <td>0.75821865</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.497958</td>\n",
              "      <td>0.5222972</td>\n",
              "      <td>0.98039836</td>\n",
              "      <td>0.505809</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>background</td>\n",
              "      <td>0.9911669</td>\n",
              "      <td>0.98187554</td>\n",
              "      <td>0.9904827</td>\n",
              "      <td>0.9864969</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.86467</td>\n",
              "      <td>0.93637216</td>\n",
              "      <td>0.9824052</td>\n",
              "      <td>0.8990183</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.83635235</td>\n",
              "      <td>0.90857315</td>\n",
              "      <td>0.9197711</td>\n",
              "      <td>0.8709122</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.7977485</td>\n",
              "      <td>0.77684623</td>\n",
              "      <td>0.9426015</td>\n",
              "      <td>0.78688747</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.8759745</td>\n",
              "      <td>0.8388938</td>\n",
              "      <td>0.9710733</td>\n",
              "      <td>0.855324</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.74136764</td>\n",
              "      <td>0.68837744</td>\n",
              "      <td>0.9884834</td>\n",
              "      <td>0.70588934</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>background</td>\n",
              "      <td>0.98802346</td>\n",
              "      <td>0.9697033</td>\n",
              "      <td>0.9851346</td>\n",
              "      <td>0.97877043</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.74535835</td>\n",
              "      <td>0.9215867</td>\n",
              "      <td>0.967095</td>\n",
              "      <td>0.8240592</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8371124</td>\n",
              "      <td>0.7906755</td>\n",
              "      <td>0.89125234</td>\n",
              "      <td>0.81283987</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.75408965</td>\n",
              "      <td>0.67243797</td>\n",
              "      <td>0.92496836</td>\n",
              "      <td>0.7097137</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.6850978</td>\n",
              "      <td>0.8887783</td>\n",
              "      <td>0.9475481</td>\n",
              "      <td>0.7647378</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.7240068</td>\n",
              "      <td>0.10957118</td>\n",
              "      <td>0.9819021</td>\n",
              "      <td>0.1761628</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>background</td>\n",
              "      <td>0.992205</td>\n",
              "      <td>0.97272587</td>\n",
              "      <td>0.98763543</td>\n",
              "      <td>0.9823658</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.73683214</td>\n",
              "      <td>0.96617043</td>\n",
              "      <td>0.9682747</td>\n",
              "      <td>0.8358861</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8808155</td>\n",
              "      <td>0.7366551</td>\n",
              "      <td>0.891575</td>\n",
              "      <td>0.8022011</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.75174326</td>\n",
              "      <td>0.71548</td>\n",
              "      <td>0.9285556</td>\n",
              "      <td>0.7321203</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.6684346</td>\n",
              "      <td>0.8007639</td>\n",
              "      <td>0.937667</td>\n",
              "      <td>0.7202116</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.46115923</td>\n",
              "      <td>0.5222603</td>\n",
              "      <td>0.9753512</td>\n",
              "      <td>0.46827856</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       name   precision      recall    accuracy          f1  \\\n",
              "0                background   0.9891449    0.978951  0.98869836  0.98402023   \n",
              "1                 epidermis   0.8334789  0.93416774   0.9788316  0.88068295   \n",
              "2                 mesophyll  0.85370314  0.85329354  0.91249764   0.8532683   \n",
              "3                 air_space   0.7612357  0.78674287  0.93720657   0.7731284   \n",
              "4   bundle_sheath_extension   0.7947765  0.82899123   0.9603858    0.805474   \n",
              "5                      vein   0.5848458   0.5973344  0.98347235   0.5836266   \n",
              "6                background   0.9720894   0.9803872   0.9829499  0.97618246   \n",
              "7                 epidermis  0.76074743   0.9142331   0.9687332   0.8302668   \n",
              "8                 mesophyll   0.8314152   0.8348781   0.9000164   0.8330386   \n",
              "9                 air_space  0.78356063  0.66796744  0.92928183  0.72075015   \n",
              "10  bundle_sheath_extension   0.6911211  0.83071744   0.9438694   0.7453248   \n",
              "11                     vein   0.4999949  0.30961272   0.9806613   0.3733444   \n",
              "12               background  0.98999405   0.9757571   0.9879486  0.98282146   \n",
              "13                epidermis  0.77777916   0.9718127  0.97438985   0.8638998   \n",
              "14                mesophyll  0.89473945   0.7942634   0.9108225   0.8414815   \n",
              "15                air_space   0.6951082   0.8441415   0.9282716   0.7618119   \n",
              "16  bundle_sheath_extension    0.853063   0.7533709   0.9592848  0.79559547   \n",
              "17                     vein  0.45355314   0.7920189  0.97642165  0.57316977   \n",
              "18               background   0.9850481  0.97276294  0.98517114    0.978862   \n",
              "19                epidermis   0.7917539   0.8944381   0.9714629    0.839822   \n",
              "20                mesophyll   0.8178379   0.8111397   0.8891085   0.8137638   \n",
              "21                air_space  0.71030736  0.69480145   0.9192463   0.7010785   \n",
              "22  bundle_sheath_extension   0.7006907   0.8206617   0.9456712   0.7443942   \n",
              "23                     vein         nan         0.0   0.9804614         0.0   \n",
              "24               background  0.98424435   0.9859316  0.98944265   0.9850853   \n",
              "25                epidermis   0.7976248  0.96231854   0.9764166   0.8721735   \n",
              "26                mesophyll   0.8990737   0.8074497   0.9155838   0.8507307   \n",
              "27                air_space   0.7436389   0.8272622  0.93755543   0.7828784   \n",
              "28  bundle_sheath_extension  0.85274774   0.8304554   0.9672812   0.8402403   \n",
              "29                     vein   0.5985856   0.7335698   0.9843464   0.6528429   \n",
              "30               background   0.9839018    0.985082  0.98900425  0.98448914   \n",
              "31                epidermis   0.8164691   0.9525248   0.9780709  0.87901896   \n",
              "32                mesophyll  0.85787886   0.8415599   0.9110141   0.8495842   \n",
              "33                air_space   0.7780288    0.768083    0.938382    0.772691   \n",
              "34  bundle_sheath_extension   0.8088106   0.7703899   0.9569801  0.78206795   \n",
              "35                     vein  0.53505164   0.7810178    0.981382   0.6235921   \n",
              "36               background    0.968657  0.98359716   0.9827449   0.9760269   \n",
              "37                epidermis   0.8180636   0.9283899   0.9766811  0.86950016   \n",
              "38                mesophyll   0.8697109   0.8176443   0.9091628  0.84282064   \n",
              "39                air_space  0.74927557  0.79095316  0.93540347  0.76892644   \n",
              "40  bundle_sheath_extension   0.7921652  0.74519587   0.9516484  0.75821865   \n",
              "41                     vein    0.497958   0.5222972  0.98039836    0.505809   \n",
              "42               background   0.9911669  0.98187554   0.9904827   0.9864969   \n",
              "43                epidermis     0.86467  0.93637216   0.9824052   0.8990183   \n",
              "44                mesophyll  0.83635235  0.90857315   0.9197711   0.8709122   \n",
              "45                air_space   0.7977485  0.77684623   0.9426015  0.78688747   \n",
              "46  bundle_sheath_extension   0.8759745   0.8388938   0.9710733    0.855324   \n",
              "47                     vein  0.74136764  0.68837744   0.9884834  0.70588934   \n",
              "48               background  0.98802346   0.9697033   0.9851346  0.97877043   \n",
              "49                epidermis  0.74535835   0.9215867    0.967095   0.8240592   \n",
              "50                mesophyll   0.8371124   0.7906755  0.89125234  0.81283987   \n",
              "51                air_space  0.75408965  0.67243797  0.92496836   0.7097137   \n",
              "52  bundle_sheath_extension   0.6850978   0.8887783   0.9475481   0.7647378   \n",
              "53                     vein   0.7240068  0.10957118   0.9819021   0.1761628   \n",
              "54               background    0.992205  0.97272587  0.98763543   0.9823658   \n",
              "55                epidermis  0.73683214  0.96617043   0.9682747   0.8358861   \n",
              "56                mesophyll   0.8808155   0.7366551    0.891575   0.8022011   \n",
              "57                air_space  0.75174326     0.71548   0.9285556   0.7321203   \n",
              "58  bundle_sheath_extension   0.6684346   0.8007639    0.937667   0.7202116   \n",
              "59                     vein  0.46115923   0.5222603   0.9753512  0.46827856   \n",
              "\n",
              "   model number                  model name  \n",
              "0             1  10 leaf bce p2 100 epoch__  \n",
              "1             1  10 leaf bce p2 100 epoch__  \n",
              "2             1  10 leaf bce p2 100 epoch__  \n",
              "3             1  10 leaf bce p2 100 epoch__  \n",
              "4             1  10 leaf bce p2 100 epoch__  \n",
              "5             1  10 leaf bce p2 100 epoch__  \n",
              "6             2  10 leaf bce p2 100 epoch__  \n",
              "7             2  10 leaf bce p2 100 epoch__  \n",
              "8             2  10 leaf bce p2 100 epoch__  \n",
              "9             2  10 leaf bce p2 100 epoch__  \n",
              "10            2  10 leaf bce p2 100 epoch__  \n",
              "11            2  10 leaf bce p2 100 epoch__  \n",
              "12            3  10 leaf bce p2 100 epoch__  \n",
              "13            3  10 leaf bce p2 100 epoch__  \n",
              "14            3  10 leaf bce p2 100 epoch__  \n",
              "15            3  10 leaf bce p2 100 epoch__  \n",
              "16            3  10 leaf bce p2 100 epoch__  \n",
              "17            3  10 leaf bce p2 100 epoch__  \n",
              "18            4  10 leaf bce p2 100 epoch__  \n",
              "19            4  10 leaf bce p2 100 epoch__  \n",
              "20            4  10 leaf bce p2 100 epoch__  \n",
              "21            4  10 leaf bce p2 100 epoch__  \n",
              "22            4  10 leaf bce p2 100 epoch__  \n",
              "23            4  10 leaf bce p2 100 epoch__  \n",
              "24            5  10 leaf bce p2 100 epoch__  \n",
              "25            5  10 leaf bce p2 100 epoch__  \n",
              "26            5  10 leaf bce p2 100 epoch__  \n",
              "27            5  10 leaf bce p2 100 epoch__  \n",
              "28            5  10 leaf bce p2 100 epoch__  \n",
              "29            5  10 leaf bce p2 100 epoch__  \n",
              "30            6  10 leaf bce p2 100 epoch__  \n",
              "31            6  10 leaf bce p2 100 epoch__  \n",
              "32            6  10 leaf bce p2 100 epoch__  \n",
              "33            6  10 leaf bce p2 100 epoch__  \n",
              "34            6  10 leaf bce p2 100 epoch__  \n",
              "35            6  10 leaf bce p2 100 epoch__  \n",
              "36            7  10 leaf bce p2 100 epoch__  \n",
              "37            7  10 leaf bce p2 100 epoch__  \n",
              "38            7  10 leaf bce p2 100 epoch__  \n",
              "39            7  10 leaf bce p2 100 epoch__  \n",
              "40            7  10 leaf bce p2 100 epoch__  \n",
              "41            7  10 leaf bce p2 100 epoch__  \n",
              "42            8  10 leaf bce p2 100 epoch__  \n",
              "43            8  10 leaf bce p2 100 epoch__  \n",
              "44            8  10 leaf bce p2 100 epoch__  \n",
              "45            8  10 leaf bce p2 100 epoch__  \n",
              "46            8  10 leaf bce p2 100 epoch__  \n",
              "47            8  10 leaf bce p2 100 epoch__  \n",
              "48            9  10 leaf bce p2 100 epoch__  \n",
              "49            9  10 leaf bce p2 100 epoch__  \n",
              "50            9  10 leaf bce p2 100 epoch__  \n",
              "51            9  10 leaf bce p2 100 epoch__  \n",
              "52            9  10 leaf bce p2 100 epoch__  \n",
              "53            9  10 leaf bce p2 100 epoch__  \n",
              "54           10  10 leaf bce p2 100 epoch__  \n",
              "55           10  10 leaf bce p2 100 epoch__  \n",
              "56           10  10 leaf bce p2 100 epoch__  \n",
              "57           10  10 leaf bce p2 100 epoch__  \n",
              "58           10  10 leaf bce p2 100 epoch__  \n",
              "59           10  10 leaf bce p2 100 epoch__  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Y4ncwAi9Yx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZmEjhTJ6Qyb"
      },
      "source": [
        "#**Save Validation CSV**\n",
        "Please do not alter this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J2uTuPAtHsMm",
        "outputId": "7c46030a-3587-43a6-94b3-6ded4193d8bb"
      },
      "source": [
        "display(modeldata)\n",
        "modeldata.to_csv(csv_directory)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>model number</th>\n",
              "      <th>model name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>background</td>\n",
              "      <td>0.98913115</td>\n",
              "      <td>0.9789686</td>\n",
              "      <td>0.9886998</td>\n",
              "      <td>0.98402244</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.9114641</td>\n",
              "      <td>0.8529936</td>\n",
              "      <td>0.98070943</td>\n",
              "      <td>0.8808489</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.85377663</td>\n",
              "      <td>0.8529668</td>\n",
              "      <td>0.9124594</td>\n",
              "      <td>0.8531457</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.8140149</td>\n",
              "      <td>0.7169959</td>\n",
              "      <td>0.9388369</td>\n",
              "      <td>0.761989</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.79504293</td>\n",
              "      <td>0.82938814</td>\n",
              "      <td>0.96053636</td>\n",
              "      <td>0.8058756</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.5878334</td>\n",
              "      <td>0.59575737</td>\n",
              "      <td>0.98353374</td>\n",
              "      <td>0.58457774</td>\n",
              "      <td>1</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>background</td>\n",
              "      <td>0.97212374</td>\n",
              "      <td>0.98047704</td>\n",
              "      <td>0.9829963</td>\n",
              "      <td>0.97624457</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.83429563</td>\n",
              "      <td>0.8269793</td>\n",
              "      <td>0.9717369</td>\n",
              "      <td>0.8303884</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.83138955</td>\n",
              "      <td>0.8355037</td>\n",
              "      <td>0.9001522</td>\n",
              "      <td>0.8333398</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.8305472</td>\n",
              "      <td>0.5929439</td>\n",
              "      <td>0.92752373</td>\n",
              "      <td>0.6915067</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.6918358</td>\n",
              "      <td>0.8324186</td>\n",
              "      <td>0.9440608</td>\n",
              "      <td>0.746335</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.4904712</td>\n",
              "      <td>0.30670398</td>\n",
              "      <td>0.98048514</td>\n",
              "      <td>0.3682732</td>\n",
              "      <td>2</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>background</td>\n",
              "      <td>0.99003255</td>\n",
              "      <td>0.97574216</td>\n",
              "      <td>0.9879569</td>\n",
              "      <td>0.98283273</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.86293447</td>\n",
              "      <td>0.9185284</td>\n",
              "      <td>0.980945</td>\n",
              "      <td>0.8896597</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8948414</td>\n",
              "      <td>0.79433745</td>\n",
              "      <td>0.91087484</td>\n",
              "      <td>0.84156847</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.75111884</td>\n",
              "      <td>0.78151524</td>\n",
              "      <td>0.93478185</td>\n",
              "      <td>0.76560533</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.85139894</td>\n",
              "      <td>0.753709</td>\n",
              "      <td>0.95913476</td>\n",
              "      <td>0.79497933</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.45579785</td>\n",
              "      <td>0.7926088</td>\n",
              "      <td>0.97657794</td>\n",
              "      <td>0.57517874</td>\n",
              "      <td>3</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>background</td>\n",
              "      <td>0.985046</td>\n",
              "      <td>0.9729223</td>\n",
              "      <td>0.98522556</td>\n",
              "      <td>0.9789416</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.87666833</td>\n",
              "      <td>0.7904377</td>\n",
              "      <td>0.9731348</td>\n",
              "      <td>0.83111334</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8172401</td>\n",
              "      <td>0.8116132</td>\n",
              "      <td>0.88899726</td>\n",
              "      <td>0.8137037</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.785024</td>\n",
              "      <td>0.5861675</td>\n",
              "      <td>0.92066133</td>\n",
              "      <td>0.669625</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.70025015</td>\n",
              "      <td>0.8176578</td>\n",
              "      <td>0.94530153</td>\n",
              "      <td>0.7426665</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>vein</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9804614</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>background</td>\n",
              "      <td>0.98419344</td>\n",
              "      <td>0.98587036</td>\n",
              "      <td>0.98940194</td>\n",
              "      <td>0.9850294</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.86759883</td>\n",
              "      <td>0.9154832</td>\n",
              "      <td>0.9812269</td>\n",
              "      <td>0.8907908</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.89901435</td>\n",
              "      <td>0.80775225</td>\n",
              "      <td>0.915631</td>\n",
              "      <td>0.8508748</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.80356157</td>\n",
              "      <td>0.755977</td>\n",
              "      <td>0.94136935</td>\n",
              "      <td>0.77880585</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.8503946</td>\n",
              "      <td>0.8304693</td>\n",
              "      <td>0.9670167</td>\n",
              "      <td>0.83903086</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.6004003</td>\n",
              "      <td>0.73241585</td>\n",
              "      <td>0.9843496</td>\n",
              "      <td>0.6531081</td>\n",
              "      <td>5</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>background</td>\n",
              "      <td>0.9838945</td>\n",
              "      <td>0.9851472</td>\n",
              "      <td>0.98902255</td>\n",
              "      <td>0.9845182</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.89039433</td>\n",
              "      <td>0.8904874</td>\n",
              "      <td>0.9816122</td>\n",
              "      <td>0.890133</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.85803664</td>\n",
              "      <td>0.8416971</td>\n",
              "      <td>0.91111106</td>\n",
              "      <td>0.8497394</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.8303164</td>\n",
              "      <td>0.6906579</td>\n",
              "      <td>0.93829966</td>\n",
              "      <td>0.7538795</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.8092127</td>\n",
              "      <td>0.771252</td>\n",
              "      <td>0.9571622</td>\n",
              "      <td>0.7827851</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.5358833</td>\n",
              "      <td>0.7815533</td>\n",
              "      <td>0.98138314</td>\n",
              "      <td>0.6238798</td>\n",
              "      <td>6</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>background</td>\n",
              "      <td>0.9689806</td>\n",
              "      <td>0.9836413</td>\n",
              "      <td>0.9828847</td>\n",
              "      <td>0.97621334</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.9088379</td>\n",
              "      <td>0.8122045</td>\n",
              "      <td>0.9774157</td>\n",
              "      <td>0.8575238</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.86952955</td>\n",
              "      <td>0.81752634</td>\n",
              "      <td>0.90906554</td>\n",
              "      <td>0.842672</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.8063162</td>\n",
              "      <td>0.71317935</td>\n",
              "      <td>0.93727034</td>\n",
              "      <td>0.7563989</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.79227924</td>\n",
              "      <td>0.74569315</td>\n",
              "      <td>0.9516579</td>\n",
              "      <td>0.7583412</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.5000788</td>\n",
              "      <td>0.52509505</td>\n",
              "      <td>0.9805099</td>\n",
              "      <td>0.50817347</td>\n",
              "      <td>7</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>background</td>\n",
              "      <td>0.99122584</td>\n",
              "      <td>0.9818719</td>\n",
              "      <td>0.9905039</td>\n",
              "      <td>0.9865242</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.9182787</td>\n",
              "      <td>0.87612426</td>\n",
              "      <td>0.98309386</td>\n",
              "      <td>0.8966112</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8362284</td>\n",
              "      <td>0.90844727</td>\n",
              "      <td>0.9196933</td>\n",
              "      <td>0.8707886</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.8436654</td>\n",
              "      <td>0.7087983</td>\n",
              "      <td>0.94212514</td>\n",
              "      <td>0.77019924</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.87551326</td>\n",
              "      <td>0.84061986</td>\n",
              "      <td>0.9711919</td>\n",
              "      <td>0.8560668</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.74319947</td>\n",
              "      <td>0.6893981</td>\n",
              "      <td>0.98853034</td>\n",
              "      <td>0.70717657</td>\n",
              "      <td>8</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>background</td>\n",
              "      <td>0.9880846</td>\n",
              "      <td>0.96964085</td>\n",
              "      <td>0.9851357</td>\n",
              "      <td>0.9787687</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.84422654</td>\n",
              "      <td>0.8184036</td>\n",
              "      <td>0.9721535</td>\n",
              "      <td>0.8309742</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.8366979</td>\n",
              "      <td>0.7902364</td>\n",
              "      <td>0.89100885</td>\n",
              "      <td>0.8124196</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.81682146</td>\n",
              "      <td>0.5769194</td>\n",
              "      <td>0.923893</td>\n",
              "      <td>0.67508113</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.68509674</td>\n",
              "      <td>0.8889834</td>\n",
              "      <td>0.9475333</td>\n",
              "      <td>0.76471996</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.69951564</td>\n",
              "      <td>0.11769601</td>\n",
              "      <td>0.9819435</td>\n",
              "      <td>0.17983022</td>\n",
              "      <td>9</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>background</td>\n",
              "      <td>0.99225366</td>\n",
              "      <td>0.97263604</td>\n",
              "      <td>0.9876212</td>\n",
              "      <td>0.9823437</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>epidermis</td>\n",
              "      <td>0.8339945</td>\n",
              "      <td>0.90209734</td>\n",
              "      <td>0.9767461</td>\n",
              "      <td>0.8664584</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>mesophyll</td>\n",
              "      <td>0.880998</td>\n",
              "      <td>0.7362443</td>\n",
              "      <td>0.8915329</td>\n",
              "      <td>0.8020409</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>air_space</td>\n",
              "      <td>0.79974973</td>\n",
              "      <td>0.64535964</td>\n",
              "      <td>0.9289355</td>\n",
              "      <td>0.7133117</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>bundle_sheath_extension</td>\n",
              "      <td>0.66681635</td>\n",
              "      <td>0.79929477</td>\n",
              "      <td>0.9373089</td>\n",
              "      <td>0.71873385</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>vein</td>\n",
              "      <td>0.461102</td>\n",
              "      <td>0.5171454</td>\n",
              "      <td>0.97525156</td>\n",
              "      <td>0.4659152</td>\n",
              "      <td>10</td>\n",
              "      <td>10 leaf bce p2 100 epoch__</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       name  ...                  model name\n",
              "0                background  ...  10 leaf bce p2 100 epoch__\n",
              "1                 epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "2                 mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "3                 air_space  ...  10 leaf bce p2 100 epoch__\n",
              "4   bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "5                      vein  ...  10 leaf bce p2 100 epoch__\n",
              "6                background  ...  10 leaf bce p2 100 epoch__\n",
              "7                 epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "8                 mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "9                 air_space  ...  10 leaf bce p2 100 epoch__\n",
              "10  bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "11                     vein  ...  10 leaf bce p2 100 epoch__\n",
              "12               background  ...  10 leaf bce p2 100 epoch__\n",
              "13                epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "14                mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "15                air_space  ...  10 leaf bce p2 100 epoch__\n",
              "16  bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "17                     vein  ...  10 leaf bce p2 100 epoch__\n",
              "18               background  ...  10 leaf bce p2 100 epoch__\n",
              "19                epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "20                mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "21                air_space  ...  10 leaf bce p2 100 epoch__\n",
              "22  bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "23                     vein  ...  10 leaf bce p2 100 epoch__\n",
              "24               background  ...  10 leaf bce p2 100 epoch__\n",
              "25                epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "26                mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "27                air_space  ...  10 leaf bce p2 100 epoch__\n",
              "28  bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "29                     vein  ...  10 leaf bce p2 100 epoch__\n",
              "30               background  ...  10 leaf bce p2 100 epoch__\n",
              "31                epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "32                mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "33                air_space  ...  10 leaf bce p2 100 epoch__\n",
              "34  bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "35                     vein  ...  10 leaf bce p2 100 epoch__\n",
              "36               background  ...  10 leaf bce p2 100 epoch__\n",
              "37                epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "38                mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "39                air_space  ...  10 leaf bce p2 100 epoch__\n",
              "40  bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "41                     vein  ...  10 leaf bce p2 100 epoch__\n",
              "42               background  ...  10 leaf bce p2 100 epoch__\n",
              "43                epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "44                mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "45                air_space  ...  10 leaf bce p2 100 epoch__\n",
              "46  bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "47                     vein  ...  10 leaf bce p2 100 epoch__\n",
              "48               background  ...  10 leaf bce p2 100 epoch__\n",
              "49                epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "50                mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "51                air_space  ...  10 leaf bce p2 100 epoch__\n",
              "52  bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "53                     vein  ...  10 leaf bce p2 100 epoch__\n",
              "54               background  ...  10 leaf bce p2 100 epoch__\n",
              "55                epidermis  ...  10 leaf bce p2 100 epoch__\n",
              "56                mesophyll  ...  10 leaf bce p2 100 epoch__\n",
              "57                air_space  ...  10 leaf bce p2 100 epoch__\n",
              "58  bundle_sheath_extension  ...  10 leaf bce p2 100 epoch__\n",
              "59                     vein  ...  10 leaf bce p2 100 epoch__\n",
              "\n",
              "[60 rows x 7 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDdtRtlaW8fX"
      },
      "source": [
        "#**Load Model**\n",
        "**model_number**: Select the best model number above and input into the model_number line. Dont forget the quotation marks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CAux88lvcxS"
      },
      "source": [
        "\"\"\"Input model number here\"\"\"\n",
        "model_number='8'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUB79IBEvg5m"
      },
      "source": [
        "#Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN3B88mB1qXd",
        "outputId": "1ab5f5e1-4e78-43f4-bbb9-4338b9bc44e7"
      },
      "source": [
        "#Code Box 5\n",
        "import torch\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "from torchvision.models.segmentation.fcn import FCNHead\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        " \n",
        " \n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "model=torchvision.models.segmentation.fcn_resnet101(pretrained=False)\n",
        "\n",
        "model.classifier=FCNHead(2048, num_materials)\n",
        " \n",
        "device = torch.device('cuda')\n",
        " \n",
        "outputs=[]\n",
        "model.to(device)\n",
        " \n",
        "#!!!!!!!!!!!!!!!!!!!!!Select Correct Model from the best models directory!!!!!!!!!!!!!!!!!!!!!!!!!1\n",
        "#model.load_state_dict(torch.load('drive/My Drive/Mina_Colab_Notebook/best_models/500epoch3train3test486_R2_Sep.pth'), strict=False)\n",
        "model.load_state_dict(torch.load(models_directory+model_group + current_model_name+model_number+'.pth'), strict=False)\n",
        " \n",
        " \n",
        " \n",
        " \n",
        "model.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FCN(\n",
              "  (backbone): IntermediateLayerGetter(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (8): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (9): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (10): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (11): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (12): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (13): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (14): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (15): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (16): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (17): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (18): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (19): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (20): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (21): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (22): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): FCNHead(\n",
              "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "    (4): Conv2d(512, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X49s7N2WXHKM"
      },
      "source": [
        "#**Image Segmentation and Data Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgNZi5B0YB47",
        "outputId": "b9460403-b0b8-4f75-9e99-6e290d0701e3"
      },
      "source": [
        "#Use this block for data extraction using the regionprops function at the bottom of this code, good for area/perimeter, counting.\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\"\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import argparse\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "\n",
        "from glob import glob\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from scipy.ndimage import morphology\n",
        "sys.path.append(os.path.join(sys.path[0]))  # To find local version of the library\n",
        "\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "import torch\n",
        "from skimage.color import rgb2grey, label2rgb\n",
        "\n",
        "\n",
        "\n",
        "from skimage import io,exposure, feature, filters, io, measure, morphology, restoration, segmentation, transform, util, data, color\n",
        "from skimage.measure import label, regionprops\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!Put the name of the folder with the images you want to analyze here!!!!!!!!!!!!!!!!!!!!!!!\n",
        "#dir_name = inference_directory\n",
        "dir_name=test_images\n",
        "\n",
        "filenames = os.listdir(dir_name)\n",
        "\n",
        "\n",
        "whole_leaf_tables=[]\n",
        "file_name=[]\n",
        "color=[]\n",
        "value_counts=[]\n",
        "sort_idx = np.argsort([(int(filename.split(proceeding)[1].split(following)[0])) for filename in filenames])\n",
        "# sort_idx = np.argsort([(int(filename.split('.')[0])) for filename in filenames])\n",
        "for i in sort_idx:\n",
        "    #makes new directory called \"(directory name here) + name in red\" that your new images go into\n",
        "    new_dir_name = output_directory\n",
        "    if not os.path.exists(new_dir_name):\n",
        "      os.makedirs(new_dir_name)\n",
        "    \n",
        "    for mat in materials:\n",
        "      new_dir_name_mat= new_dir_name + mat.name\n",
        "      if not os.path.exists(new_dir_name_mat):\n",
        "        os.makedirs(new_dir_name_mat)\n",
        "    filename = filenames[i]\n",
        "    \n",
        "    image = Image.open(dir_name +'/'+ filenames[i])\n",
        "    image1 = (image)\n",
        "    image1 = np.array(image1)\n",
        "    \n",
        "    w, h = image.size\n",
        "    print(image.size)\n",
        "    #!!!!!!!!!!!!!!!!!!!!Make sure scale matches!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    scale=scale\n",
        "    newW, newH = int(scale * w), int(scale * h)\n",
        "    image=image.resize((newW, newH))\n",
        "    image=np.array(image)\n",
        "    new_im=np.zeros((3, newH, newW))\n",
        "    new_im[0,:,:]=image\n",
        "    new_im[1,:,:]=image\n",
        "    new_im[2,:,:]=image\n",
        "    image=new_im\n",
        "    \n",
        "\n",
        "    image=torch.from_numpy(image)\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!Make sure normalization goes match above!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    image=T.Normalize(mean=mean, std=std)(image)\n",
        " \n",
        "    image.unsqueeze_(0)\n",
        "    image = image.to(device=device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    tic=time.time()\n",
        "    with torch.no_grad():\n",
        "      mask=model(image)['out']\n",
        "      mask=nn.Sigmoid()(mask)\n",
        "      # mask=mask.cpu().detach().numpy()\n",
        "    toc=time.time()\n",
        "    print('time: '+str(toc-tic))\n",
        "#!!!!!!!!!!!!!!!!!Make sure there are the same number of mask outputs as you trained on!!!!!!!!!!!!!!!!!!!!!\n",
        "    image_rescaled = rescale(image1, scale, anti_aliasing=True)\n",
        "    combined_image = image_rescaled = rescale(image1, scale, anti_aliasing=True)\n",
        "    list_of_mat_tables = []\n",
        "    for i, mat in enumerate(materials):\n",
        "      mat_mask = mask.cpu().detach().numpy()[0,i,:,:]\n",
        "      mat_mask[mat_mask >= mat.confidence_threshold] = mat.output_val\n",
        "      mat_mask[mat_mask < mat.confidence_threshold] = 0\n",
        "\n",
        "      combined_image = np.add(combined_image, mat_mask, casting=\"unsafe\")\n",
        "      img3=label2rgb(combined_image, image_rescaled, alpha=0.2)  \n",
        "      io.imsave(new_dir_name+'/' + mat.name + '/'+filename.split(following)[0]+'_' + mat.name + \"_mask.png\", mat_mask)\n",
        "      np_mat = np.array(mat_mask)\n",
        "\n",
        "      \n",
        "      label_mat = label(np_mat, background = 0)\n",
        "      if np.sum(label_mat)<1:\n",
        "        label_mat=np.ones_like(label_mat)\n",
        "      elif np.sum(label_mat)>=1:\n",
        "        label_mat=label_mat\n",
        "\n",
        "      \n",
        "      mat_table=measure.regionprops_table(label_mat, combined_image, properties=['label','area','perimeter'])\n",
        "      mat_table=pd.DataFrame(mat_table)\n",
        "      if mat_table['area'].sum()==np.ones_like(label_mat).sum():\n",
        "        mat_table_a=mat_table['area'].sum()==0\n",
        "      \n",
        "      elif mat_table['area'].sum()<np.ones_like(label_mat).sum():\n",
        "        mat_table_a=mat_table['area'].sum()/(scale**2)\n",
        "\n",
        "      if mat_table['area'].sum()==np.ones_like(label_mat).sum():\n",
        "        mat_table_p=mat_table['perimeter'].sum()==0\n",
        "     \n",
        "      elif mat_table['area'].sum()<np.ones_like(label_mat).sum():\n",
        "        mat_table_p=mat_table['perimeter'].sum()/(scale)\n",
        "\n",
        "\n",
        "\n",
        "      # mat_table_a=mat_table['area'].sum()\n",
        "      # mat_table_p=mat_table['perimeter'].sum()\n",
        "\n",
        "      list_of_mat_tables.append(mat_table_a)\n",
        "      list_of_mat_tables.append(mat_table_p)\n",
        "      \n",
        "\n",
        "    io.imsave(new_dir_name+'/'+filename.split(following)[0]+'.png', combined_image)    \n",
        "\n",
        "    print(list_of_mat_tables)\n",
        "    list_of_mat_tables = np.array(list_of_mat_tables, dtype=int)\n",
        "    whole_leaf = value_counts.append(list_of_mat_tables)\n",
        "    print(whole_leaf)\n",
        "\n",
        "    name = file_name.append([filename])\n",
        "  \n",
        "counts=(np.array(value_counts))\n",
        "print(counts)\n",
        "names=(np.array(file_name))\n",
        "print(names)\n",
        "\n",
        "whole_leaf=np.concatenate((names, counts), axis=1)\n",
        "\n",
        "\n",
        "# whole_leaf_table=pd.concat((names, whole_leaf_tables), axis=1)\n",
        "whole_leaf_table=(pd.DataFrame(whole_leaf))\n",
        "print(whole_leaf_table)\n",
        "table_columns = [[f\"{mat.name} area(pix)\", f\"{mat.name} perimeter (pix)\"] for mat in materials]\n",
        "print(table_columns)\n",
        "table_columns = [element for sublist in table_columns for element in sublist] #flattening the list\n",
        "print(table_columns)\n",
        "table_columns = [\"file_name\"] + table_columns\n",
        "print(table_columns)\n",
        "whole_leaf_table.columns = table_columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_row',None)\n",
        "# print(d)\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!Can change table output name here!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "whole_leaf_table.to_csv(new_dir_name+'/'+'material area and perimeter.csv')\n",
        "#print (counts)\n",
        "print('----end-----')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'01a Intro Env Soil Chem  and Soil Minerals_Jan9.pdf'\n",
            "'01b Soil Minerals_Jan11.pdf'\n",
            "'01c Soil Minerals_Jan13.pdf'\n",
            "'01e Soil Minerals_Jan20.pdf'\n",
            " 01f_Applied_Minerals_Rippner.pdf\n",
            "'02a organic matter_Jan23.pdf'\n",
            "'02b organic matter_Jan25.pdf'\n",
            "'02c organic matter_Jan27.pdf'\n",
            "'02d organic matter_Jan30.pdf'\n",
            "'03b Soil solution_Feb6.pdf'\n",
            "'03c Soil solution_Feb8.pdf'\n",
            "'03d Soil solution_Feb10.pdf'\n",
            "'03e Soil solution_Feb13.pdf'\n",
            "'04a Sorption_Feb15.pdf'\n",
            "'04c Sorption_Feb22.pdf'\n",
            "'04d Sorption_Feb24.pdf'\n",
            "'04e Sorption_Feb27.pdf'\n",
            "'04g Sorption_March3.pdf'\n",
            "'05b redox_March10.pdf'\n",
            "'05c redox_March13.pdf'\n",
            "'05d redox_March15.pdf'\n",
            "'06 Arsenic Lecture_march 17.pdf'\n",
            " 13_Mar_12-15_Grades-SSC_202_001_WQ_2017.gsheet\n",
            "'142500 Tube A  Almond Buds0017.tif'\n",
            "'15N figures 16NOV17.pptx'\n",
            " 20161114_201004.mp4\n",
            "'2017 Review Questions - 1.pdf'\n",
            "'2017 Review Questions 3-key.pdf'\n",
            "'2017 Review Questions - 3.pdf'\n",
            " 20190114_144554.mp4\n",
            " 20200216_023747_Devin_Forest10x.h5_00000.tiff.png\n",
            " 20200216_023747_Devin_Forest10x.h5_00001.tiff.png\n",
            " 20200216_023747_Devin_Forest10x.h5_00002.tiff.png\n",
            "'32P Images from 121618.pptx'\n",
            "'32P SOP.gdoc'\n",
            " 3-5COMMUNITYCONNECTION_plan.docx\n",
            " 3-5HANDOUT-COUNCILCIRCLEGUIDELINES.docx\n",
            " 4_1_40kx_4.tif\n",
            "'64Cu study.png'\n",
            "'7900 ICP-MS.png'\n",
            " AAAQ15928.pdf\n",
            " AAAQ15962.pdf\n",
            " ACL2572164.pdf\n",
            " AcutelyToxicSolidsLiquids_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            " aggregate_______2.mpg\n",
            " aggregate.mpg\n",
            "'aggregate new_Slomo.mp4'\n",
            " aggregate________Slomo.mp4\n",
            "'Ag microbiome call'\n",
            "'Alex Compost'\n",
            "'ALS R1.pdf'\n",
            "'ALS Workflow'\n",
            " Ammonium_Nitrate_10-13.docx\n",
            "'Annual Refresher Group Training_20170321.docx'\n",
            "'Bacteria on lettuce roots.png'\n",
            " Bayer\n",
            "'Bayer Supplies.gsheet'\n",
            "'Bayer Update 41919 (1).pptx'\n",
            "'Bayer Update 41919.pptx'\n",
            "'Beamline Planning.gdoc'\n",
            "'Biochar pictures.pptx'\n",
            "'Biochar Videos'\n",
            "'Birnessite-(Na0.3Ca0.1K0.1)(Mn4+,Mn3+)2O4 · 1.5 H2O.tif'\n",
            "'Blank Quiz.gform'\n",
            " Buds\n",
            " Carcinogens_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            "'Chloe Annotations.zip'\n",
            "'Chris FCN Workflow'\n",
            "'Christine FCN Workflow'\n",
            "'Clarissa colab'\n",
            "'Class Todo.gdoc'\n",
            "'Cleaning Duckweed SOP.docx'\n",
            "'CLS proposal work flow'\n",
            " CMGI_Pilot_Funds_2017_DR_RD_SJP.pdf\n",
            " colab_notebook_DARplay\n",
            "'Colab Notebook for Beth'\n",
            "'Colab Notebooks'\n",
            "'Colab Notebooks_'\n",
            "'Colab Notebooks_DR'\n",
            "'Colab Notebooks_MinaDAR'\n",
            "'column 5_Trim.mp4'\n",
            " column6_Trim.mp4\n",
            "'Column Pic (1).png'\n",
            "'Column Pic.png'\n",
            "'Community Composition Stats for Andrew.docx'\n",
            "'Compost Final Day CN 1 to 56.png'\n",
            "'Compost Final Day CN 57 to 84.png'\n",
            "'Compost Final Day CN.png'\n",
            "'Compost Initial Day CN 1 to 23.png'\n",
            "'Compost Initial Day CN 24 to 60.png'\n",
            "'Compost Initial Day CN 61 to 84.png'\n",
            "'Compost Mixing Schedule.gsheet'\n",
            "'CoO 2.tif'\n",
            " CoO.mp4\n",
            "'CoO NPs (40K zoom) better.png'\n",
            "'CoO NPs (40K zoom).png'\n",
            " CoO_NPs.mp4\n",
            "'Corn P uptake V2 (1).zip'\n",
            "'Corn P uptake V2 (2).zip'\n",
            "'Corn P uptake V2.zip'\n",
            " Corrosives_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            "'Costs and Design Apendix for Project.docx'\n",
            "'Costs and Design Apendix for Project.gdoc'\n",
            "'costs for each system.gsheet'\n",
            "'Costs for each System.xlsx'\n",
            "'CuO HM10.tif'\n",
            "'CuO HM_1.tif'\n",
            " dani\n",
            "'dani column_5.mpg'\n",
            "'dani column_7_1 (1).mpg'\n",
            "'dani column_7_1.mpg'\n",
            "'dani column__Trim.mp4'\n",
            "'DAR122920_SF_Edits Land management controls microbial response to Cu nanoparticles_sf.docx'\n",
            "'DAR122920_SF_Edits Land management controls microbial response to Cu nanoparticles_sf.gdoc'\n",
            " Design_Project_243a,_fall_2013l.docx\n",
            "'Devin_Ripner_Final Review.pdf'\n",
            " Draft.docx\n",
            " Draft.gdoc\n",
            "'Dragonfly 2020-06-15 15-07-53.mp4'\n",
            "'Dragonfly 2020-06-15 20-58-51.mp4'\n",
            "'Dragonfly 2020-06-29 11-31-30.mp4'\n",
            "'Dragonfly 2020-06-29 11-32-20.mp4'\n",
            "'Dragonfly 2020-06-29 11-33-31.mp4'\n",
            "'Dragonfly 2020-06-29 11-57-28.mp4'\n",
            "'Dragonfly 2020-06-29 19-49-49.mp4'\n",
            "'Dragonfly 2020-07-02 21-08-32.mp4'\n",
            "'Dragonfly 2020-07-03 16-29-10.mp4'\n",
            "'Dragonfly 2020-07-03 20-48-24.mp4'\n",
            "'Dragonfly 2020-07-03 21-09-47.mp4'\n",
            "'Dragonfly 2020-10-18 15-31-43.mp4'\n",
            "'Dragonfly 2020-11-05 10-49-30.mp4'\n",
            "'Dragonfly 2020-11-05 20-04-53.mp4'\n",
            "'DRP competition'\n",
            "'Duckweed 2.jpg'\n",
            "'Duckweed Growth.xlsx'\n",
            " Duckweed.png\n",
            "'E33 no PH adjustment.gsheet'\n",
            "'E33 no PH adjustment.xlsx'\n",
            " earlyferm.gif\n",
            "'Easter Island Slides.pdf'\n",
            "'ECG Application.doc'\n",
            "'ECG Application.gdoc'\n",
            "'Endangered soils are those with greater than 50.docx'\n",
            "'Environmental Metal Contamination.pptx'\n",
            " Erosion.jpg\n",
            "'E-Safety Training Attendance Record_2020_CR_AM_NB_TK_KK_IH_FD_KA_DR.pdf'\n",
            "'ESI (1).jpg'\n",
            " ESI.jpg\n",
            "'Event Summary.gdoc'\n",
            "'Excess Water.png'\n",
            "'FCN for Garett'\n",
            "'FCN WORKFLOW PAPER'\n",
            " feldstone_Slomo.mp4\n",
            "'Fertilizer and Plant Nutrition Guide FAO (1).pdf'\n",
            "'Fertilizer and Plant Nutrition Guide FAO.pdf'\n",
            " filepath\n",
            "'Final Exam Practice.pdf'\n",
            "'Financial Need.pdf'\n",
            " FlammableLiquids_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DR.pdf\n",
            "'Funding 2014-2015.gdoc'\n",
            "'Geisenheim Test 109 Davis'\n",
            "'Generalized leaf Sept 411 r3.mpg'\n",
            "'GFH No PH Adjust Design.gsheet'\n",
            "'GFH No PH Adjust Design.xlsx'\n",
            "'GFH w PH Adjustment Design (1).gsheet'\n",
            "'GFH w PH Adjustment Design.gsheet'\n",
            "'GFH w PH Adjustment Design.xlsx'\n",
            "'Grape Soil Health Initiative'\n",
            "'Green House 0.png'\n",
            "'Green House 1.png'\n",
            "'Green House 2.png'\n",
            "'Green House 3.png'\n",
            "'Green House 4.png'\n",
            "'Green House 5.png'\n",
            "'Green House 6.png'\n",
            "'Handbook for Integrated Soil Fertility Management. Africa.pdf'\n",
            " HW1_HYD134_answer_key.pdf\n",
            " HW2_HYD134_answer_key.pdf\n",
            "'HW3_HYD134_AlF Answer Key.pdf'\n",
            " HW4_HYD134_answer_key.pdf\n",
            "'HW5_HYD134 answer key.pdf'\n",
            "'HXMA_dotE Lab view (1).zip'\n",
            "'HXMA_dotE Lab view.zip'\n",
            "'HXMA Fits Labview.zip'\n",
            "'HYD_134_HW6_answer key.pdf'\n",
            "'HYD_134_HW7 answer key.pdf'\n",
            "'HYD134 Lab Manual_2016.gdoc'\n",
            "'Hydroponic Carrot (1).png'\n",
            "'Hydroponic Carrot.png'\n",
            "'image (1).png'\n",
            "'image (2).png'\n",
            "'image (3).png'\n",
            "'image (4).png'\n",
            "'image (5).png'\n",
            " image_FCN_binary\n",
            " image.png\n",
            " images_\n",
            "'images_ (1)'\n",
            " IMG_20180623_192708161.jpg\n",
            "'Incubation Figures_ajm.pptx'\n",
            "'Incubation Figures.pptx'\n",
            " incubation.png\n",
            "'In-Vivo tracking of Radiolabeled nanoparticles.pdf'\n",
            "'Job Talk USDA ARS Washington.pptx'\n",
            "'Jordon Media.pptx'\n",
            "'late ferm.gif'\n",
            " LBNL.png\n",
            "'Leaf 411_2_Slomo.mp4'\n",
            "'Leaf 411.avi'\n",
            "'Leaf 486 oct r2_Slomo.mp4'\n",
            "'Leaf 486_R2_Sep.avi'\n",
            " leaf_area_seg.zip\n",
            "'Lettuce NP uptake.png'\n",
            "'Lettuce Root Growth Experiment.png'\n",
            "'liming soil health 17OCT17.docx'\n",
            " Magnetite-Fe3O4.tif\n",
            "'Managing Soil Organic Matter.pdf'\n",
            " Mayachar4.tif\n",
            "'Me and the ICP-Ms.png'\n",
            "'Midterm #1 CO2 closed 2016 answer key.pdf'\n",
            "'Midterm #1 CO2 closed 2016.pdf'\n",
            "'Midterm #2 2017 Answer Key.pdf'\n",
            " Mina_Colab_Notebook\n",
            "'Moisture content correction for compost initial and final 1 to 34.png'\n",
            "'Moisture content correction for compost initial and final 36 to 73.png'\n",
            "'Moisture content correction for compost initial and final 74 to 84.png'\n",
            "'My photos'\n",
            "'nanoparticle uptake by lactuca.pdf'\n",
            "'nanoparticle uptake by Latuca.pdf'\n",
            "'Natalie Poster.pptx'\n",
            "'NDCRO-D-17-01961R1 response to reviewers 29AUG17_SJP_BA.docx'\n",
            "'new leaf_1__.avi'\n",
            " Nocco2021_Seminar_UCD_Plant_Sci.pptx\n",
            "'Notes from 72018 meeting.docx'\n",
            "'NP in Column on Mag.png'\n",
            "'oak '\n",
            "'Oak 4.emf'\n",
            "'oak reconstruction 2.emf'\n",
            "'oak reconstruction 3.emf'\n",
            "'Old ALS'\n",
            " olddataframe.csv\n",
            "'Oxalate-P Manuscript_draft_v3.docx'\n",
            "'Parikh Rippner SSSA Tomato CuO.pptx'\n",
            "'Personal Statement.gdoc'\n",
            " Pictures\n",
            "'Pixel Quantification Practice 122718_2 (1).xlsx'\n",
            "'Pixel Quantification Practice 122718_2.xlsx'\n",
            "'PNNL Proposal'\n",
            "'PNNL Soil Colab'\n",
            "'PONE-D-17-26375 Response to reviews 2DEC17_AJM.docx'\n",
            "'PowerPoint Slide Show  -  Jordon Media.pptx  -  Last saved by user 2020-11-11 20-00-48.mp4'\n",
            "'PowerPoint Slide Show  -  Soil Con talk 2021-01-25 17-48-19_Trim.mp4'\n",
            "'Practice Exam-1.pdf'\n",
            "'Practice Exam-2.pdf'\n",
            "'Practice Exam-3.pdf'\n",
            "'Practice exam questions3.pdf'\n",
            "'Practice Midterm Exam #1.pdf'\n",
            "'Practice Midterm Exam #2.pdf'\n",
            "'Practice redox questions.pdf'\n",
            " preferm.gif\n",
            "'Problem set #1-key.pdf'\n",
            "'Problem set #2-key.pdf'\n",
            "'Problem set #3-key.pdf'\n",
            "'Problem set #4-key.pdf'\n",
            "'Problem set #5-key.pdf'\n",
            "'Problem set #6.pdf'\n",
            "'Problem set #7-key.pdf'\n",
            "'Problem set #8-key.pdf'\n",
            " PSET_1_2017_KEY.pdf\n",
            " PSET_2_2017_KEY.pdf\n",
            " PSET_3_2017_KEY.pdf\n",
            " PSET_4_2017_KEY.pdf\n",
            " PSET_5_Key_2017.pdf\n",
            " Pyrophorics_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            "'Questions for Will.gdoc'\n",
            "'reconfiguring ICPMS.docx'\n",
            "'Redox midterm 2016 answer key.pdf'\n",
            "'Redox midterm 2016.pdf'\n",
            " ReproductiveToxins_SOP_CR_AM_NB_TK_KK_IH_FD_KA_DAR.pdf\n",
            "'Research Todo'\n",
            "'Riparian Soil Profile.png'\n",
            "'Rippner CuO Nanoparticles Soil Incubation 102317 (1).pptx'\n",
            "'Rippner CuO Nanoparticles Soil Microbial Size and Structure (1).pptx'\n",
            "'Rippner CuO Nanoparticles Soil Microbial Size and Structure.pptx'\n",
            "'Rippner, Devin.pdf'\n",
            "'RIPPNER,devin-W2018-TA-iDocJasper-1 (1).docx'\n",
            "'RIPPNER,devin-W2018-TA-iDocJasper-1 (2).docx'\n",
            " RIPPNER,devin-W2018-TA-iDocJasper-1.docx\n",
            " Role_Call_blank.PNG\n",
            " Roots.png\n",
            "'Sanjai Mentorship Nomination Letter.gdoc'\n",
            "'Sarah and I.png'\n",
            "'Shalini Images 32P'\n",
            " Shared\n",
            "'Shrink Swell.png'\n",
            "'small_image bce 100 epoch1 (1).gsheet'\n",
            "'small_image bce 100 epoch1.gsheet'\n",
            "'Soil Colab'\n",
            "'soil column 1.avi'\n",
            "'soil column 2.avi'\n",
            "'soil column 3.avi'\n",
            "'soil column 4.avi'\n",
            "'Soil Con talk__.mp4'\n",
            "'Soil Health Paper'\n",
            "'Soils Outreach - Parikh Lab'\n",
            " Soils_Wines_Vines_2017.docx\n",
            " Spectroscopy_Manuscript.docx\n",
            " Spectroscopy_Manuscript.gdoc\n",
            "'spurs embedding.pdf'\n",
            "'SSC10 zip.zip'\n",
            "'SSSA Joint Symposia Proposal.docx'\n",
            "'SSSA Talk Actual 102117.pptx'\n",
            " student_assistant_pay_plan.pdf\n",
            "'Student Assistant Position Information Form.pdf'\n",
            "'Submission Ready Folder'\n",
            "'T0 Introduction Slides.pdf'\n",
            "'T10 Slides.pdf'\n",
            "'T11 Slides.pdf'\n",
            "'T12 Slides.pdf'\n",
            "'T13 Slides.pdf'\n",
            "'T14 Slides.pdf'\n",
            "'T15-16 Slides.pdf'\n",
            "'T17 Slides.pdf'\n",
            "'T18 Slides.pdf'\n",
            "'T19 Slides.pdf'\n",
            "'T1 slides.pdf'\n",
            "'T20 Slides.pdf'\n",
            "'T2 Slides.pdf'\n",
            "'T3 Slides.pdf'\n",
            "'T4 Slides.pdf'\n",
            "'T5 Slides.pdf'\n",
            "'T6 Slides.pdf'\n",
            "'T7 Slides.pdf'\n",
            "'T8 Slides.pdf'\n",
            "'T9 Slides.pdf'\n",
            "'task_segmentation d7-2020_09_25_14_35_06-cvat for images 1.1 (4).zip'\n",
            " testcropimage.tif\n",
            "'The transport and fate of manufactured nano-metal oxides SJP.pptx'\n",
            "'Tomato Paper'\n",
            "'Tropical Soil Biology and Fertility, A handbook of methods.pdf'\n",
            " Uganda_soils.kmz\n",
            " Untitled\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document (3).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled presentation.gslides'\n",
            "'Update on 32P project.pptx'\n",
            "'URC Poster 2015 edits.ppt'\n",
            "'USDA Compost Day 0 and final.xlsx'\n",
            "'USDA NP 2017_Draft_2.pptx'\n",
            "'Using Synchrotron Light to Probe Plant, Soil.pptx'\n",
            "'validation '\n",
            "'Virginia Tech'\n",
            "'Visiting Mina.gsheet'\n",
            "'Windows Media Player 2021-01-18 13-29-33_Trim_Trim (1).mp4'\n",
            "'Windows Media Player 2021-01-18 13-29-33_Trim_Trim (2).mp4'\n",
            "'Windows Media Player 2021-01-18 13-29-33_Trim_Trim.mp4'\n",
            " WS00560230-RR_Budget_1_4-V1.4.pdf\n",
            "'XANES EXAFS proposal.gdoc'\n",
            "'XANES Fig2.tif'\n",
            "'Yuhei and Zaahir.png'\n",
            "'Zaahir Biochar Presentation.pptx'\n",
            "(1566, 474)\n",
            "time: 0.031023502349853516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 30.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 150.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 100.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 180.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0.08235294117653479, 435.678431372549]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[250740.0, 6755.39105243401, 67717.0, 6795.693793113451, 255588.0, 22071.488839957252, 97948.0, 19415.359405256622, 69265.0, 3182.2724368761405, 14976.0, 1069.8031739553294]\n",
            "None\n",
            "(1566, 474)\n",
            "time: 0.0313570499420166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 30.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 150.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 100.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 180.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0.13333333333335118, 435.75686274509803]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[248309.0, 6796.6458864299475, 66437.0, 6678.789247542955, 269613.0, 23914.284871237647, 123679.0, 21964.629570622958, 39322.0, 2239.9078631008238, 8357.0, 609.286363288515]\n",
            "None\n",
            "(1566, 474)\n",
            "time: 0.030385255813598633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 30.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 150.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 100.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 180.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0.11764705882353475, 435.6156862745098]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[259517.0, 6787.976838871637, 67312.0, 6712.610531992765, 231065.0, 20596.99118580545, 105083.0, 18291.78058202518, 78955.0, 2799.7617228637364, 15251.0, 841.1513703397204]\n",
            "None\n",
            "(1566, 474)\n",
            "time: 0.028922557830810547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 30.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 150.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 100.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 180.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0.11372549019608144, 435.65882352941173]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[274373.0, 6806.077343935025, 67928.0, 6772.154687870049, 217437.0, 18235.96557369853, 74804.0, 15090.36095889143, 102053.0, 3630.114103330233, 18204.0, 1287.6204537917824]\n",
            "None\n",
            "(1566, 474)\n",
            "time: 0.027137279510498047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 30.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 150.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 100.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0.0, 180.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0.06274509803922171, 405.7725490196078]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[271012.0, 6862.427632360468, 66601.0, 6849.441051158564, 227675.0, 19402.37578264755, 94641.0, 17739.179464217155, 84538.0, 3771.7232303649735, 10567.0, 868.9503602129438]\n",
            "None\n",
            "[[250740   6755  67717   6795 255588  22071  97948  19415  69265   3182\n",
            "   14976   1069]\n",
            " [248309   6796  66437   6678 269613  23914 123679  21964  39322   2239\n",
            "    8357    609]\n",
            " [259517   6787  67312   6712 231065  20596 105083  18291  78955   2799\n",
            "   15251    841]\n",
            " [274373   6806  67928   6772 217437  18235  74804  15090 102053   3630\n",
            "   18204   1287]\n",
            " [271012   6862  66601   6849 227675  19402  94641  17739  84538   3771\n",
            "   10567    868]]\n",
            "[['411_R3_Sep_slice_1.png']\n",
            " ['411_R3_Sep_slice_2.png']\n",
            " ['411_R3_Sep_slice_3.png']\n",
            " ['411_R3_Sep_slice_4.png']\n",
            " ['411_R3_Sep_slice_5.png']]\n",
            "                       0       1     2      3     4       5      6       7   \\\n",
            "0  411_R3_Sep_slice_1.png  250740  6755  67717  6795  255588  22071   97948   \n",
            "1  411_R3_Sep_slice_2.png  248309  6796  66437  6678  269613  23914  123679   \n",
            "2  411_R3_Sep_slice_3.png  259517  6787  67312  6712  231065  20596  105083   \n",
            "3  411_R3_Sep_slice_4.png  274373  6806  67928  6772  217437  18235   74804   \n",
            "4  411_R3_Sep_slice_5.png  271012  6862  66601  6849  227675  19402   94641   \n",
            "\n",
            "      8       9     10     11    12  \n",
            "0  19415   69265  3182  14976  1069  \n",
            "1  21964   39322  2239   8357   609  \n",
            "2  18291   78955  2799  15251   841  \n",
            "3  15090  102053  3630  18204  1287  \n",
            "4  17739   84538  3771  10567   868  \n",
            "[['background area(pix)', 'background perimeter (pix)'], ['epidermis area(pix)', 'epidermis perimeter (pix)'], ['mesophyll area(pix)', 'mesophyll perimeter (pix)'], ['air_space area(pix)', 'air_space perimeter (pix)'], ['bundle_sheath_extension area(pix)', 'bundle_sheath_extension perimeter (pix)'], ['vein area(pix)', 'vein perimeter (pix)']]\n",
            "['background area(pix)', 'background perimeter (pix)', 'epidermis area(pix)', 'epidermis perimeter (pix)', 'mesophyll area(pix)', 'mesophyll perimeter (pix)', 'air_space area(pix)', 'air_space perimeter (pix)', 'bundle_sheath_extension area(pix)', 'bundle_sheath_extension perimeter (pix)', 'vein area(pix)', 'vein perimeter (pix)']\n",
            "['file_name', 'background area(pix)', 'background perimeter (pix)', 'epidermis area(pix)', 'epidermis perimeter (pix)', 'mesophyll area(pix)', 'mesophyll perimeter (pix)', 'air_space area(pix)', 'air_space perimeter (pix)', 'bundle_sheath_extension area(pix)', 'bundle_sheath_extension perimeter (pix)', 'vein area(pix)', 'vein perimeter (pix)']\n",
            "----end-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwWQvEJK7f8D"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWxoXzF1HYxb"
      },
      "source": [
        "#For loop for FCN model training Cell Code Box 4\n",
        "#!cd \"drive/My Drive/Colab Notebooks\"\n",
        "# Semantic Segmentation and Data Extraction in Pytorch Using FCN by Pranav Raja and a tiny bit by Devin Rippner (Plant AI and BioPhysics Lab)\n",
        "# a work in progress, works well overall but need more people to look at it and identify bugs\n",
        "#%%\n",
        " \n",
        "import torchvision\n",
        "from torchvision.models.segmentation.fcn import FCNHead\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "# from torch._six import container_abcs, string_classes, int_classes\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import psutil\n",
        "# from pytorch_loss import FocalLossV1, FocalLossV2, FocalLossV3 \n",
        " \n",
        "dir_checkpoint = \"drive/My Drive/FCN WORKFLOW PAPER/best_models/\"\n",
        " \n",
        "model_group='small_image_bce p2 100 epoch_38/'\n",
        "num_models=10\n",
        "os.mkdir(dir_checkpoint+model_group)\n",
        " \n",
        "for i in range(num_models):\n",
        "  #!!!!!!! Here we pull in a pretrained FCN on torch and we replace the output layer since we have six classes rather than 21!!!!!!!!\n",
        "  num_classes=6\n",
        "  model=torchvision.models.segmentation.fcn_resnet101(pretrained=True, progress=True)\n",
        "  model.classifier=FCNHead(2048, num_classes)\n",
        "  \n",
        "  def trainval_split(dataset, val_fraction=0.5):\n",
        " \n",
        "     validation_size = int(len(dataset) * val_fraction)\n",
        "     train_size = len(dataset) - validation_size\n",
        "     #print(validation_size)\n",
        "     #print(train_size)\n",
        "     #print(len(dataset))\n",
        "     #print(dataset.dataset_size)\n",
        "     train, val = torch.utils.data.random_split(dataset, [train_size, validation_size], generator=torch.Generator().manual_seed(i))\n",
        " \n",
        "     return train, val\n",
        " \n",
        " \n",
        " \n",
        "  dataset= BasicDataset(training_image_directory, training_mask_directory, 1, transform=True)\n",
        "  dataset_train, dataset_val=trainval_split(dataset, val_fraction=0.4)\n",
        "  #!!!!!select folders for the images and masks associated with training and validation here. Also specify image scaling factor here!!!!!!!!!!!!!!!!\n",
        "  #dataset_train = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/small_image/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/small_mask/\", 1, transform=True)\n",
        "  #dataset_val = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/small_image/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/small_mask/\", 1, transform=False)\n",
        "  # dataset_train = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/train/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/train/mask_edited2/\", 1, transform=True)\n",
        "  # dataset_val = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/test/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/test/mask_edited2/\", 1, transform=False)\n",
        "  \n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Specify Batch Size Here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  train_loader = DataLoader(dataset_train, batch_size=1, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)#, collate_fn=pad_collate)\n",
        "  val_loader = DataLoader(dataset_val, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)#, collate_fn=pad_collate)\n",
        " \n",
        " \n",
        "  #%%\n",
        " \n",
        "  # this is the train code \n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!! Input epochs here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  num_epochs=100\n",
        "  # read up on optimizers but Adam should work for now, if you get good results with Adam then you can try SGD (it's harder to tune but usually converges better)\n",
        "  optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        " \n",
        "  #just initializing a value called best_loss\n",
        "  best_loss=999\n",
        " \n",
        "  # choose a loss function\n",
        "  # criterion=nn.CrossEntropyLoss()\n",
        "  #criterion=nn.BCELoss().cuda()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  # criterion = FocalLossV2()\n",
        "  # class diceloss(nn.Module):\n",
        "  #     def __init__(self, epsilon):\n",
        "  #         # super(diceloss, self).init()\n",
        "  #         super(diceloss, self).__init__()\n",
        "  #         self.sigmoid=nn.Sigmoid()\n",
        "  #         self.epsilon=epsilon\n",
        "  #         # print('HI')\n",
        "  #     def forward(self, pred, target):\n",
        "  #         if target.size() != pred.size():\n",
        "  #             raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), pred.size()))\n",
        "  #         pred=self.sigmoid(pred)\n",
        "  #         tp=torch.sum(target*pred, (1,2,3))\n",
        "  #         fp=torch.sum((1-target)*pred, (1,2,3))\n",
        "  #         fn=torch.sum(target*(1-pred), (1,2,3))\n",
        "  #         # precision=tp/(tp+fp)\n",
        "  #         # recall=tp/(tp+fn)\n",
        "  #         f1=(tp)/(tp+self.epsilon+0.5*(fp+fn))\n",
        "  #         # print(f1)\n",
        "  #         return 1-torch.mean(f1)\n",
        "  # criterion=diceloss(epsilon=1e-9)\n",
        "  # model.train()\n",
        "  # model.train()\n",
        "  #this is the train loop\n",
        "  for epoch in range(num_epochs):\n",
        "      print(psutil.virtual_memory().percent)\n",
        "      print('Epoch: ', str(epoch))\n",
        "    #add back if doing fractional training\n",
        "      train_loader.dataset.dataset.transform=True\n",
        "      model.train()\n",
        "      for images, masks in train_loader:\n",
        " \n",
        "          images = images.to(device=device, dtype=torch.float32)\n",
        "          masks = masks.to(device=device, dtype=torch.float32)\n",
        " \n",
        "          #forward pass\n",
        "          preds=model(images)['out'].cuda()\n",
        "        \n",
        "          #compute loss\n",
        "          loss=criterion(preds, masks)\n",
        "        \n",
        "          #reset the optimizer gradients to 0\n",
        "          optimizer.zero_grad()\n",
        " \n",
        "          #backward pass (compute gradients)\n",
        "          loss.backward()\n",
        " \n",
        "          #use the computed gradients to update model weights\n",
        "          optimizer.step()\n",
        " \n",
        "          print('Train loss: '+str(loss.to('cpu').detach()))\n",
        "      # model.eval()\n",
        "      #add back if doing fractional training\n",
        "      val_loader.dataset.dataset.transform=False\n",
        "      current_loss=0\n",
        "      \n",
        "      #test on val set and save the best checkpoint\n",
        "      model.eval()\n",
        "      for images, masks in val_loader:\n",
        "          images = images.to(device=device, dtype=torch.float32)\n",
        "          masks = masks.to(device=device, dtype=torch.float32)\n",
        "          preds=model(images)['out'].cuda()\n",
        "          # print(preds)\n",
        "          # print(masks)\n",
        "          loss=criterion(preds, masks)\n",
        "          #print('hi')\n",
        "          current_loss+=loss.to('cpu').detach()\n",
        "          del images, masks, preds, loss\n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!Re-name model here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!        \n",
        "      if best_loss>current_loss:\n",
        "          best_loss=current_loss\n",
        "          print('Best Model Saved!, loss: '+ str(best_loss))\n",
        "          torch.save(model.state_dict(), dir_checkpoint+model_group + 'small_image_bce p2 100 epoch_34'+str(i+1)+\".pth\")\n",
        "      else:\n",
        "          print('Model is bad!, Current loss: '+ str(current_loss) + ' Best loss: '+str(best_loss))\n",
        "      print('\\n')\n",
        " \n",
        " \n",
        "        \n",
        " \n",
        " \n",
        " \n",
        "# %%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuI5qMoiOAW6"
      },
      "source": [
        "**Wont crap out model training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh1uLW5JOABD"
      },
      "source": [
        "#For loop for FCN model training Cell Code Box 4\n",
        "#!cd \"drive/My Drive/Colab Notebooks\"\n",
        "# Semantic Segmentation and Data Extraction in Pytorch Using FCN by Pranav Raja and a tiny bit by Devin Rippner (Plant AI and BioPhysics Lab)\n",
        "# a work in progress, works well overall but need more people to look at it and identify bugs\n",
        "#%%\n",
        " \n",
        "import torchvision\n",
        "from torchvision.models.segmentation.fcn import FCNHead\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "# from torch._six import container_abcs, string_classes, int_classes\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import os\n",
        "# from pytorch_loss import FocalLossV1, FocalLossV2, FocalLossV3 \n",
        "\n",
        "dir_checkpoint = \"drive/My Drive/FCN WORKFLOW PAPER/best_models/\"\n",
        " \n",
        " \n",
        "model_group='small_image dice e000000001 200 epoch_1/'\n",
        "num_models=10\n",
        "os.mkdir(dir_checkpoint+model_group)\n",
        " \n",
        "for i in range(num_models):\n",
        "  #!!!!!!! Here we pull in a pretrained FCN on torch and we replace the output layer since we have six classes rather than 21!!!!!!!!\n",
        "  num_classes=6\n",
        "  model=torchvision.models.segmentation.fcn_resnet101(pretrained=True, progress=True)\n",
        "  model.classifier=FCNHead(2048, num_classes)\n",
        "  \n",
        "  # def trainval_split(dataset, val_fraction=0.5):\n",
        " \n",
        "  #   validation_size = int(len(dataset) * val_fraction)\n",
        "  #   train_size = len(dataset) - validation_size\n",
        "  #   # print(validation_size)\n",
        "  #   # print(train_size)\n",
        "  #   # print(len(dataset))\n",
        "  #   # print(dataset.dataset_size)\n",
        "  #   train, val = torch.utils.data.random_split(dataset, [train_size, validation_size], generator=torch.Generator().manual_seed(i))\n",
        " \n",
        "  #   return train, val\n",
        " \n",
        " \n",
        " \n",
        "  # dataset= BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/combined_image/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/combined_mask/\", 1, transform=True)\n",
        "  # dataset_train, dataset_val=trainval_split(dataset, val_fraction=0.2)\n",
        "  #!!!!!select folders for the images and masks associated with training and validation here. Also specify image scaling factor here!!!!!!!!!!!!!!!!\n",
        "  dataset_train = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/small_image/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/small_mask/\", 1, transform=True)\n",
        "  dataset_val = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/small_image/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/small_mask/\", 1, transform=False)\n",
        "  # dataset_train = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/train/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/train/mask_edited2/\", 1, transform=True)\n",
        "  # dataset_val = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/test/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/test/mask_edited2/\", 1, transform=False)\n",
        "  \n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Specify Batch Size Here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  train_loader = DataLoader(dataset_train, batch_size=1, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)#, collate_fn=pad_collate)\n",
        "  val_loader = DataLoader(dataset_val, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)#, collate_fn=pad_collate)\n",
        " \n",
        " \n",
        "  #%%\n",
        " \n",
        "  # this is the train code \n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!! Input epochs here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  num_epochs=200\n",
        "  # read up on optimizers but Adam should work for now, if you get good results with Adam then you can try SGD (it's harder to tune but usually converges better)\n",
        "  optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        " \n",
        "  #just initializing a value called best_loss\n",
        "  best_loss=999\n",
        " \n",
        "  # choose a loss function\n",
        "  # criterion=nn.CrossEntropyLoss()\n",
        "  #criterion=nn.BCELoss().cuda()\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # criterion = FocalLossV2()\n",
        "  class diceloss(nn.Module):\n",
        "      def __init__(self, epsilon):\n",
        "          # super(diceloss, self).init()\n",
        "          super(diceloss, self).__init__()\n",
        "          self.sigmoid=nn.Sigmoid()\n",
        "          self.epsilon=epsilon\n",
        "          # print('HI')\n",
        "      def forward(self, pred, target):\n",
        "          if target.size() != pred.size():\n",
        "              raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), pred.size()))\n",
        "          pred=self.sigmoid(pred)\n",
        "          tp=torch.sum(target*pred, (1,2,3))\n",
        "          fp=torch.sum((1-target)*pred, (1,2,3))\n",
        "          fn=torch.sum(target*(1-pred), (1,2,3))\n",
        "          # precision=tp/(tp+fp)\n",
        "          # recall=tp/(tp+fn)\n",
        "          f1=(tp)/(tp+self.epsilon+0.5*(fp+fn))\n",
        "          # print(f1)\n",
        "          return 1-torch.mean(f1)\n",
        "  criterion=diceloss(epsilon=0.000000001)\n",
        "  model.train()\n",
        "  # model.train()\n",
        "  #this is the train loop\n",
        "  for epoch in range(num_epochs):\n",
        "      print('Epoch: ', str(epoch))\n",
        "    #add back if doing fractional training\n",
        "      # train_loader.dataset.dataset.transform=True\n",
        "      model.train()\n",
        "      for images, masks in train_loader:\n",
        " \n",
        "          images = images.to(device=device, dtype=torch.float32)\n",
        "          masks = masks.to(device=device, dtype=torch.float32)\n",
        " \n",
        "          #forward pass\n",
        "          preds=model(images)['out'].cuda()\n",
        "        \n",
        "          #compute loss\n",
        "          loss=criterion(preds, masks)\n",
        "        \n",
        "          #reset the optimizer gradients to 0\n",
        "          optimizer.zero_grad()\n",
        " \n",
        "          #backward pass (compute gradients)\n",
        "          loss.backward()\n",
        " \n",
        "          #use the computed gradients to update model weights\n",
        "          optimizer.step()\n",
        " \n",
        "          print('Train loss: '+str(loss.to('cpu').detach()))\n",
        "      # model.eval()\n",
        "      #add back if doing fractional training\n",
        "      # val_loader.dataset.dataset.transform=False\n",
        "      current_loss=0\n",
        "      \n",
        "      #test on val set and save the best checkpoint\n",
        "      model.eval()\n",
        "      for images, masks in val_loader:\n",
        "          images = images.to(device=device, dtype=torch.float32)\n",
        "          masks = masks.to(device=device, dtype=torch.float32)\n",
        "          preds=model(images)['out'].cuda()\n",
        "          # print(preds)\n",
        "          # print(masks)\n",
        "          loss=criterion(preds, masks)\n",
        "          #print('hi')\n",
        "          current_loss+=loss.to('cpu').detach()\n",
        "          del images, masks, preds, loss\n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!Re-name model here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!        \n",
        "      if best_loss>current_loss:\n",
        "          best_loss=current_loss\n",
        "          print('Best Model Saved!, loss: '+ str(best_loss))\n",
        "          torch.save(model.state_dict(), dir_checkpoint+model_group + 'small_image dice e000000001 200 epoch'+str(i+1)+\".pth\")\n",
        "      else:\n",
        "          print('Model is bad!, Current loss: '+ str(current_loss) + ' Best loss: '+str(best_loss))\n",
        "      print('\\n')\n",
        " \n",
        " \n",
        "        \n",
        " \n",
        " \n",
        " \n",
        "# %%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RggGbWi1up33"
      },
      "source": [
        "#Code Box #6. Use this to generate binary masks of annotations, annotations overlayed on the original image, and a summary table with the area of each annotation type in each image, for all the images. \n",
        "#Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\"\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import argparse\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "\n",
        "from glob import glob\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from scipy.ndimage import morphology\n",
        "sys.path.append(os.path.join(sys.path[0]))  # To find local version of the library\n",
        "\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "import torch\n",
        "from skimage.color import rgb2grey, label2rgb\n",
        "\n",
        "from skimage import io,exposure, feature, filters, io, measure, morphology, restoration, segmentation, transform, util\n",
        "from skimage.measure import label, regionprops\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!Put the name of the folder with the images you want to analyze here!!!!!!!!!!!!!!!!!!!!!!!\n",
        "dir_name=val_images\n",
        "# dir_name = 'drive/MyDrive/Mina_Colab_Notebook/411_R3_Sep'\n",
        "filenames = os.listdir(dir_name)\n",
        "\n",
        "\n",
        "whole_leaf_tables=[]\n",
        "file_name=[]\n",
        "color=[]\n",
        "value_counts=[]\n",
        "for i in sort_idx:\n",
        "    #makes new directory called \"(directory name here) + name in red\"\n",
        "    new_dir_name = output_directory\n",
        "    if not os.path.exists(new_dir_name):\n",
        "      os.makedirs(new_dir_name)\n",
        "    for mat in materials:\n",
        "      new_mat_dir_name = new_dir_name + mat.name\n",
        "      if not os.path.exists(new_mat_dir_name):\n",
        "        os.makedirs(new_mat_dir_name)\n",
        "\n",
        "    filename = filenames[i]\n",
        "    \n",
        "    image=Image.open(dir_name +'/'+ filenames[i])\n",
        "    image1=(image)\n",
        "    image1=np.array(image1)\n",
        "    \n",
        "    w, h = image.size\n",
        "    print(image.size)\n",
        "    #!!!!!!!!!!!!!!!!!!!!Make sure scale matches!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    scale=1\n",
        "    newW, newH = int(scale * w), int(scale * h)\n",
        "    image=image.resize((newW, newH))\n",
        "    image=np.array(image)\n",
        "    new_im=np.zeros((3, newH, newW))\n",
        "    new_im[0,:,:]=image\n",
        "    new_im[1,:,:]=image\n",
        "    new_im[2,:,:]=image\n",
        "    image=new_im\n",
        "    \n",
        "\n",
        "    image=torch.from_numpy(image)\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!Make sure normalization goes match above!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    # image=T.Normalize(mean=[0.5432, 0.5432, 0.5432], std=[0.0671, 0.0671, 0.0671])(image)\n",
        "    image=T.Normalize(mean=image_mean, std=image_std)(image)\n",
        " \n",
        " \n",
        "    image.unsqueeze_(0)\n",
        "    image = image.to(device=device, dtype=torch.float32)\n",
        " \n",
        "#new addition that fixes some VRAM consumption issues.\n",
        "    tic=time.time()\n",
        "    with torch.no_grad():\n",
        "      mask=model(image)['out']\n",
        "      mask=mask.cpu().detach().numpy()\n",
        "    toc=time.time()\n",
        "    print('time: '+str(toc-tic))\n",
        "#!!!!!!!!!!!!!!!!!Make sure there are the same number of mask outputs as you trained on!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    combined_image = 0\n",
        "    for i, mat in enumerate(materials):\n",
        "      material_mask = mask[0, i, :, :]\n",
        "      material_mask[material_mask > mat.confidence_threshold] = mat.output_val\n",
        "      material_mask[material_mask < mat.confidence_threshold] = 0\n",
        "      combined_image += material_mask\n",
        "      io.imsave(new_dir_name + mat.name + \"/\" + filename.split('.tif')[0]+ '_' + mat.name + '.png', material_mask)\n",
        "    \n",
        "    img3=label2rgb(combined_image*.5, image1, alpha=0.3)  \n",
        "    io.imsave(new_dir_name+filename.split('.tif')[0]+'_masked.png', img3)  \n",
        "   \n",
        "    \n",
        "# #!!!!!!!!!!!!!!!!!Check image input and output formats here; you can also select which layers you want to output here!!!!!!!!!!!!!!!!!!!!!\n",
        "#     io.imsave(new_dir_name+'/all_tissues/'+filename.split('.tif')[0]+'.png', epidermis_mask+air_space_mask+mesophyll_mask+bundle_sheath_extension_mask+vein_mask)\n",
        "#     #io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'.png', bundle_sheath_extension_mask+vein_mask)\n",
        "#     #io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'.png', image1+air_space_mask)\n",
        "\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_epidermis_mask.png', image1+epidermis_mask)\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_mesophyll_mask.png', image1+mesophyll_mask)\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_air_space_mask.png', image1+air_space_mask)\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_bundle_sheath_extension_mask.png', image1+bundle_sheath_extension_mask)\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_vein_mask.png', image1+vein_mask)\n",
        "\n",
        "#     io.imsave(new_dir_name+'/epidermis/'+filename.split('.tif')[0]+'_epidermis_mask.png', epidermis_mask)\n",
        "#     io.imsave(new_dir_name+'/mesophyll/'+filename.split('.tif')[0]+'_mesophyll_mask.png', mesophyll_mask)\n",
        "#     io.imsave(new_dir_name+'/air_space/'+filename.split('.tif')[0]+'_air_space_mask.png', air_space_mask)\n",
        "#     io.imsave(new_dir_name+'/bundle_sheath_extension/'+filename.split('.png')[0]+'_bundle_sheath_extension_mask.png', bundle_sheath_extension_mask)\n",
        "#     io.imsave(new_dir_name+'/vein/'+filename.split('.tif')[0]+'_vein_mask.png', vein_mask)\n",
        "    \n",
        "  \n",
        "    # print(epidermis_mask)\n",
        "    # print(mesophyll_mask)\n",
        "    # print(air_space_mask)\n",
        "    # print(bundle_sheath_extension_mask)\n",
        "    # print(vein_mask)\n",
        "    epidermis=np.array(epidermis_mask)\n",
        "    mesophyll=np.array(mesophyll_mask)\n",
        "    air_space=np.array(air_space_mask)\n",
        "    bundle_sheath=np.array(bundle_sheath_extension_mask)\n",
        "    vein=np.array(vein_mask)\n",
        "\n",
        "    label_image_epidermis=label(epidermis, background=0)\n",
        "    label_image_mesophyll=label(mesophyll, background=0)\n",
        "    label_image_air_space=label(air_space, background=0)\n",
        "    label_image_bundle_sheath=label(bundle_sheath, background=0)\n",
        "    label_image_vein=label(vein, background=0)\n",
        "    if np.sum(label_image_vein)<1:\n",
        "      label_image_vein=np.ones_like(label_image_vein)\n",
        "    elif np.sum(label_image_vein)>1:\n",
        "        label_image_vein=label_image_vein\n",
        "\n",
        "    es_table=measure.regionprops_table(label_image_epidermis, image1, properties=['label','area','perimeter'])\n",
        "    ml_table=measure.regionprops_table(label_image_mesophyll, image1, properties=['label','area','perimeter'])\n",
        "    as_table=measure.regionprops_table(label_image_air_space, image1, properties=['label','area','perimeter'])\n",
        "    bse_table=measure.regionprops_table(label_image_bundle_sheath, image1, properties=['label','area','perimeter'])\n",
        "    v_table=measure.regionprops_table(label_image_vein, image1, properties=['label','area','perimeter'])\n",
        "    \n",
        "    es_table=pd.DataFrame(es_table)\n",
        "    es_table_a=es_table['area'].sum()\n",
        "    es_table_p=es_table['perimeter'].sum()\n",
        "    ml_table=pd.DataFrame(ml_table)\n",
        "    ml_table_a=ml_table['area'].sum()\n",
        "    ml_table_p=ml_table['perimeter'].sum()\n",
        "    as_table=pd.DataFrame(as_table)\n",
        "    as_table_a=as_table['area'].sum()\n",
        "    as_table_p=as_table['perimeter'].sum()\n",
        "    bse_table=pd.DataFrame(bse_table)\n",
        "    bse_table_a=bse_table['area'].sum()\n",
        "    bse_table_p=bse_table['perimeter'].sum()\n",
        "    v_table=pd.DataFrame(v_table)\n",
        "    if v_table['area'].sum()==np.ones_like(label_image_vein).sum():\n",
        "      v_table_a=v_table['area'].sum()==0\n",
        "      \n",
        "    elif v_table['area'].sum()<np.ones_like(label_image_vein).sum():\n",
        "      v_table_a=v_table['area'].sum()\n",
        "\n",
        "    if v_table['area'].sum()==np.ones_like(label_image_vein).sum():\n",
        "      v_table_p=v_table['perimeter'].sum()==0\n",
        "     \n",
        "    elif v_table['area'].sum()<np.ones_like(label_image_vein).sum():\n",
        "      v_table_p=v_table['perimeter'].sum()\n",
        "    \n",
        "    \n",
        "    x=filename\n",
        "    whole_leaf_=np.array([es_table_a, es_table_p, ml_table_a, ml_table_p, as_table_a, as_table_p, bse_table_a, bse_table_p, v_table_a, v_table_p], dtype=int)\n",
        "    whole_leaf=value_counts.append(whole_leaf_)\n",
        "    image_name_num=[x]\n",
        "    name=file_name.append(image_name_num)\n",
        "    print(whole_leaf_)\n",
        "  # #!!!!!!!!!!!!!!!!!Make sure these gray scale values match those of the output masks !!!!!!!!!!!!!!!!!!!!!  \n",
        "    epidermis30=np.count_nonzero(epidermis)\n",
        "    epidermis0=np.count_nonzero(epidermis == 0)\n",
        "    mesophyll60=np.count_nonzero(mesophyll)\n",
        "    mesophyll0=np.count_nonzero(mesophyll == 0)\n",
        "    air_space90=np.count_nonzero(air_space)\n",
        "    air_space0=np.count_nonzero(air_space == 0)\n",
        "    bundle_sheath120=np.count_nonzero(bundle_sheath)\n",
        "    bundle_sheath0=np.count_nonzero(bundle_sheath == 0)\n",
        "    vein150=np.count_nonzero(vein)\n",
        "    vein0=np.count_nonzero(vein == 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    print(epidermis30)\n",
        "    print(epidermis0)\n",
        "    print(mesophyll60)\n",
        "    print(mesophyll0)\n",
        "    print(air_space90)\n",
        "    print(air_space0)\n",
        "    print(bundle_sheath120)\n",
        "    print(bundle_sheath0)\n",
        "    print(vein150)\n",
        "    print(vein0)\n",
        "  #   x=filename\n",
        "    \n",
        "  #   c=epidermis[0,0]\n",
        "  #   c0=epidermis[1,0]\n",
        "  #   c00=np.int(epidermis30)\n",
        "  #   d=mesophyll[0,0]\n",
        "  #   d0=mesophyll[1,0]\n",
        "  #   d00=np.int(mesophyll60)\n",
        "  #   e=air_space[0,0]\n",
        "  #   e0=air_space[1,0]\n",
        "  #   e00=np.int(air_space90)\n",
        "  #   f=bundle_sheath[0,0]\n",
        "  #   f0=bundle_sheath[1,0]\n",
        "  #   f00=np.int(bundle_sheath120)\n",
        "  #   g=vein[0,0]\n",
        "  #   g0=vein[1,0]\n",
        "  #   g00=np.int(vein150)\n",
        " \n",
        "  #   h00=(np.int(epidermis0) + np.int(epidermis30))\n",
        "  #   i00=h00-g00-f00-e00-d00-c00\n",
        "\n",
        "  #   pixel_value_counts=[c00, d00, e00, f00, g00, i00, h00]\n",
        "  #   leaf=value_counts.append(whole_leaf)\n",
        "  #   image_name_num=[x]\n",
        "  #   name=file_name.append(image_name_num)\n",
        "  #   color=[c00, d00, e00, f00, g00,i00, h00]\n",
        "  #   colors=color.append(color)\n",
        "    \n",
        "    \n",
        "  #   print('----end-----')\n",
        "\n",
        "counts=(np.array(value_counts))\n",
        "names=(np.array(file_name))\n",
        "\n",
        "whole_leaf=np.concatenate((names, counts), axis=1)\n",
        "\n",
        "\n",
        "# whole_leaf_table=pd.concat((names, whole_leaf_tables), axis=1)\n",
        "whole_leaf_table=(pd.DataFrame(whole_leaf))\n",
        "whole_leaf_table.columns = ['file_name','epidermis area (pix)','epidermis perimeter (pix)', 'mesophyll area (pix)','mesophyll perimeter (pix)','air space area (pix)','air space perimeter (pix)','bundle sheath extension area (pix)','bundle sheath extension perimeter (pix)','vein area (pix)','vein perimeter (pix)']\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_row',None)\n",
        "\n",
        "\n",
        "# print(d)\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!Can change table output name here!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "whole_leaf_table.to_csv(new_dir_name+'/'+'leaf tissue.csv')\n",
        "#print (counts)\n",
        "print('----end-----')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liO4hUTfcdPs"
      },
      "source": [
        "#Code Box 5\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "from torchvision.models.segmentation.fcn import FCNHead\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "\n",
        "\n",
        "\n",
        "import time\n",
        "# model=torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True, progress=True)\n",
        "#model=UNet16(6)\n",
        "\n",
        "model=torchvision.models.segmentation.fcn_resnet101(pretrained=False)\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!Specify Layer # here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "#model.classifier=FCNHead(2048, 6)\n",
        "#model.classifier=DeepLabHead(2048, 6)\n",
        "#model=torchvision.models.segmentation.fcn_resnet101(pretrained=False)\n",
        "#!!!!!!!!!!!!!!!!!Specify Layer # here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "model.classifier=FCNHead(2048, 6)\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "outputs=[]\n",
        "model.to(device)\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!Select Correct Model from the best models directory!!!!!!!!!!!!!!!!!!!!!!!!!1\n",
        "# model.load_state_dict(torch.load('drive/My Drive/Mina_Colab_Notebook/best_models/500epoch3train3test486_R2_Sep.pth'), strict=False)\n",
        "model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/411sept4x1.pth'), strict=False)\n",
        "# model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/p1deeplabmodel_52021.pth'), strict=False)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# model.train()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxnWvuDhJRZU"
      },
      "source": [
        "#Testing individual FCN Model\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision.models.segmentation.fcn import FCNHead\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "#from statistics import mean\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# model=torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True, progress=True)\n",
        "#model=UNet16(6)\n",
        "\n",
        "model=torchvision.models.segmentation.fcn_resnet101(pretrained=False)\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!Specify Layer # here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "model.classifier=FCNHead(2048, num_classes)\n",
        "# model.classifier=DeepLabHead(2048, 6)\n",
        "device = torch.device('cuda')\n",
        "\n",
        "outputs=[]\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!Select Correct Model from the best models directory!!!!!!!!!!!!!!!!!!!!!!!!!1\n",
        "#model.load_state_dict(torch.load('drive/My Drive/Mina_Colab_Notebook/best_models/500epoch3train3test486_R2_Sep.pth'), strict=False)\n",
        "model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/small_image_dice e000001 100 epoch/small_image_dice e000001 100 epoch10.pth'), strict=False)\n",
        "#model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/p001deeplabmodel_52021.pth'), strict=False)\n",
        "#model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/p1deeplabmodel_52021.pth'), strict=False)\n",
        "#model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/12x12trainpoint01_42921.pth'), strict=False)\n",
        "#model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/12x12train_10_42921.pth'), strict=False)\n",
        "#model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/12x12train_point1_42921.pth'), strict=False)\n",
        "#model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/B1_12x12train_diceloss_5521.pth'), strict=False)\n",
        "#model.load_state_dict(torch.load('drive/My Drive/FCN WORKFLOW PAPER/best_models/unet1.pth'), strict=False)\n",
        "model.train()\n",
        "\n",
        "dataset_val = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/val_image/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/val_mask/\", 1, transform=False)\n",
        "val_loader = DataLoader(dataset_val, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)#, collate_fn=pad_collate)\n",
        "background_precision_list=[]\n",
        "background_recall_list=[]\n",
        "background_accuracy_list=[]\n",
        "background_f1_list=[]\n",
        "\n",
        "epidermis_precision_list=[]\n",
        "epidermis_recall_list=[]\n",
        "epidermis_accuracy_list=[]\n",
        "epidermis_f1_list=[]\n",
        "\n",
        "mesophyll_precision_list=[]\n",
        "mesophyll_recall_list=[]\n",
        "mesophyll_accuracy_list=[]\n",
        "mesophyll_f1_list=[]\n",
        "\n",
        "air_space_precision_list=[]\n",
        "air_space_recall_list=[]\n",
        "air_space_accuracy_list=[]\n",
        "air_space_f1_list=[]\n",
        "\n",
        "bundle_sheath_extension_precision_list=[]\n",
        "bundle_sheath_extension_recall_list=[]\n",
        "bundle_sheath_extension_accuracy_list=[]\n",
        "bundle_sheath_extension_f1_list=[]\n",
        "\n",
        "vein_precision_list=[]\n",
        "vein_recall_list=[]\n",
        "vein_accuracy_list=[]\n",
        "vein_f1_list=[]\n",
        "\n",
        "\n",
        "\n",
        "for images, target in val_loader:\n",
        "        images = images.to(device=device, dtype=torch.float32)\n",
        "        target = target.to(device=device, dtype=torch.float32)\n",
        "        background_target=target[:,0,:,:]\n",
        "        epidermis_target=target[:,1,:,:]\n",
        "        mesophyll_target=target[:,2,:,:]\n",
        "        air_space_target=target[:,3,:,:]\n",
        "        bundle_sheath_extension_target=target[:,4,:,:]\n",
        "        vein_target=target[:,5,:,:]\n",
        "        pred=model(images)['out'].cuda()# FCN&Deeplab\n",
        "        #pred=model(images).cuda()\n",
        "        pred=nn.Sigmoid()(pred)\n",
        "        background_pred=pred[:,0,:,:]\n",
        "        epidermis_pred=pred[:,1,:,:]\n",
        "        mesophyll_pred=pred[:,2,:,:]\n",
        "        air_space_pred=pred[:,3,:,:]\n",
        "        bundle_sheath_extension_pred=pred[:,4,:,:]\n",
        "        vein_pred=pred[:,5,:,:]\n",
        "        \n",
        "        background_tp=torch.sum(background_target*background_pred, (1,2))\n",
        "        background_fp=torch.sum((1-background_target)*background_pred, (1,2))\n",
        "        background_fn=torch.sum(background_target*(1-background_pred), (1,2))\n",
        "        background_tn=torch.sum((1-background_target)*(1-background_pred), (1,2))\n",
        "\n",
        "        epidermis_tp=torch.sum(epidermis_target*epidermis_pred, (1,2))\n",
        "        epidermis_fp=torch.sum((1-epidermis_target)*epidermis_pred, (1,2))\n",
        "        epidermis_fn=torch.sum(epidermis_target*(1-epidermis_pred), (1,2))\n",
        "        epidermis_tn=torch.sum((1-epidermis_target)*(1-epidermis_pred), (1,2))\n",
        "\n",
        "        mesophyll_tp=torch.sum(mesophyll_target*mesophyll_pred, (1,2))\n",
        "        mesophyll_fp=torch.sum((1-mesophyll_target)*mesophyll_pred, (1,2))\n",
        "        mesophyll_fn=torch.sum(mesophyll_target*(1-mesophyll_pred), (1,2))\n",
        "        mesophyll_tn=torch.sum((1-mesophyll_target)*(1-mesophyll_pred), (1,2))\n",
        "\n",
        "        air_space_tp=torch.sum(air_space_target*air_space_pred, (1,2))\n",
        "        air_space_fp=torch.sum((1-air_space_target)*air_space_pred, (1,2))\n",
        "        air_space_fn=torch.sum(air_space_target*(1-air_space_pred), (1,2))\n",
        "        air_space_tn=torch.sum((1-air_space_target)*(1-air_space_pred), (1,2))\n",
        "\n",
        "        bundle_sheath_extension_tp=torch.sum(bundle_sheath_extension_target*bundle_sheath_extension_pred, (1,2))\n",
        "        bundle_sheath_extension_fp=torch.sum((1-bundle_sheath_extension_target)*bundle_sheath_extension_pred, (1,2))\n",
        "        bundle_sheath_extension_fn=torch.sum(bundle_sheath_extension_target*(1-bundle_sheath_extension_pred), (1,2))\n",
        "        bundle_sheath_extension_tn=torch.sum((1-bundle_sheath_extension_target)*(1-bundle_sheath_extension_pred), (1,2))\n",
        "\n",
        "        vein_tp=torch.sum(vein_target*vein_pred, (1,2))\n",
        "        vein_fp=torch.sum((1-vein_target)*vein_pred, (1,2))\n",
        "        vein_fn=torch.sum(vein_target*(1-vein_pred), (1,2))\n",
        "        vein_tn=torch.sum((1-vein_target)*(1-vein_pred), (1,2))\n",
        "\n",
        "        background_precision=torch.mean(background_tp/(background_tp+background_fp))\n",
        "        background_recall=torch.mean(background_tp/(background_tp+background_fn))\n",
        "        background_accuracy=torch.mean((background_tp+background_tn)/(background_tp+background_tn+background_fp+background_fn))\n",
        "        background_f1=torch.mean((background_tp)/(background_tp+0.5*(background_fp+background_fn)))\n",
        "\n",
        "        epidermis_precision=torch.mean(epidermis_tp/(epidermis_tp+epidermis_fp))\n",
        "        epidermis_recall=torch.mean(epidermis_tp/(epidermis_tp+epidermis_fn))\n",
        "        epidermis_accuracy=torch.mean((epidermis_tp+epidermis_tn)/(epidermis_tp+epidermis_tn+epidermis_fp+epidermis_fn))\n",
        "        epidermis_f1=torch.mean((epidermis_tp)/(epidermis_tp+0.5*(epidermis_fp+epidermis_fn)))\n",
        "\n",
        "        mesophyll_precision=torch.mean(mesophyll_tp/(mesophyll_tp+mesophyll_fp))\n",
        "        mesophyll_recall=torch.mean(mesophyll_tp/(mesophyll_tp+mesophyll_fn))\n",
        "        mesophyll_accuracy=torch.mean((mesophyll_tp+mesophyll_tn)/(mesophyll_tp+mesophyll_tn+mesophyll_fp+mesophyll_fn))\n",
        "        mesophyll_f1=torch.mean((mesophyll_tp)/(mesophyll_tp+0.5*(mesophyll_fp+mesophyll_fn)))\n",
        "\n",
        "        air_space_precision=torch.mean(air_space_tp/(air_space_tp+air_space_fp))\n",
        "        air_space_recall=torch.mean(air_space_tp/(air_space_tp+air_space_fn))\n",
        "        air_space_accuracy=torch.mean((air_space_tp+air_space_tn)/(air_space_tp+air_space_tn+air_space_fp+air_space_fn))\n",
        "        air_space_f1=torch.mean((air_space_tp)/(air_space_tp+0.5*(air_space_fp+air_space_fn)))\n",
        "\n",
        "        bundle_sheath_extension_precision=torch.mean(bundle_sheath_extension_tp/(bundle_sheath_extension_tp+bundle_sheath_extension_fp))\n",
        "        bundle_sheath_extension_recall=torch.mean(bundle_sheath_extension_tp/(bundle_sheath_extension_tp+bundle_sheath_extension_fn))\n",
        "        bundle_sheath_extension_accuracy=torch.mean((bundle_sheath_extension_tp+bundle_sheath_extension_tn)/(bundle_sheath_extension_tp+bundle_sheath_extension_tn+bundle_sheath_extension_fp+bundle_sheath_extension_fn))\n",
        "        bundle_sheath_extension_f1=torch.mean((bundle_sheath_extension_tp)/(bundle_sheath_extension_tp+0.5*(bundle_sheath_extension_fp+bundle_sheath_extension_fn)))\n",
        "\n",
        "        vein_precision=torch.mean(vein_tp/(vein_tp+vein_fp))\n",
        "        vein_recall=torch.mean(vein_tp/(vein_tp+vein_fn))\n",
        "        vein_accuracy=torch.mean((vein_tp+vein_tn)/(vein_tp+vein_tn+vein_fp+vein_fn))\n",
        "        vein_f1=torch.mean((vein_tp)/(vein_tp+0.5*(vein_fp+vein_fn)))\n",
        "\n",
        "\n",
        "        background_precision_list.append(background_precision.cpu().detach().numpy())\n",
        "        background_recall_list.append(background_recall.cpu().detach().numpy())\n",
        "        background_accuracy_list.append(background_accuracy.cpu().detach().numpy())\n",
        "        background_f1_list.append(background_f1.cpu().detach().numpy())\n",
        "\n",
        "        epidermis_precision_list.append(epidermis_precision.cpu().detach().numpy())\n",
        "        epidermis_recall_list.append(epidermis_recall.cpu().detach().numpy())\n",
        "        epidermis_accuracy_list.append(epidermis_accuracy.cpu().detach().numpy())\n",
        "        epidermis_f1_list.append(epidermis_f1.cpu().detach().numpy())\n",
        "\n",
        "        mesophyll_precision_list.append(mesophyll_precision.cpu().detach().numpy())\n",
        "        mesophyll_recall_list.append(mesophyll_recall.cpu().detach().numpy())\n",
        "        mesophyll_accuracy_list.append(mesophyll_accuracy.cpu().detach().numpy())\n",
        "        mesophyll_f1_list.append(mesophyll_f1.cpu().detach().numpy())\n",
        "\n",
        "        air_space_precision_list.append(air_space_precision.cpu().detach().numpy())\n",
        "        air_space_recall_list.append(air_space_recall.cpu().detach().numpy())\n",
        "        air_space_accuracy_list.append(air_space_accuracy.cpu().detach().numpy())\n",
        "        air_space_f1_list.append(air_space_f1.cpu().detach().numpy())\n",
        "\n",
        "        bundle_sheath_extension_precision_list.append(bundle_sheath_extension_precision.cpu().detach().numpy())\n",
        "        bundle_sheath_extension_recall_list.append(bundle_sheath_extension_recall.cpu().detach().numpy())\n",
        "        bundle_sheath_extension_accuracy_list.append(bundle_sheath_extension_accuracy.cpu().detach().numpy())\n",
        "        bundle_sheath_extension_f1_list.append(bundle_sheath_extension_f1.cpu().detach().numpy())\n",
        "\n",
        "        vein_precision_list.append(vein_precision.cpu().detach().numpy())\n",
        "        vein_recall_list.append(vein_recall.cpu().detach().numpy())\n",
        "        vein_accuracy_list.append(vein_accuracy.cpu().detach().numpy())\n",
        "        vein_f1_list.append(vein_f1.cpu().detach().numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "background_precision_final=np.mean(background_precision_list)\n",
        "background_recall_final=np.mean(background_recall_list)\n",
        "background_accuracy_final=np.mean(background_accuracy_list)\n",
        "background_f1_final=np.mean(background_f1_list)\n",
        "\n",
        "epidermis_precision_final=np.mean(epidermis_precision_list)\n",
        "epidermis_recall_final=np.mean(epidermis_recall_list)\n",
        "epidermis_accuracy_final=np.mean(epidermis_accuracy_list)\n",
        "epidermis_f1_final=np.mean(epidermis_f1_list)\n",
        "\n",
        "mesophyll_precision_final=np.mean(mesophyll_precision_list)\n",
        "mesophyll_recall_final=np.mean(mesophyll_recall_list)\n",
        "mesophyll_accuracy_final=np.mean(mesophyll_accuracy_list)\n",
        "mesophyll_f1_final=np.mean(mesophyll_f1_list)\n",
        "\n",
        "air_space_precision_final=np.mean(air_space_precision_list)\n",
        "air_space_recall_final=np.mean(air_space_recall_list)\n",
        "air_space_accuracy_final=np.mean(air_space_accuracy_list)\n",
        "air_space_f1_final=np.mean(air_space_f1_list)\n",
        "\n",
        "bundle_sheath_extension_precision_final=np.mean(bundle_sheath_extension_precision_list)\n",
        "bundle_sheath_extension_recall_final=np.mean(bundle_sheath_extension_recall_list)\n",
        "bundle_sheath_extension_accuracy_final=np.mean(bundle_sheath_extension_accuracy_list)\n",
        "bundle_sheath_extension_f1_final=np.mean(bundle_sheath_extension_f1_list)\n",
        "\n",
        "# vein_precision_final=(np.mean(vein_precision_list),np.std(vein_precision_list))\n",
        "vein_precision_final=np.mean(vein_precision_list)\n",
        "vein_recall_final=np.mean(vein_recall_list)\n",
        "vein_accuracy_final=np.mean(vein_accuracy_list)\n",
        "vein_f1_final=np.mean(vein_f1_list)\n",
        "\n",
        "\n",
        "print(\"background_precision: \", str(background_precision_final))      \n",
        "print(\"background_recall: \", str(background_recall_final)) \n",
        "print(\"background_accuracy: \", str(background_accuracy_final)) \n",
        "print(\"background_f1: \", str(background_f1_final)) \n",
        "\n",
        "print(\"epidermis_precision: \", str(epidermis_precision_final))      \n",
        "print(\"epidermis_recall: \", str(epidermis_recall_final)) \n",
        "print(\"epidermis_accuracy: \", str(epidermis_accuracy_final)) \n",
        "print(\"epidermis_f1: \", str(epidermis_f1_final)) \n",
        "\n",
        "print(\"mesophyll_precision: \", str(mesophyll_precision_final))      \n",
        "print(\"mesophyll_recall: \", str(mesophyll_recall_final)) \n",
        "print(\"mesophyll_accuracy: \", str(mesophyll_accuracy_final)) \n",
        "print(\"mesophyll_f1: \", str(mesophyll_f1_final)) \n",
        "\n",
        "print(\"air_space_precision: \", str(air_space_precision_final))      \n",
        "print(\"air_space_recall: \", str(air_space_recall_final)) \n",
        "print(\"air_space_accuracy: \", str(air_space_accuracy_final)) \n",
        "print(\"air_space_f1: \", str(air_space_f1_final))\n",
        "\n",
        "print(\"bundle_sheath_extension_precision: \", str(bundle_sheath_extension_precision_final))      \n",
        "print(\"bundle_sheath_extension_recall: \", str(bundle_sheath_extension_recall_final)) \n",
        "print(\"bundle_sheath_extension_accuracy: \", str(bundle_sheath_extension_accuracy_final)) \n",
        "print(\"bundle_sheath_extension_f1: \", str(bundle_sheath_extension_f1_final))\n",
        "\n",
        "print(\"vein_precision (mean, std): \", str(vein_precision_final))      \n",
        "print(\"vein_recall: \", str(vein_recall_final)) \n",
        "print(\"vein_accuracy: \", str(vein_accuracy_final)) \n",
        "print(\"vein_f1: \", str(vein_f1_final))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bAuU5161ST8"
      },
      "source": [
        "#Code Box #6. Use this to generate binary masks of annotations, annotations overlayed on the original image, and a summary table with the area of each annotation type in each image, for all the images. \n",
        "#Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\"\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import argparse\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "\n",
        "from glob import glob\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from scipy.ndimage import morphology\n",
        "sys.path.append(os.path.join(sys.path[0]))  # To find local version of the library\n",
        "\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "import torch\n",
        "from skimage.color import rgb2grey, label2rgb\n",
        "\n",
        "from skimage import io,exposure, feature, filters, io, measure, morphology, restoration, segmentation, transform, util\n",
        "from skimage.measure import label, regionprops\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!Put the name of the folder with the images you want to analyze here!!!!!!!!!!!!!!!!!!!!!!!\n",
        "dir_name = 'drive/My Drive/FCN WORKFLOW PAPER/trainran/small_image'\n",
        "\n",
        "filenames = os.listdir(dir_name)\n",
        "\n",
        "\n",
        "whole_leaf_tables=[]\n",
        "file_name=[]\n",
        "color=[]\n",
        "value_counts=[]\n",
        "#sort_idx = np.argsort([(int(filename.split('_')[1].split('.png')[0])) for filename in filenames])\n",
        "sort_idx = np.argsort([(int(filename.split('e_')[1].split('.png')[0])) for filename in filenames])\n",
        "for i in sort_idx:\n",
        "    #makes new directory called \"(directory name here) + name in red\" that your new images go into\n",
        "    new_dir_name=dir_name+'test'\n",
        "    if not os.path.exists(new_dir_name):\n",
        "      os.makedirs(new_dir_name)\n",
        "    new_dir_name_epidermis=dir_name+'test/epidermis'\n",
        "    if not os.path.exists(new_dir_name_epidermis):\n",
        "      os.makedirs(new_dir_name_epidermis)\n",
        "    new_dir_name_mesophyll=dir_name+'test/mesophyll'\n",
        "    if not os.path.exists(new_dir_name_mesophyll):\n",
        "      os.makedirs(new_dir_name_mesophyll)\n",
        "    new_dir_name_air_space=dir_name+'test/air_space'\n",
        "    if not os.path.exists(new_dir_name_air_space):\n",
        "      os.makedirs(new_dir_name_air_space)\n",
        "    new_dir_name_bundle_sheath_extension=dir_name+'test/bundle_sheath_extension'\n",
        "    if not os.path.exists(new_dir_name_bundle_sheath_extension):\n",
        "      os.makedirs(new_dir_name_bundle_sheath_extension)\n",
        "    new_dir_name_vein=dir_name+'test/vein'\n",
        "    if not os.path.exists(new_dir_name_vein):\n",
        "      os.makedirs(new_dir_name_vein)\n",
        "    filename = filenames[i]\n",
        "    \n",
        "    image=Image.open(dir_name +'/'+ filenames[i])\n",
        "    image1=(image)\n",
        "    image1=np.array(image1)\n",
        "    \n",
        "    w, h = image.size\n",
        "    print(image.size)\n",
        "    #!!!!!!!!!!!!!!!!!!!!Make sure scale matches!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    scale=1\n",
        "    newW, newH = int(scale * w), int(scale * h)\n",
        "    image=image.resize((newW, newH))\n",
        "    image=np.array(image)\n",
        "    new_im=np.zeros((3, newH, newW))\n",
        "    new_im[0,:,:]=image\n",
        "    new_im[1,:,:]=image\n",
        "    new_im[2,:,:]=image\n",
        "    image=new_im\n",
        "    \n",
        "\n",
        "    image=torch.from_numpy(image)\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!Make sure normalization goes match above!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    image=T.Normalize(mean=[0.4932, 0.4932, 0.4932], std=[0.0550, 0.0550, 0.0550])(image)\n",
        " \n",
        "    image.unsqueeze_(0)\n",
        "    image = image.to(device=device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    tic=time.time()\n",
        "    mask=model(image)['out']\n",
        "    toc=time.time()\n",
        "    print('time: '+str(toc-tic))\n",
        "#!!!!!!!!!!!!!!!!!Make sure there are the same number of mask outputs as you trained on!!!!!!!!!!!!!!!!!!!!!\n",
        "    background_mask=mask.cpu().detach().numpy()[0,0,:,:]\n",
        "    epidermis_mask=mask.cpu().detach().numpy()[0,1,:,:]\n",
        "    mesophyll_mask=mask.cpu().detach().numpy()[0,2,:,:]\n",
        "    air_space_mask=mask.cpu().detach().numpy()[0,3,:,:]\n",
        "    bundle_sheath_extension_mask=mask.cpu().detach().numpy()[0,4,:,:]\n",
        "    vein_mask=mask.cpu().detach().numpy()[0,5,:,:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!Input gray scale values for your output masks here!!!!!!!!!!!!!!!!!!!!!\n",
        "    background_mask[background_mask>=0]=0\n",
        "    background_mask[background_mask<0]=0\n",
        "\n",
        "    epidermis_mask[epidermis_mask>=0]=30\n",
        "    epidermis_mask[epidermis_mask<0]=0\n",
        "    \n",
        "    mesophyll_mask[mesophyll_mask>=0]=60\n",
        "    mesophyll_mask[mesophyll_mask<0]=0\n",
        "\n",
        "    air_space_mask[air_space_mask>=0]=120\n",
        "    air_space_mask[air_space_mask<0]=0\n",
        "\n",
        "    bundle_sheath_extension_mask[bundle_sheath_extension_mask>=0]=90\n",
        "    bundle_sheath_extension_mask[bundle_sheath_extension_mask<0]=0\n",
        "\n",
        "    vein_mask[vein_mask>=0]=150\n",
        "    vein_mask[vein_mask<0]=0\n",
        "    \n",
        "\n",
        "   \n",
        "    \n",
        "#!!!!!!!!!!!!!!!!!Check image input and output formats here; you can also select which layers you want to output here!!!!!!!!!!!!!!!!!!!!!\n",
        "    io.imsave(new_dir_name+'/'+filename.split('.png')[0]+'.png', image1+epidermis_mask+air_space_mask+mesophyll_mask+bundle_sheath_extension_mask+vein_mask)\n",
        "    #io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'.png', bundle_sheath_extension_mask+vein_mask)\n",
        "    #io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'.png', image1+air_space_mask)\n",
        "\n",
        "    # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_epidermis_mask.png', image1+epidermis_mask)\n",
        "    # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_mesophyll_mask.png', image1+mesophyll_mask)\n",
        "    # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_air_space_mask.png', image1+air_space_mask)\n",
        "    # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_bundle_sheath_extension_mask.png', image1+bundle_sheath_extension_mask)\n",
        "    # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_vein_mask.png', image1+vein_mask)\n",
        "\n",
        "    io.imsave(new_dir_name+'/epidermis/'+filename.split('.png')[0]+'_epidermis_mask.png', epidermis_mask)\n",
        "    io.imsave(new_dir_name+'/mesophyll/'+filename.split('.png')[0]+'_mesophyll_mask.png', mesophyll_mask)\n",
        "    io.imsave(new_dir_name+'/air_space/'+filename.split('.png')[0]+'_air_space_mask.png', air_space_mask)\n",
        "    io.imsave(new_dir_name+'/bundle_sheath_extension/'+filename.split('.png')[0]+'_bundle_sheath_extension_mask.png', bundle_sheath_extension_mask)\n",
        "    io.imsave(new_dir_name+'/vein/'+filename.split('.png')[0]+'_vein_mask.png', vein_mask)\n",
        "    \n",
        "  \n",
        "    # print(epidermis_mask)\n",
        "    # print(mesophyll_mask)\n",
        "    # print(air_space_mask)\n",
        "    # print(bundle_sheath_extension_mask)\n",
        "    # print(vein_mask)\n",
        "    epidermis=np.array(epidermis_mask)\n",
        "    mesophyll=np.array(mesophyll_mask)\n",
        "    air_space=np.array(air_space_mask)\n",
        "    bundle_sheath=np.array(bundle_sheath_extension_mask)\n",
        "    vein=np.array(vein_mask)\n",
        "\n",
        "    label_image_epidermis=label(epidermis, background=0)\n",
        "    label_image_mesophyll=label(mesophyll, background=0)\n",
        "    label_image_air_space=label(air_space, background=0)\n",
        "    label_image_bundle_sheath=label(bundle_sheath, background=0)\n",
        "    label_image_vein=label(vein, background=0)\n",
        "\n",
        "    es_table=measure.regionprops_table(label_image_epidermis, image1, properties=['label','area','perimeter'])\n",
        "    ml_table=measure.regionprops_table(label_image_mesophyll, image1, properties=['label','area','perimeter'])\n",
        "    as_table=measure.regionprops_table(label_image_air_space, image1, properties=['label','area','perimeter'])\n",
        "    bse_table=measure.regionprops_table(label_image_bundle_sheath, image1, properties=['label','area','perimeter'])\n",
        "    v_table=measure.regionprops_table(label_image_vein, image1, properties=['label','area','perimeter'])\n",
        "    \n",
        "    es_table=pd.DataFrame(es_table)\n",
        "    es_table_a=es_table['area'].sum()\n",
        "    es_table_p=es_table['perimeter'].sum()\n",
        "    ml_table=pd.DataFrame(ml_table)\n",
        "    ml_table_a=ml_table['area'].sum()\n",
        "    ml_table_p=ml_table['perimeter'].sum()\n",
        "    as_table=pd.DataFrame(as_table)\n",
        "    as_table_a=as_table['area'].sum()\n",
        "    as_table_p=as_table['perimeter'].sum()\n",
        "    bse_table=pd.DataFrame(bse_table)\n",
        "    bse_table_a=bse_table['area'].sum()\n",
        "    bse_table_p=bse_table['perimeter'].sum()\n",
        "    v_table=pd.DataFrame(v_table)\n",
        "    v_table_a=v_table['area'].sum()\n",
        "    v_table_p=v_table['perimeter'].sum()\n",
        "    x=filename\n",
        "    whole_leaf_=np.array([es_table_a, es_table_p, ml_table_a, ml_table_p, as_table_a, as_table_p, bse_table_a, bse_table_p, v_table_a, v_table_p], dtype=int)\n",
        "    whole_leaf=value_counts.append(whole_leaf_)\n",
        "    image_name_num=[x]\n",
        "    name=file_name.append(image_name_num)\n",
        "    print(whole_leaf_)\n",
        "  # # #!!!!!!!!!!!!!!!!!Make sure these gray scale values match those of the output masks !!!!!!!!!!!!!!!!!!!!!  \n",
        "  #   epidermis30=np.count_nonzero(epidermis)\n",
        "  #   epidermis0=np.count_nonzero(epidermis == 0)\n",
        "  #   mesophyll60=np.count_nonzero(mesophyll)\n",
        "  #   mesophyll0=np.count_nonzero(mesophyll == 0)\n",
        "  #   air_space90=np.count_nonzero(air_space)\n",
        "  #   air_space0=np.count_nonzero(air_space == 0)\n",
        "  #   bundle_sheath120=np.count_nonzero(bundle_sheath)\n",
        "  #   bundle_sheath0=np.count_nonzero(bundle_sheath == 0)\n",
        "  #   vein150=np.count_nonzero(vein)\n",
        "  #   vein0=np.count_nonzero(vein == 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  #   print(epidermis30)\n",
        "  #   print(epidermis0)\n",
        "  #   print(mesophyll60)\n",
        "  #   print(mesophyll0)\n",
        "  #   print(air_space90)\n",
        "  #   print(air_space0)\n",
        "  #   print(bundle_sheath120)\n",
        "  #   print(bundle_sheath0)\n",
        "  #   print(vein150)\n",
        "  #   print(vein0)\n",
        "  # #   x=filename\n",
        "    \n",
        "  # #   c=epidermis[0,0]\n",
        "  # #   c0=epidermis[1,0]\n",
        "  # #   c00=np.int(epidermis30)\n",
        "  # #   d=mesophyll[0,0]\n",
        "  # #   d0=mesophyll[1,0]\n",
        "  # #   d00=np.int(mesophyll60)\n",
        "  # #   e=air_space[0,0]\n",
        "  # #   e0=air_space[1,0]\n",
        "  # #   e00=np.int(air_space90)\n",
        "  # #   f=bundle_sheath[0,0]\n",
        "  # #   f0=bundle_sheath[1,0]\n",
        "  # #   f00=np.int(bundle_sheath120)\n",
        "  # #   g=vein[0,0]\n",
        "  # #   g0=vein[1,0]\n",
        "  # #   g00=np.int(vein150)\n",
        " \n",
        "  # #   h00=(np.int(epidermis0) + np.int(epidermis30))\n",
        "  # #   i00=h00-g00-f00-e00-d00-c00\n",
        "\n",
        "  # #   pixel_value_counts=[c00, d00, e00, f00, g00, i00, h00]\n",
        "  # #   leaf=value_counts.append(whole_leaf)\n",
        "  # #   image_name_num=[x]\n",
        "  # #   name=file_name.append(image_name_num)\n",
        "  # #   color=[c00, d00, e00, f00, g00,i00, h00]\n",
        "  # #   colors=color.append(color)\n",
        "    \n",
        "    \n",
        "  # #   print('----end-----')\n",
        "\n",
        "counts=(np.array(value_counts))\n",
        "names=(np.array(file_name))\n",
        "\n",
        "whole_leaf=np.concatenate((names, counts), axis=1)\n",
        "\n",
        "\n",
        "# whole_leaf_table=pd.concat((names, whole_leaf_tables), axis=1)\n",
        "whole_leaf_table=(pd.DataFrame(whole_leaf))\n",
        "whole_leaf_table.columns = ['file_name','epidermis area (pix)','epidermis perimeter (pix)', 'mesophyll area (pix)','mesophyll perimeter (pix)','air space area (pix)','air space perimeter (pix)','bundle sheath extension area (pix)','bundle sheath extension perimeter (pix)','vein area (pix)','vein perimeter (pix)']\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_row',None)\n",
        "\n",
        "\n",
        "# print(d)\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!Can change table output name here!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "whole_leaf_table.to_csv(new_dir_name+'/'+'leaf tissue area and perimeter.csv')\n",
        "#print (counts)\n",
        "print('----end-----')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdazmW6UlstS"
      },
      "source": [
        "#Works Great TIFF STACKER any image type, a bit slow.....also can eat up all your RAM, so be careful of stacking large folders of images (20 gb max)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\"\n",
        "\n",
        "import tifffile as tifffile\n",
        "import os as os\n",
        "import numpy as np\n",
        "from skimage import filters, transform, io\n",
        "with tifffile.TiffWriter('drive/My Drive/FCN WORKFLOW PAPER/486_R2_Sep_BSE12x12_binary/all_tissues_stack.tiff', bigtiff=True) as stack:\n",
        "#with tifffile.TiffWriter('drive/My Drive/PNNL Soil Colab/Val/masks/solid.tiff') as stack:\n",
        "    dir_name = 'drive/My Drive/FCN WORKFLOW PAPER/486_R2_Sep_BSE12x12_binary/all_tissues/'\n",
        "    filenames = os.listdir(dir_name)\n",
        "    sort_idx = np.argsort([int(filename.split('bit')[1].split('.png')[0]) for filename in filenames])\n",
        "    for i in sort_idx:\n",
        "        filename = dir_name + filenames[i]\n",
        "        \n",
        "#         image=np.array(filename, dtype='ubyte')\n",
        "#         image=np.array(filename)\n",
        "        stack.save(io.imread(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21q_sg4gJcPQ"
      },
      "source": [
        "#reslicer\n",
        "#TIFF stack unstacker\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\"\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage as sk\n",
        "\n",
        "from skimage import filters, io, img_as_ubyte\n",
        "from skimage.data import camera\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage as sk\n",
        "\n",
        "from skimage import filters, io\n",
        "from skimage.data import camera\n",
        "from skimage import data, io,img_as_float64, img_as_float32\n",
        "from skimage.exposure import histogram\n",
        "from scipy import ndimage as ndi\n",
        "import skimage as sk\n",
        "import tifffile\n",
        "%matplotlib inline\n",
        "from matplotlib import cm\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import img_as_float64, img_as_int, img_as_uint\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection, Line3DCollection\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "from skimage import (exposure, feature, filters, io, measure,\n",
        "                      morphology, restoration, segmentation, transform,\n",
        "                      util)\n",
        "directn='drive/My Drive/FCN WORKFLOW PAPER/486_R2_Sep_BSE12x12_binary/'\n",
        "new_dir_name=directn+'all_tissues_resliced'\n",
        "os.makedirs(new_dir_name)\n",
        "if not os.path.exists(new_dir_name):\n",
        "      os.makedirs(new_dir_name)\n",
        "#Put name of file you want to split here\n",
        "img=io.imread_collection('drive/My Drive/FCN WORKFLOW PAPER/486_R2_Sep_BSE12x12_binary/all_tissues_stack.tiff', plugin='tifffile')\n",
        "img=np.array(img)\n",
        "#print(img)\n",
        "#io.imshow_collection(img)\n",
        "Z=img.shape\n",
        "print(Z[1])\n",
        "\n",
        "\n",
        "for i in range(Z[1]):\n",
        "         io.imsave(new_dir_name+'/'+'all_tissues_resliced%s.png'%i, (img[:,i,:]))\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF390-YDnLPI"
      },
      "source": [
        "# # ***************************************************IGNORE***********************************Code Box #7. Use this to get a tabular summary of all the data for each tissue type in an image. There is no spatial information, it is total area per slice only.\n",
        "\n",
        "\n",
        "\n",
        "# #Load the Drive helper and mount\n",
        "# from google.colab import drive\n",
        "# # This will prompt for authorization.\n",
        "# drive.mount('/content/drive')\n",
        "# !ls \"/content/drive/My Drive\"\n",
        "\n",
        "# #%% Imports\n",
        "# # Import libraries\n",
        "# import os\n",
        "# import pandas as pd\n",
        "# import sys\n",
        "# import random\n",
        "# import math\n",
        "# import re\n",
        "# import time\n",
        "# import numpy as np\n",
        "# import cv2\n",
        "# import matplotlib\n",
        "# import matplotlib.pyplot as plt\n",
        "# from glob import glob\n",
        "# import argparse\n",
        "# import torch\n",
        "# import torchvision\n",
        "# from PIL import Image\n",
        "# #from imantics import Polygons, Mask, Annotation, Image\n",
        "# #import skimage.transform as tfm\n",
        "# from glob import glob\n",
        "# import torchvision.transforms as T\n",
        "# from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "# from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "# from scipy.ndimage import morphology\n",
        "# sys.path.append(os.path.join(sys.path[0]))  # To find local version of the library\n",
        "\n",
        "# from torchvision.models.detection.rpn import AnchorGenerator\n",
        "# import torch\n",
        "# from skimage.color import rgb2grey, label2rgb\n",
        "\n",
        "# from skimage import io\n",
        "# import os\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# dir_name = 'drive/My Drive/FCN WORKFLOW PAPER/486_R2_Sep'\n",
        "# #new_dir_name=dir_name+'masked'\n",
        "# filenames = os.listdir(dir_name)\n",
        "\n",
        "\n",
        "\n",
        "# file_name=[]\n",
        "# color=[]\n",
        "# value_counts=[]\n",
        "# sort_idx = np.argsort([(int(filename.split('_')[1].split('.')[0])) for filename in filenames])\n",
        "\n",
        "# for i in sort_idx:\n",
        "#     #makes new directory called \"(directory name here) + cropped\"\n",
        "#     new_dir_name=dir_name+' tested'\n",
        "#     if not os.path.exists(new_dir_name):\n",
        "#       os.makedirs(new_dir_name)\n",
        "#     filename = filenames[i]\n",
        "#     #filed=new_dir_name+'_masked'+filenames[i]\n",
        "#     #if not os.path.exists(new_dir_name):\n",
        "#       #os.makedirs(new_dir_name)\n",
        "#     #image is read from directory to system  \n",
        "#     image=Image.open(dir_name +'/'+ filenames[i])\n",
        "#     image1=(image)\n",
        "#     #image=np.array(image)\n",
        "#     #image=Image.open('drive/My Drive/Colab Notebooks_DR/test/images/TubeD_Position7_567.jpeg')\n",
        "# # model.train()\n",
        "#     w, h = image.size\n",
        "#     print(image.size)\n",
        "#     scale=1\n",
        "#     newW, newH = int(scale * w), int(scale * h)\n",
        "#     image=image.resize((newW, newH))\n",
        "#     image=np.array(image)\n",
        "#     new_im=np.zeros((3, newH, newW))\n",
        "#     new_im[0,:,:]=image\n",
        "#     new_im[1,:,:]=image\n",
        "#     new_im[2,:,:]=image\n",
        "#     image=new_im\n",
        "    \n",
        "# # image = image.transpose((2, 0, 1))\n",
        "# #print(image.shape)\n",
        "# #image= np.flip(image, axis=1).copy()\n",
        "# #image= ndi.rotate(image, -5, reshape=False, axes=(0, 1))\n",
        "# #print(type(image))\n",
        "# #plt.imshow(image)\n",
        "\n",
        "# #image = T.ToTensor()(image)\n",
        "# #image = torch.from_numpy(image)\n",
        "#     image=torch.from_numpy(image)\n",
        "\n",
        "# # image=T.Normalize(mean=[0.5378, 0.5378, 0.5378], std=[0.0189, 0.0189, 0.0189])(image)\n",
        "\n",
        "# #Change normalization codes\n",
        "#     #image=T.Normalize(mean=[0.5404, 0.5404, 0.5404], std=[0.0711, 0.0711, 0.0711])(image)\n",
        "#     #image=T.Normalize(mean=[0.5453, 0.5453, 0.5453], std=[0.0573, 0.0573, 0.0573])(image)\n",
        "#     image=T.Normalize(mean=[0.5560, 0.5560, 0.5560], std=[0.0623, 0.0623, 0.0623])(image)\n",
        "    \n",
        " \n",
        "#     image.unsqueeze_(0)\n",
        "#     image = image.to(device=device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# #outputs.append(image)\n",
        "# #image = matplotlib._png.read_png_int(x)\n",
        "#     tic=time.time()\n",
        "#     with torch.no_grad():\n",
        "#       mask=model(image)['out']\n",
        "#       mask=mask.cpu().detach().numpy()\n",
        "#     toc=time.time()\n",
        "#     print('time: '+str(toc-tic))\n",
        "# #!!!!!!!!!!!!!!!!!Make sure there are the same number of mask outputs as you trained on!!!!!!!!!!!!!!!!!!!!!\n",
        "#     background_mask=mask[0,0,:,:]\n",
        "#     epidermis_mask=mask[0,1,:,:]\n",
        "#     mesophyll_mask=mask[0,2,:,:]\n",
        "#     air_space_mask=mask[0,3,:,:]\n",
        "#     bundle_sheath_extension_mask=mask[0,4,:,:]\n",
        "#     vein_mask=mask[0,5,:,:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     background_mask[background_mask>=0]=0\n",
        "#     background_mask[background_mask<0]=0\n",
        "\n",
        "#     epidermis_mask[epidermis_mask>=0]=30\n",
        "#     epidermis_mask[epidermis_mask<0]=0\n",
        "    \n",
        "#     mesophyll_mask[mesophyll_mask>=0]=60\n",
        "#     mesophyll_mask[mesophyll_mask<0]=0\n",
        "\n",
        "#     air_space_mask[air_space_mask>=0]=120\n",
        "#     air_space_mask[air_space_mask<0]=0\n",
        "\n",
        "#     bundle_sheath_extension_mask[bundle_sheath_extension_mask>=0]=90\n",
        "#     bundle_sheath_extension_mask[bundle_sheath_extension_mask<0]=0\n",
        "\n",
        "#     vein_mask[vein_mask>=0]=150\n",
        "#     vein_mask[vein_mask<0]=0\n",
        "    \n",
        "\n",
        "   \n",
        "#     #img0=img = apply_mask(bud_mask, bud_mask, colors[0], alpha=1)\n",
        "#     #img1=img = apply_mask(air_mask, air_mask, colors[1], alpha=1)\n",
        "#     #img2=img = apply_mask(sepal_mask, sepal_mask, colors[2], alpha=1)\n",
        "\n",
        "#     io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'.png', background_mask+epidermis_mask+mesophyll_mask+air_space_mask+bundle_sheath_extension_mask+vein_mask)\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_epidermis_mask.png', epidermis_mask)\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_mesophyll_mask.png', mesophyll_mask)\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_air_space_mask.png', air_space_mask)\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_bundle_sheath_extension_mask.png', bundle_sheath_extension_mask)\n",
        "#     # io.imsave(new_dir_name+'/'+filename.split('.tif')[0]+'_vein_mask.png', vein_mask)\n",
        "    \n",
        "#     #df=np.array(sepal_mask)\n",
        "#     #df=pd.DataFrame(df)\n",
        "#     #np.savetxt(new_dir_name+'/'+filename,df)\n",
        "#     #print(df)\n",
        "    \n",
        "#     #background=(np.unique(epidermis_mask, return_counts=True))\n",
        "#     #epidermis=(np.unique(epidermis_mask, return_counts=True))\n",
        "#     #mesophyll=(np.unique(mesophyll_mask, return_counts=True))\n",
        "#     #air_space=(np.unique(air_space_mask, return_counts=True))\n",
        "#     #bundle_sheath=(np.unique(bundle_sheath_extension_mask, return_counts=True))\n",
        "#     #vein=(np.unique(vein_mask, return_counts=True))\n",
        "#     print(epidermis_mask)\n",
        "#     print(mesophyll_mask)\n",
        "#     print(air_space_mask)\n",
        "#     print(bundle_sheath_extension_mask)\n",
        "#     print(vein_mask)\n",
        "#     epidermis=np.array(epidermis_mask)\n",
        "#     mesophyll=np.array(mesophyll_mask)\n",
        "#     air_space=np.array(air_space_mask)\n",
        "#     bundle_sheath=np.array(bundle_sheath_extension_mask)\n",
        "#     vein=np.array(vein_mask)\n",
        "\n",
        "\n",
        "\n",
        "#     epidermis30=np.count_nonzero(epidermis == 30)\n",
        "#     epidermis0=np.count_nonzero(epidermis == 0)\n",
        "#     mesophyll60=np.count_nonzero(mesophyll == 60)\n",
        "#     mesophyll0=np.count_nonzero(mesophyll == 0)\n",
        "#     air_space90=np.count_nonzero(air_space == 120)\n",
        "#     air_space0=np.count_nonzero(air_space == 0)\n",
        "#     bundle_sheath120=np.count_nonzero(bundle_sheath == 90)\n",
        "#     bundle_sheath0=np.count_nonzero(bundle_sheath == 0)\n",
        "#     vein150=np.count_nonzero(vein == 150)\n",
        "#     vein0=np.count_nonzero(vein == 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     #epidermis=np.count_zero(epidermis)\n",
        "#     print(epidermis30)\n",
        "#     print(epidermis0)\n",
        "#     print(mesophyll60)\n",
        "#     print(mesophyll0)\n",
        "#     print(air_space90)\n",
        "#     print(air_space0)\n",
        "#     print(bundle_sheath120)\n",
        "#     print(bundle_sheath0)\n",
        "#     print(vein150)\n",
        "#     print(vein0)\n",
        "#     x=filename\n",
        "    \n",
        "#     c=epidermis[0,0]\n",
        "#     c0=epidermis[1,0]\n",
        "#     c00=np.int(epidermis30)\n",
        "#     d=mesophyll[0,0]\n",
        "#     d0=mesophyll[1,0]\n",
        "#     d00=np.int(mesophyll60)\n",
        "#     e=air_space[0,0]\n",
        "#     e0=air_space[1,0]\n",
        "#     e00=np.int(air_space90)\n",
        "#     f=bundle_sheath[0,0]\n",
        "#     f0=bundle_sheath[1,0]\n",
        "#     f00=np.int(bundle_sheath120)\n",
        "#     g=vein[0,0]\n",
        "#     g0=vein[1,0]\n",
        "#     g00=np.int(vein150)\n",
        "#     #h=image.size\n",
        "#     #h0=np.int(h)\n",
        "#     # h00=image.size(h0)\n",
        "#     h00=(np.int(epidermis0) + np.int(epidermis30))\n",
        "#     i00=h00-g00-f00-e00-d00-c00\n",
        "\n",
        "#     pixel_value_counts=[c00, d00, e00, f00, g00,i00,h00]\n",
        "#     leaf=value_counts.append(pixel_value_counts)\n",
        "#     image_name_num=[x]\n",
        "#     name=file_name.append(image_name_num)\n",
        "#     color=[c00, d00, e00, f00, g00,i00,h00]\n",
        "#     colors=color.append(color)\n",
        "#     #io.imsave(new_dir_name+'/'+filename,bud_mask)\n",
        "#     print('----end-----')\n",
        "\n",
        "# counts=(np.array(value_counts))\n",
        "# names=(np.array(file_name))\n",
        "# colors=(np.array(color))\n",
        "# d=np.concatenate((names, counts), axis=1)\n",
        "# counts=np.array(counts)\n",
        "# d=(pd.DataFrame(d))\n",
        "\n",
        "# d.columns = ['filename','epidermis (pixels)', 'mesophyll (pixels)','air space (pixels)', 'bundle sheath extension (pixels)', 'veins (pixels)','background (pixels)','full image size (pixels)']\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.max_row',None)\n",
        "\n",
        "# #d=d.rename(columns = ({\"1\":\"Mod_col\"},{\"2\":\"Mod_col\"},{\"3\":\"Mod_col\"},{\"4\":\"Mod_col\"},{\"5\":\"Mod_col\"})\n",
        "\n",
        "# print(d)\n",
        "# d.to_csv(new_dir_name+'/'+'leaf tissue.csv')\n",
        "# #print (counts)\n",
        "# print('----end-----')\n",
        "\n",
        "\n",
        "# # leaves=np.array(counts)\n",
        "# # FLV=np.sum(leaves)\n",
        "# # STV=np.sum(leaves, axis=0)\n",
        "# # FLC=STV[0]+STV[1]+STV[2]+STV[3]+STV[4]\n",
        "\n",
        "\n",
        "\n",
        "# # print('Full Image Volume (pixels)')\n",
        "# # print(FLV)\n",
        "# # print('')\n",
        "# # print('Specific Tissue Volume (pixels)')\n",
        "# # print('')\n",
        "# # print(STV)\n",
        "# # print('Full Bud Volume Check, should equal 1 if the sum of the individual columns equal to sum of all elements in the array ')\n",
        "# # print(FLC/FLV)\n",
        "# # print('')\n",
        "\n",
        "# # print('Epidermis leaf fraction')\n",
        "# # print(STV[0]/FLV)\n",
        "# # print('Mesophyll fraction')\n",
        "# # print(STV[1]/FLV)\n",
        "# # print('Air_space fraction')\n",
        "# # print(STV[2]/FLV)\n",
        "# # print('Bundle_Sheath fraction')\n",
        "# # print(STV[3]/FLV)\n",
        "# # print('Vein fraction')\n",
        "# # print(STV[4]/FLV)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hc2gtfB_zVM"
      },
      "source": [
        "#For loop for FCN model training Cell Code Box 4\n",
        "#!cd \"drive/My Drive/Colab Notebooks\"\n",
        "# Semantic Segmentation and Data Extraction in Pytorch Using FCN by Pranav Raja and a tiny bit by Devin Rippner (Plant AI and BioPhysics Lab)\n",
        "# a work in progress, works well overall but need mroe people to look at it and identify bugs\n",
        "#%%\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.segmentation.fcn import FCNHead\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "# from torch._six import container_abcs, string_classes, int_classes\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import os\n",
        "\n",
        "dir_checkpoint = \"drive/My Drive/FCN WORKFLOW PAPER/best_models/\"\n",
        "\n",
        "\n",
        "model_group='all_combined bce_/'\n",
        "num_models=10\n",
        "os.mkdir(dir_checkpoint+model_group)\n",
        "\n",
        "for i in range(num_models):\n",
        "  #!!!!!!! Here we pull in a pretrained FCN on torch and we replace the output layer since we have six classes rather than 21!!!!!!!!\n",
        "  num_classes=6\n",
        "  model=torchvision.models.segmentation.fcn_resnet101(pretrained=True, progress=True)\n",
        "  model.classifier=FCNHead(2048, num_classes)\n",
        "  \n",
        "  # def trainval_split(dataset, val_fraction=0.5):\n",
        "\n",
        "  #   validation_size = int(len(dataset) * val_fraction)\n",
        "  #   train_size = len(dataset) - validation_size\n",
        "  #   # print(validation_size)\n",
        "  #   # print(train_size)\n",
        "  #   # print(len(dataset))\n",
        "  #   # print(dataset.dataset_size)\n",
        "  #   train, val = torch.utils.data.random_split(dataset, [train_size, validation_size], generator=torch.Generator().manual_seed(i))\n",
        "\n",
        "  #   return train, val\n",
        "\n",
        "\n",
        "\n",
        "  # dataset= BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/mask_/\", 1, transform=True)\n",
        "  # dataset_train, dataset_val=trainval_split(dataset, val_fraction=0.5)\n",
        "  \n",
        "  #!!!!!select folders for the images and masks associated with training and validation here. Also specify image scaling factor here!!!!!!!!!!!!!!!!\n",
        "  dataset_train = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/mask_/\", 1, transform=True)\n",
        "  dataset_val = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/mask_/\", 1, transform=False)\n",
        "  # dataset_train = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/train/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/train/mask_edited2/\", 1, transform=True)\n",
        "  # dataset_val = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/test/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/test/mask_edited2/\", 1, transform=False)\n",
        "  \n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Specify Batch Size Here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  train_loader = DataLoader(dataset_train, batch_size=1, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)#, collate_fn=pad_collate)\n",
        "  val_loader = DataLoader(dataset_val, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)#, collate_fn=pad_collate)\n",
        "\n",
        "\n",
        "  #%%\n",
        "\n",
        "  # this is the train code \n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!! Input epochs here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  num_epochs=500\n",
        "  # read up on optimizers but Adam should work for now, if you get good results with Adam then you can try SGD (it's harder to tune but usually converges better)\n",
        "  optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "  #just initializing a value called best_loss\n",
        "  best_loss=999\n",
        "\n",
        "  # choose a loss function\n",
        "  # criterion=nn.CrossEntropyLoss()\n",
        "  #criterion=nn.BCELoss().cuda()\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  class diceloss(nn.Module):\n",
        "      def __init__(self, epsilon):\n",
        "          # super(diceloss, self).init()\n",
        "          super(diceloss, self).__init__()\n",
        "          self.sigmoid=nn.Sigmoid()\n",
        "          self.epsilon=epsilon\n",
        "          # print('HI')\n",
        "      def forward(self, pred, target):\n",
        "          if target.size() != pred.size():\n",
        "              raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), pred.size()))\n",
        "          pred=self.sigmoid(pred)\n",
        "          tp=torch.sum(target*pred, (1,2,3))\n",
        "          fp=torch.sum((1-target)*pred, (1,2,3))\n",
        "          fn=torch.sum(target*(1-pred), (1,2,3))\n",
        "          # precision=tp/(tp+fp)\n",
        "          # recall=tp/(tp+fn)\n",
        "          f1=(tp)/(tp+self.epsilon+0.5*(fp+fn))\n",
        "          # print(f1)\n",
        "          return 1-torch.mean(f1)\n",
        "  criterion=diceloss(epsilon=0.1)\n",
        "  model.train()\n",
        "  # model.train()\n",
        "  #this is the train loop\n",
        "  for epoch in range(num_epochs):\n",
        "      print('Epoch: ', str(epoch))\n",
        "    \n",
        "      # train_loader.dataset.dataset.transform=True\n",
        "      model.train()\n",
        "      for images, masks in train_loader:\n",
        "\n",
        "          images = images.to(device=device, dtype=torch.float32)\n",
        "          masks = masks.to(device=device, dtype=torch.float32)\n",
        "\n",
        "          #forward pass\n",
        "          preds=model(images)['out'].cuda()\n",
        "        \n",
        "          #compute loss\n",
        "          loss=criterion(preds, masks)\n",
        "        \n",
        "          #reset the optimizer gradients to 0\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          #backward pass (compute gradients)\n",
        "          loss.backward()\n",
        "\n",
        "          #use the computed gradients to update model weights\n",
        "          optimizer.step()\n",
        "\n",
        "          print('Train loss: '+str(loss.to('cpu').detach()))\n",
        "      # model.eval()\n",
        "      # val_loader.dataset.dataset.transform=False\n",
        "      current_loss=0\n",
        "      \n",
        "      #test on val set and save the best checkpoint\n",
        "      model.eval()\n",
        "      for images, masks in val_loader:\n",
        "          images = images.to(device=device, dtype=torch.float32)\n",
        "          masks = masks.to(device=device, dtype=torch.float32)\n",
        "          preds=model(images)['out'].cuda()\n",
        "          # print(preds)\n",
        "          # print(masks)\n",
        "          loss=criterion(preds, masks)\n",
        "          #print('hi')\n",
        "          current_loss+=loss.to('cpu').detach()\n",
        "          del images, masks, preds, loss\n",
        "  #!!!!!!!!!!!!!!!!!!!!!!!!!!!Re-name model here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!        \n",
        "      if best_loss>current_loss:\n",
        "          best_loss=current_loss\n",
        "          print('Best Model Saved!, loss: '+ str(best_loss))\n",
        "          torch.save(model.state_dict(), dir_checkpoint+model_group + '411 5x5 diceloss'+str(i+1)+\".pth\")\n",
        "      else:\n",
        "          print('Model is bad!, Current loss: '+ str(current_loss) + ' Best loss: '+str(best_loss))\n",
        "      print('\\n')\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "# %%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6UJlCd4cHS8"
      },
      "source": [
        "#Individual model training for FCN Code Box 4\n",
        "#!cd \"drive/My Drive/Colab Notebooks\"\n",
        "# Semantic Segmentation and Data Extraction in Pytorch Using FCN by Pranav Raja and Devin Rippner (Plant AI and BioPhysics Lab)\n",
        "# a work in progress, works well overall but need mroe people to look at it and identify bugs\n",
        "#%%\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.segmentation.fcn import FCNHead\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "# from torch._six import container_abcs, string_classes, int_classes\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "#!!!!!!! Here we pull in a pretrained FCN on torch and we replace the output layer since we have six classes rather than 21!!!!!!!!\n",
        "num_classes=6\n",
        "model=torchvision.models.segmentation.fcn_resnet101(pretrained=True, progress=True)\n",
        "model.classifier=FCNHead(2048, num_classes)\n",
        "\n",
        "\n",
        "dir_checkpoint = \"drive/My Drive/FCN WORKFLOW PAPER/best_models/\"\n",
        "\n",
        "\n",
        "def trainval_split(dataset, val_fraction=0.5):\n",
        "\n",
        "    validation_size = int(len(dataset) * val_fraction)\n",
        "    train_size = len(dataset) - validation_size\n",
        "    # print(validation_size)\n",
        "    # print(train_size)\n",
        "    # print(len(dataset))\n",
        "    # print(dataset.dataset_size)\n",
        "    train, val = torch.utils.data.random_split(dataset, [train_size, validation_size], generator=torch.Generator().manual_seed(2))\n",
        "\n",
        "    return train, val\n",
        "\n",
        "\n",
        "\n",
        "dataset= BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/image_/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/mask_/\", 1, transform=True)\n",
        "dataset_train, dataset_val=trainval_split(dataset, val_fraction=0.5)\n",
        "# dataset_val = BasicDataset(\"drive/My Drive/FCN WORKFLOW PAPER/trainran/image/\", \"drive/My Drive/FCN WORKFLOW PAPER/trainran/mask/\", 1, transform=False)\n",
        "\n",
        "# train, val=trainval_split(dataset, val_fraction=0.5)\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Specify Batch Size Here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "train_loader = DataLoader(dataset_train, batch_size=1, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)#, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(dataset_val, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)#, collate_fn=pad_collate)\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "# this is the train code \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!! Input epochs here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "num_epochs=300\n",
        "# read up on optimizers but Adam should work for now, if you get good results with Adam then you can try SGD (it's harder to tune but usually converges better)\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "#just initializing a value called best_loss\n",
        "best_loss=999\n",
        "\n",
        "# choose a loss function\n",
        "# criterion=nn.CrossEntropyLoss()\n",
        "#criterion=nn.BCELoss().cuda()\n",
        "# criterion = nn.BCEWithLogitsLoss()\n",
        "class diceloss(nn.Module):\n",
        "    def __init__(self, epsilon):\n",
        "        # super(diceloss, self).init()\n",
        "        super(diceloss, self).__init__()\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        self.epsilon=epsilon\n",
        "        # print('HI')\n",
        "    def forward(self, pred, target):\n",
        "        if target.size() != pred.size():\n",
        "            raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), pred.size()))\n",
        "        pred=self.sigmoid(pred)\n",
        "        tp=torch.sum(target*pred, (1,2,3))\n",
        "        fp=torch.sum((1-target)*pred, (1,2,3))\n",
        "        fn=torch.sum(target*(1-pred), (1,2,3))\n",
        "        # precision=tp/(tp+fp)\n",
        "        # recall=tp/(tp+fn)\n",
        "        f1=(tp)/(tp+self.epsilon+0.5*(fp+fn))\n",
        "        # print(f1)\n",
        "        return 1-torch.mean(f1)\n",
        "criterion=diceloss(epsilon=0.1)\n",
        "model.train()\n",
        "# model.train()\n",
        "#this is the train loop\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch: ', str(epoch))\n",
        "   \n",
        "    # train_loader.dataset.dataset.transform=True\n",
        "    model.train()\n",
        "    for images, masks in train_loader:\n",
        "\n",
        "        images = images.to(device=device, dtype=torch.float32)\n",
        "        masks = masks.to(device=device, dtype=torch.float32)\n",
        "\n",
        "        #forward pass\n",
        "        preds=model(images)['out'].cuda()\n",
        "       \n",
        "        #compute loss\n",
        "        loss=criterion(preds, masks)\n",
        "       \n",
        "        #reset the optimizer gradients to 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #backward pass (compute gradients)\n",
        "        loss.backward()\n",
        "\n",
        "        #use the computed gradients to update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        print('Train loss: '+str(loss.to('cpu').detach()))\n",
        "    # model.eval()\n",
        "    # val_loader.dataset.dataset.transform=False\n",
        "    current_loss=0\n",
        "    \n",
        "    #test on val set and save the best checkpoint\n",
        "    model.eval()\n",
        "    for images, masks in val_loader:\n",
        "        images = images.to(device=device, dtype=torch.float32)\n",
        "        masks = masks.to(device=device, dtype=torch.float32)\n",
        "        preds=model(images)['out'].cuda()\n",
        "        # print(preds)\n",
        "        # print(masks)\n",
        "        loss=criterion(preds, masks)\n",
        "        #print('hi')\n",
        "        current_loss+=loss.to('cpu').detach()\n",
        "        del images, masks, preds, loss\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!Re-name model here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!        \n",
        "    if best_loss>current_loss:\n",
        "        best_loss=current_loss\n",
        "        print('Best Model Saved!, loss: '+ str(best_loss))\n",
        "        torch.save(model.state_dict(), dir_checkpoint + '6223_411sept4x1.pth')\n",
        "    else:\n",
        "        print('Model is bad!, Current loss: '+ str(current_loss) + ' Best loss: '+str(best_loss))\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "# %%"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}